# Apache Flink 핸즈온 가이드: 스트림 처리의 모든 것

## 머리말

데이터는 우리 주변 세상의 자연스러운 흐름입니다. 웹 서버의 이벤트 로그, 증권 거래소의 거래 내역, 공장 기계의 센서 데이터 등 모든 데이터는 본질적으로 '스트림'의 형태로 생성됩니다. 이러한 데이터의 흐름을 어떻게 분석하고 처리할 것인가는 현대 데이터 엔지니어링의 가장 중요한 화두 중 하나입니다.

Apache Flink는 바로 이 스트리밍 데이터를 처리하기 위해 태어난 강력한 오픈소스 프레임워크입니다. Flink를 사용하면 대규모의 스트리밍 데이터를 실시간으로, 그리고 신뢰성 있게 처리하는 정교한 애플리케이션을 구축할 수 있습니다.

이 책은 Apache Flink의 세계에 첫발을 내딛는 여러분을 위한 실용적인 안내서입니다. 우리는 확장 가능한 스트리밍 ETL, 데이터 분석, 이벤트 기반 애플리케이션을 작성하는 데 꼭 필요한 핵심 개념부터 차근차근 짚어볼 것입니다. 복잡하고 방대한 Flink의 모든 기능을 다루기보다는, 상태(state)와 시간(time)이라는 두 가지 핵심 요소를 관리하는 API에 집중하여 기본기를 탄탄하게 다지는 것을 목표로 합니다.

이 책을 통해 여러분은 다음의 내용들을 배우게 될 것입니다.
- 스트리밍 데이터 처리 파이프라인을 구현하는 방법
- Flink가 상태를 관리하는 방법과 그 중요성
- 이벤트 시간을 사용하여 일관되고 정확한 분석 결과를 계산하는 방법
- 연속적인 스트림 위에서 이벤트 기반 애플리케이션을 구축하는 방법
- Flink가 어떻게 내결함성(fault-tolerant)과 정확히 한 번(exactly-once) 의미 구조를 보장하는지

이 책은 스트리밍 데이터의 연속적 처리, 이벤트 시간, 상태 저장 스트림 처리, 그리고 상태 스냅샷이라는 네 가지 핵심 개념에 초점을 맞춥니다. 이 개념들을 확실히 이해한다면, 여러분은 Flink의 더 깊이 있는 기능들을 스스로 학습하고 활용할 수 있는 훌륭한 토대를 마련하게 될 것입니다.

이제 Flink와 함께 데이터의 흐름에 올라탈 준비를 시작해 봅시다.

---
## 제1장. 스트림 처리의 세계

### 1.1 데이터의 자연스러운 형태, 스트림

데이터의 가장 자연스러운 서식지는 스트림입니다. 데이터는 정지된 호수가 아니라 끊임없이 흐르는 강과 같습니다. 웹 서버에서 발생하는 클릭 이벤트, 주식 시장의 체결 데이터, 공장 자동화 설비에서 수집되는 센서 값까지, 모든 데이터는 연속적인 스트림의 일부로 생성됩니다.

이러한 데이터를 분석할 때, 우리는 두 가지 패러다임 중 하나를 선택할 수 있습니다. 바로 유한(bounded) 스트림을 다루는 방식과 무한(unbounded) 스트림을 다루는 방식입니다. 어떤 패러다임을 선택하는지는 데이터 처리 방식에 지대한 영향을 미칩니다.

**배치 처리(Batch processing)**는 유한 데이터 스트림을 처리하는 전통적인 패러다임입니다. 이 방식에서는 정해진 양의 데이터를 모두 수집한 후에 처리를 시작할 수 있습니다. 예를 들어, 어제 하루 동안 쌓인 모든 로그를 모아 한 번에 분석하는 경우가 여기에 해당합니다. 전체 데이터를 한 번에 볼 수 있으므로 데이터를 정렬하거나, 전역적인 통계를 계산하거나, 모든 입력을 요약하는 최종 보고서를 만드는 작업이 가능합니다.

반면, **스트림 처리(Stream processing)**는 무한 데이터 스트림을 다룹니다. 개념적으로 입력 데이터는 끝이 없으므로, 데이터가 도착하는 대로 즉시, 그리고 지속적으로 처리해야 합니다. 소셜 미디어 피드처럼 실시간으로 발생하는 데이터를 처리하는 것이 대표적인 예입니다.

### 1.2 Flink 애플리케이션의 구조

Flink에서 애플리케이션은 사용자가 정의한 **연산자(operator)**에 의해 변환되는 **스트리밍 데이터 흐름(streaming dataflows)**으로 구성됩니다. 이러한 데이터 흐름은 하나 이상의 **소스(source)**에서 시작하여 하나 이상의 **싱크(sink)**에서 끝나는 방향성 비순환 그래프(DAG) 형태를 이룹니다.

소스(Source): 데이터가 Flink 애플리케이션으로 들어오는 시작점입니다. Apache Kafka, Kinesis와 같은 메시지 큐나 분산 로그 시스템에서 실시간 데이터를 가져올 수도 있고, 파일 시스템이나 데이터베이스에서 과거의 유한 데이터를 읽어올 수도 있습니다.

연산자(Operator): 데이터 스트림을 변환하는 역할을 합니다. map, filter, window 등 다양한 연산자를 통해 데이터를 가공, 집계, 분석합니다.

싱크(Sink): 처리된 결과를 외부 시스템으로 내보내는 종착점입니다. 데이터베이스, 파일 시스템, 다른 메시지 큐 등 다양한 시스템이 싱크가 될 수 있습니다.

보통 프로그램 코드의 변환(transformation) 하나는 데이터 흐름 그래프의 연산자 하나와 일대일로 대응됩니다. 하지만 때로는 하나의 변환이 여러 연산자로 구성될 수도 있습니다.

### 1.3 병렬 데이터 흐름: Flink의 확장성

Flink 프로그램은 본질적으로 병렬적이고 분산적으로 설계되었습니다. 프로그램이 실행될 때, 하나의 스트림은 하나 이상의 **스트림 파티션(stream partition)**으로 나뉘고, 각 연산자는 하나 이상의 **연산자 서브태스크(operator subtask)**를 가집니다. 각 서브태스크는 서로 독립적으로, 별개의 스레드에서 실행되며, 물리적으로 다른 장비나 컨테이너에서 실행될 수 있습니다.

한 연산자가 가지는 서브태스크의 개수를 해당 연산자의 **병렬성(parallelism)**이라고 합니다. 같은 프로그램 내에서도 연산자마다 다른 수준의 병렬성을 가질 수 있습니다.

두 연산자 사이의 데이터 전송 방식은 크게 두 가지로 나뉩니다.

일대일(One-to-one) 또는 전달(Forwarding) 방식: 위 그림에서 'Source'와 'map()' 연산자 사이의 관계처럼, 데이터의 파티셔닝과 순서를 그대로 유지합니다. 즉, 'Source' 연산자의 첫 번째 서브태스크가 생성한 요소들은 순서 그대로 'map()' 연산자의 첫 번째 서브태스크로 전달됩니다.

재배포(Redistributing) 방식: 'map()'과 'keyBy/window' 사이, 그리고 'keyBy/window'와 'Sink' 사이의 관계처럼 스트림의 파티션을 변경합니다. 각 연산자 서브태스크는 선택된 변환 방식에 따라 데이터를 여러 대상 서브태스크로 보냅니다. 예를 들어, keyBy()는 키를 해싱하여 재파티셔닝하고, rebalance()는 무작위로 재파티셔닝합니다. 이 방식에서는 데이터를 보내는 서브태스크와 받는 서브태스크 쌍 내에서만 데이터의 순서가 보장됩니다. 따라서 위 그림의 'Sink' 연산자는 서로 다른 키에 대한 집계 결과가 비결정적인 순서로 도착할 수 있습니다.

지금까지 Flink의 기본적인 데이터 흐름과 병렬 처리에 대해 알아보았습니다. Flink가 어떻게 대규모 데이터를 효율적으로 처리할 수 있는지에 대한 기본 개념을 이해하셨을 것입니다.


# Apache Flink 핸즈온 가이드: 스트림 처리의 모든 것 (2부)

## 제2장. 시간을 다스리는 기술: 적시 스트림 처리
대부분의 스트리밍 애플리케이션에서 과거의 데이터를 현재의 실시간 데이터와 동일한 코드로 재처리하고, 언제나 결정적이고 일관된 결과를 얻는 능력은 매우 중요합니다.

예를 들어, 전자상거래 트랜잭션이나 금융 거래와 관련된 일련의 이벤트를 생각해 봅시다. 이 이벤트들이 처리 시스템에 도착한 순서보다는 실제로 발생한 순서에 주목하는 것이 중요할 수 있습니다. 또한, 특정 시간 범위 내의 이벤트 집합이 언제 완전하게 수집되었는지를 판단하는 능력도 필수적입니다.

이러한 요구사항은 데이터를 처리하는 기계의 시계(Processing Time) 대신, 데이터 스트림 자체에 기록된 이벤트 시간(Event Time) 타임스탬프를 사용함으로써 충족될 수 있습니다. Flink는 이벤트 시간을 기반으로 데이터를 처리하는 정교한 메커니즘을 제공하여, 데이터 도착 순서나 처리 지연에 상관없이 항상 정확한 결과를 보장합니다.

---
## 제3장. 기억하는 스트림: 상태 저장 처리
Flink의 연산은 **상태(state)**를 가질 수 있습니다. 이는 한 이벤트를 처리하는 방식이 그 이전에 도착했던 모든 이벤트들의 누적된 효과에 따라 달라질 수 있다는 의미입니다. 상태는 대시보드에 표시하기 위해 분당 이벤트 수를 세는 것과 같은 간단한 작업부터, 사기 탐지 모델을 위한 특징(feature)을 계산하는 것과 같은 복잡한 작업에 이르기까지 다양하게 사용됩니다.

Flink 애플리케이션은 분산된 클러스터에서 병렬로 실행됩니다. 특정 연산자의 여러 병렬 인스턴스들은 서로 다른 스레드에서, 그리고 일반적으로는 서로 다른 머신에서 독립적으로 실행됩니다.

상태를 가진 연산자의 병렬 인스턴스 집합은 사실상 분할된(sharded) 키-값 저장소와 같습니다. 각 병렬 인스턴스는 특정 키 그룹에 대한 이벤트를 처리할 책임이 있으며, 해당 키에 대한 상태는 로컬에 저장됩니다.

위 다이어그램은 처음 세 연산자가 2의 병렬성을 가지고 실행되다가 병렬성이 1인 싱크로 끝나는 작업을 보여줍니다. 세 번째 연산자는 상태를 가지고 있으며, 두 번째와 세 번째 연산자 사이에는 완전 연결된 네트워크 셔플(shuffle)이 발생하고 있습니다. 이는 스트림을 특정 키로 파티셔닝하여, 함께 처리되어야 할 모든 이벤트가 동일한 병렬 인스턴스로 보내지도록 하기 위함입니다.

상태는 항상 로컬에서 접근됩니다. 이는 Flink 애플리케이션이 높은 처리량과 낮은 지연 시간을 달성하는 데 큰 도움이 됩니다. 상태를 JVM 힙에 저장할 수도 있고, 크기가 너무 크다면 효율적으로 구성된 디스크 내 자료 구조에 저장할 수도 있습니다.

---
## 제4장. 장애를 극복하는 힘: 상태 스냅샷을 통한 내결함성
Flink는 **상태 스냅샷(state snapshots)**과 **스트림 재현(stream replay)**의 조합을 통해 장애에 강하고, 정확히 한 번(exactly-once) 처리 의미를 보장할 수 있습니다.

스냅샷은 분산된 파이프라인의 전체 상태를 캡처합니다. 여기에는 입력 큐의 오프셋(어디까지 읽었는지)뿐만 아니라, 해당 지점까지 데이터를 처리한 결과로 생성된 작업 그래프 전반의 모든 상태가 기록됩니다.

만약 장애가 발생하면, Flink는 다음과 같은 절차로 복구합니다.

소스(Source)를 가장 최근의 스냅샷 시점으로 되돌립니다.

스냅샷에 저장된 상태를 복원합니다.

중단되었던 지점부터 처리를 재개합니다.

이러한 상태 스냅샷은 진행 중인 처리를 방해하지 않고 비동기적으로 캡처되므로, 성능 저하를 최소화하면서도 강력한 내결함성을 제공할 수 있습니다.

## 맺음말
이것으로 Apache Flink 핸즈온 가이드의 모든 파트를 마칩니다. 우리는 스트림 처리의 기본 개념부터 시작하여 Flink가 병렬 처리, 시간, 상태, 그리고 내결함성을 어떻게 다루는지 살펴보았습니다.

이 책에서 다룬 네 가지 핵심 개념(연속적 처리, 이벤트 시간, 상태 저장 처리, 상태 스냅샷)은 Flink를 이해하고 활용하는 데 가장 중요한 기초입니다. 이 기초를 바탕으로 여러분은 이제 더 복잡하고 정교한 실시간 데이터 애플리케이션을 구축할 준비가 되었습니다.

더 깊이 있는 학습을 원하신다면 Apache Flink 공식 문서를 참고하시는 것을 추천합니다. 이 책이 여러분의 Flink 여정에 훌륭한 첫걸음이 되었기를 바랍니다.

--- 
## 추가 질문 

Q) 스트림 처리는 스트림 파티션으로 병렬적으로 처리되는데 이렇게 쪼개진 스트림은 각각의 연산자 서브태스크가 처리하는건가? 그러면 연산자 서브태스크의 병렬화 수준과 스트림 파티션의 병렬화 수준은 같은거? 

Q) 재배포 방식과 일대일 방식(forward) 방식의 차이에 대해서 재배포 방식은 처리한 서브태스크를 다른 키를 처리하는 서브태스크로 보낼 수 있다는 차이인가? Fan out 과 같은 처리 방식이 아니라? 

- 일대일 또는 forward 방식이 단순 데이터를 다음 서브태스크에 전달하는 방식이라면 재배포 방식은 특정 키를 가진 데이터를 특정 서브태스크로 가게 만들 수 있다. 
- Flink 는 fanout 과 같은 기능으로 broadcast() 라는 연산자가 별도로 있음. 

Q) Rebalance 라는 무작위 재파티셔닝이 필요한 이유는 뭐지? 
- 데이터 쏠림 현상을 해결하기 위해서 

Q) 네트워크 셔플(shuffle)이란 

Q) Apache Flink 에서 장애 허용성을 가지는 방법은? 

Q) Apache Flink 에서 정확히 한 번 처리하기 위한 방법은? 

Q) 왜 Two-phase Commit 매커니즘이 꼭 필요할까? 

사전 커밋과 커밋 단계를 명확히 구별하는 것으로 보임. 

데이터를 다 보내고 나서 커밋을 먼저해버리면 혼자만 완료해버리는게 됨. 다같이 다 성공하기 위해서는 준비단계가 필요함. 


