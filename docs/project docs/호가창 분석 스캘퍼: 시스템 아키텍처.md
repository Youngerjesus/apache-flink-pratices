# 시스템 아키텍처와 실질적인 구현 디테일 

핵심은 **'속도'**와 **'안정성'**, 그리고 **'확장성'**입니다. 수십 밀리초(ms)의 차이로 성패가 갈리는 전략이므로, 모든 아키텍처는 지연 시간(Latency)을 최소화하는 방향으로 설계되어야 합니다.

---

## 🚀 시스템 아키텍처 (System Architecture)

전체 시스템은 크게 **5개의 핵심 계층**으로 구성됩니다.

### **1. 데이터 수집 계층 (Data Ingestion Layer)** 
* **역할:** 업비트와 빗썸 거래소로부터 실시간 데이터를 가장 빠르게 수집하여 Kafka로 전송합니다.
* **컴포넌트:**
    * **Exchange Connectors (Upbit/Bithumb):** 각 거래소별로 독립적인 경량 마이크로서비스로 구현합니다.
        * **WebSocket Connector:** 실시간 '거래 체결(Trade Print)'과 '호가창(Order Book)' 데이터는 지연 시간을 최소화하기 위해 반드시 WebSocket API를 사용합니다.
    * **구현 언어:** Rust, Go, C++ 등 저지연 네트워킹에 강점이 있는 언어를 추천합니다. (Java/Kotlin도 가능)
    * **핵심 고려사항:** 각 거래소의 API Rate Limit을 철저히 준수해야 하며, 연결이 끊겼을 때를 대비한 재연결 로직과 데이터 유실 방지 메커니즘이 필수입니다.

### **2. 데이터 스트리밍 계층 (Data Streaming Layer - Kafka)**
* **역할:** 모든 원시 시장 데이터를 중앙에서 안정적으로 받아들이고, 후속 처리 시스템(Flink)이 소비할 수 있도록 버퍼링하는 역할을 합니다. 시스템의 '중앙 혈관'입니다.
* **Kafka Topics:**
    * `raw-trades-upbit`, `raw-trades-bithumb`: 실시간 거래 체결 데이터
    * `raw-orderbooks-upbit`, `raw-orderbooks-bithumb`: 실시간 호가창 변경분(diff) 또는 스냅샷 데이터
    * `internal-signals`: Flink에서 생성된 매수/매도 신호
    * `execution-orders`: 실제 주문 실행 요청
    * `execution-results`: 주문 실행 결과 (성공, 실패, 부분 체결 등)
    * `execution.feedback.v1`**: 주문 실행 결과를 Flink에게 피드백 (State 동기화용)
    * `system.state.restore.v1`**: Reconciliation Job이 Flink State 복원 명령 발행

* **핵심 고려사항:** 데이터 직렬화 포맷으로 **Avro** 또는 **Protocol Buffers**를 사용하여 메시지 크기를 줄이고 처리 속도를 높입니다. 데이터 처리량에 따라 파티션 수를 적절히 조절하여 병렬 처리를 극대화합니다.

### (보완) State 동기화 아키텍처 (하이브리드 CQRS + Reconciliation Loop)

**핵심 설계 철학:** "빠른 쓰기(Write), 느린 일관성 보장(Eventual Consistency)"

이 시스템의 가장 중요한 설계 결정 중 하나는 Flink State와 PostgreSQL 간의 상태 동기화 메커니즘입니다. 스캘핑 전략의 특성상 밀리초 단위의 지연도 수익에 직접적인 영향을 미치므로, 강한 일관성(Strong Consistency)을 추구하는 대신 저지연(Low Latency)과 최종 일관성(Eventual Consistency)을 선택합니다.

**구성 요소:**

1. **Flink State (Primary Source of Truth for Real-time Decisions)**
   - 역할: 실시간 매매 결정을 위한 주(主) 상태 저장소
   - 특징: 인메모리 기반, 1-5ms 응답 시간, Checkpoint를 통한 복원
   - 저장 데이터: `active_positions` (현재 보유 중인 포지션 정보)

2. **PostgreSQL (Audit Trail & Long-term Backup)**
   - 역할: 영구 감사 추적 및 장기 백업
   - 특징: 디스크 기반, 수백 ms 지연 허용, ACID 트랜잭션 보장
   - 저장 데이터: `trade_cycles` 테이블 (모든 포지션의 진입/청산 이력)

3. **Execution Feedback Loop (Fast Path - 20-50ms)**
   - 역할: 주문 실패 시 Flink State를 즉시 정정
   - 동작: 주문 실행 직후 → `execution.feedback.v1` 발행 → Flink 수신 (20-50ms)
   - 처리: 99.9%의 State 불일치를 실시간으로 방지

4. **Reconciliation Job (Slow Path - 10초 주기)**
   - 역할: 피드백이 누락된 경우의 안전망 (0.1% edge case 처리)
   - 동작: 10초마다 PostgreSQL 조회 → 불일치 감지 → `system.state.restore.v1` 발행 → Flink 복원
   - 처리: Flink 재시작이나 네트워크 장애로 인한 State 유실 복구

**데이터 흐름 시나리오:**

```
[정상 케이스 - 99.9%]
T+0ms:    Flink 매수 신호 생성
          → active_positions.put("KRW-BTC", position_info) ✅
          
T+10ms:   Execution Engine 주문 체결 성공
          → execution.feedback.v1 발행 (status=SUCCESS)
          
T+30ms:   Flink 피드백 수신
          → active_positions 유지 확인 ✅
          
T+1s:     execution.results.v1 발행 (상세 정보)
          
T+2s:     Archivist가 PostgreSQL에 기록
          → trade_cycles INSERT (status=OPEN) ✅

결과: Flink State ✅  PostgreSQL ✅ (일관성 유지)

[장애 복구 케이스 - 0.1%]
T+0ms:    Flink 매수 신호 생성 → State 추가 ✅
T+10ms:   주문 성공 → PostgreSQL 기록 ✅
T+50ms:   💥 Flink 재시작 (Checkpoint 실패)
T+60ms:   Flink State 유실 ❌ (active_positions 비어있음)
---
T+10s:    Reconciliation Job 실행
          → PostgreSQL 조회: "KRW-BTC OPEN 포지션 발견"
          → 최근 매도 신호 없음 확인
          → 판단: "Flink가 모르는 포지션 존재"
          → system.state.restore.v1 발행 📨
          
T+10.1s:  Flink 복원 명령 수신
          → active_positions.put("KRW-BTC", ...) ✅
          → 매도 로직 재활성화

결과: Flink State ✅ (복원됨)  PostgreSQL ✅ (최종 일관성 달성)
```

**트레이드오프 분석:**

| 측면 | 선택 | 이유 |
|------|------|------|
| **일관성 모델** | Eventual Consistency | 스캘핑의 저지연 요구사항 우선 |
| **Primary SSOT** | Flink State (실시간) | 1-5ms 응답 시간 확보 |
| **Secondary SSOT** | PostgreSQL (감사) | 영구 보관 및 복구 지점 |
| **동기화 지연** | 최대 10초 | Reconciliation 주기 |
| **복잡도** | 높음 | 2개 스트림 + TTL State + 별도 Job 필요 |

**이 설계를 선택한 이유:**
- ✅ 저지연: 매매 결정에 영향을 주지 않음 (Flink State만 참조)
- ✅ 강력한 복원력: 2중 안전장치 (피드백 + Reconciliation)
- ✅ 감사 추적: PostgreSQL에 모든 이력 영구 보존
- ⚠️ 단점: 최대 10초 동안 일시적 불일치 가능 (허용 가능한 수준)

### **3. 실시간 분석/신호 생성 계층 (CEP Layer - Flink)**
* **역할:** 시스템의 '두뇌'입니다. Kafka로부터 데이터를 받아 기획 문서에 명시된 'P파'와 '여진'을 실시간으로 감지하고 매매 신호를 생성합니다.
* **Flink Jobs (여러 개로 분리하여 관리):**
    * **Job 1: Market Data Processor**
        * 각 거래소의 원시 데이터를(e.g., `raw-trades-upbit`) 입력받아 정규화된(Normalized) 데이터 모델로 변환합니다.
        * 호가창 데이터와 체결 데이터를 코인별로 `keyedStream`을 사용하여 묶어줍니다. 이를 통해 특정 코인에 대한 모든 분석이 동일한 Flink Task Manager에서 처리되도록 보장합니다.
    * **Job 2: Signal Generation (P-wave & Aftershock Detection)**
        * **Stateful Processing**을 적극적으로 활용합니다. Flink의 관리형 상태(Managed State)에 이전 호가창 데이터, 최근 N초간의 거래량 등을 저장합니다.
        * **'호가 밀도 변화율' 계산:** `ProcessFunction` 을 사용하여 현재 호가창 상태와 직전 상태를 비교, 매도 물량의 급격한 감소를 감지합니다.
        * **'단기 대량 호가 출현 빈도' 계산:** 짧은 시간 윈도우(e.g., 1초) 내에서 특정 규모 이상의 호가가 생성되었다가 `order_id`가 사라지는 패턴을 상태 기반으로 추적합니다.
        * **'평균 체결 거래량 감소' 추적:** 고래 체결 감지 후, 후속 매수 거래들의 체결량을 `Tumbling Window`나 `Sliding Window`를 이용해 이동 평균을 계산하고, 이 평균값이 감소하는 추세를 감지합니다.
        * **'상대 호가 불균형 심화' 감지:** 현재 호가창 스냅샷에서 매수/매도 잔량을 비교하여 비율을 계산하고 임계치를 넘는지 확인합니다.
        * 위 조건들이 충족되면, 매수/매도 신호(e.g., `{ "symbol": "BTC/KRW", "side": "BUY", "reason": "P-WAVE_DETECTED", "timestamp": ... }`)를 `internal-signals` Kafka 토픽으로 전송합니다.

**4. 주문 실행 계층 (Order Execution Layer)**
* **역할:** Flink가 생성한 '매매 신호'를 받아 실제 거래소에 주문을 전송하는, 매우 높은 신뢰성이 요구되는 '손' 역할을 합니다.
* **컴포넌트:**
    * **Execution Engine:** `internal-signals` 토픽을 구독(consume)하는 독립적인 마이크로서비스입니다.
    * **로직:**
        1.  매매 신호 수신
        2.  현재 계좌 잔고, 기존 포지션 등 리스크 관리 로직 확인
        3.  거래소 Private API를 통해 시장가/지정가 주문 전송
        4.  주문 실행 결과를 `execution-results` 토픽으로 전송하여 모든 활동을 기록합니다.
* **핵심 고려사항:**
    * **멱등성(Idempotency):** 동일한 신호가 중복으로 처리되어 주문이 여러 번 나가는 것을 방지해야 합니다. 신호에 고유 ID를 부여하여 처리 여부를 확인합니다.
    * **장애 격리:** Flink 클러스터의 장애가 주문 실행에 직접적인 영향을 주지 않도록 Kafka를 통해 비동기적으로 분리하는 것이 매우 중요합니다.

**5. 데이터베이스 및 관리 계층 (Persistence & Management Layer)**
* **역할:** 시스템의 모든 활동을 기록하고, 설정을 관리하며, 성과를 분석하는 기반을 제공합니다.
* **PostgreSQL 활용:**
    * **Configuration Table:** `X%`, `Y초` 등 전략의 모든 **하이퍼파라미터**를 저장합니다. Flink 잡이나 Execution Engine은 시작 시 이 테이블을 읽어 설정을 로드합니다. (실시간 변경은 별도 메커니즘 필요)
    * **Trade Log Table:** `execution-results` 토픽의 데이터를 저장하여 모든 매매 내역(진입 가격, 청산 가격, 수익, 신호 이유 등)을 영구적으로 기록합니다.
    * **Monitoring/Dashboard:** Grafana, Metabase 같은 BI 툴과 PostgreSQL을 연동하여 실시간 P&L(손익), 승률, 슬리피지 등을 시각화합니다.
    * **Backtesting Data Storage:** 과거의 원시 데이터를 저장해두고, 이를 Flink 잡에 주입하여 새로운 하이퍼파라미터로 전략을 시뮬레이션하는 데 사용될 수 있습니다.


**6. 하이퍼파리미터 정리**
* P파(매수 신호) 관련:
    * pwave.density.window_seconds: 호가 밀도 변화율 계산을 위한 시간 윈도우 (초)
    * pwave.density.threshold_pct: 호가 밀도 변화율 트리거 임계값 (%)
    * pwave.spoofing.volume_threshold: 스푸핑으로 간주할 최소 주문량
    * pwave.spoofing.lifespan_ms: 스푸핑 주문의 최대 존속 시간 (ms)

* 여진(매도 신호) 관련:
    * aftershock.avg_trade_size.window_seconds: 평균 체결량 감소 추적을 위한 시간 윈도우
    * aftershock.avg_trade_size.decrease_threshold_pct: 평균 체결량 감소 트리거 임계값 (%)
    * aftershock.imbalance.depth: 호가 불균형 계산 시 확인할 호가 단계 수 (e.g., 10)
    * aftershock.imbalance.ratio_threshold: 매도벽/매수벽 불균형 트리거 비율 (e.g., 2.0)

* 리스크 관리 관련:
    * rsk.max_position_per_coin_krw: 코인당 최대 진입 금액 (KRW)
    * risk.stop_loss_pct: 강제 손절매 비율 (%)
    
**7. 백테스팅(backtesting) 관련 


---

## 🌊 데이터 흐름 및 Flink 핵심 로직 예시

1.  **[수집]** Bithumb Connector가 WebSocket으로 BTC/KRW 호가창에 100억 매도벽이 사라지는 것을 감지하고, 이 정보를 `raw-orderbooks-bithumb` 토픽으로 전송합니다.
2.  **[전송]** Kafka가 이 메시지를 수신하여 Flink가 소비할 수 있도록 대기시킵니다.
3.  **[분석]** Flink의 `Signal Generation` 잡이 이 메시지를 읽습니다.
    * 잡은 Flink State에 저장된 직전 호가창 데이터와 비교합니다.
    * **'호가 밀도 변화율'**이 설정된 임계치(e.g., 30%)를 넘었다고 판단합니다.
    * 동시에 다른 조건('단기 대량 호가 출현 빈도' 등)도 충족되는지 확인합니다.
    * 모든 'P파' 조건이 맞으면, `{ "side": "BUY", ... }` 신호를 생성하여 `internal-signals` 토픽으로 전송합니다.
4.  **[실행]** Execution Engine이 `internal-signals` 토픽에서 BUY 신호를 읽습니다.
    * 리스크 관리 규칙을 통과하면, 즉시 빗썸 API를 통해 BTC 시장가 매수 주문을 전송합니다.
    * 주문 체결 결과를 받아 `execution-results` 토픽에 기록합니다.
5.  **[기록]** 별도의 Consumer가 `execution-results` 토픽의 데이터를 PostgreSQL의 `trade_log` 테이블에 저장합니다.

---

## 🛠️ 주요 설계 고려사항 (Senior's Checklist)

* **지연 시간 (Latency):**
    * **물리적 위치:** 가능하면 거래소 서버와 가장 가까운 클라우드 리전(e.g., AWS ap-northeast-2)에 전체 시스템을 배포하여 네트워크 지연을 최소화해야 합니다.
    * **Flink 최적화:** Flink의 `RocksDBStateBackend`를 사용하고, GC 튜닝(G1GC or ZGC) 및 메모리 설정을 최적화하여 Checkpointing으로 인한 지연을 줄여야 합니다.
* **장애 복구 (Fault Tolerance):**
    * **Flink Checkpointing:** 반드시 활성화하여 Task Manager에 장애가 발생해도 Kafka의 offset과 Flink의 내부 상태(e.g., 이동 평균값)를 복구하여 데이터 유실 없이 계산을 재개할 수 있도록 해야 합니다.
    * **Execution Engine:** 이 서비스는 무상태(Stateless)로 설계하여 여러 인스턴스를 띄워 안정성을 확보하는 것이 좋습니다.
* **데이터 스키마 관리:**
    * **Schema Registry** (e.g., Confluent Schema Registry)를 사용하여 Kafka 토픽의 데이터 구조(Avro/Protobuf)를 중앙에서 관리하고, 데이터 형식 불일치로 인한 런타임 에러를 방지해야 합니다.
* **백테스팅 (Backtesting):**
    * 실제 돈을 투입하기 전에 전략의 유효성을 검증하는 것은 필수입니다. Flink는 과거 데이터를 Kafka에 재전송(replay)하여 동일한 로직으로 시뮬레이션할 수 있는 강력한 기능을 제공합니다. 이 환경을 반드시 구축해야 합니다.

이 설계는 기획 문서의 복잡한 실시간 분석 요구사항을 Flink의 강력한 상태 기반 스트림 처리 능력으로 해결하고, Kafka를 통해 각 컴포넌트를 분리하여 시스템 전체의 안정성과 확장성을 확보하는 데 중점을 두었습니다.

--- 
# 시스템 아키텍처를 실제로 구현해보기 위한 구현 디테일 

## 기술 스택 선정 (Python 기반)

프로그래밍 언어: Python
- 선택 이유: Rust 대비 학습 곡선이 낮고 생태계가 성숙하여 빠른 MVP 개발에 절대적으로 유리합니다. asyncio를 통해 비동기 I/O를 효율적으로 처리할 수 있어, 네트워크 통신이 대부분인 우리 커넥터의 성능을 충분히 확보할 수 있습니다.

- 고려사항: Python의 GIL(Global Interpreter Lock)로 인해 CPU 집약적인 작업에는 한계가 있으나, 우리 커넥터는 I/O 바운드(대부분의 시간을 네트워크 응답 대기에 사용) 작업이므로 asyncio를 통해 병목 현상을 최소화할 수 있습니다. 성능은 MVP 단계에서 충분하며, 추후 최적화가 필요할 시 Rust나 Go로의 전환을 고려할 수 있습니다.

--- 

## 1. 데이터 수집 계층 (Data Ingestion Layer) in detail 

### 1. 데이터 수집 계층의 핵심 목표
단순히 데이터를 가져오는 것을 넘어, 아래 3가지 원칙을 만족시켜야 합니다.
- 초저지연 (Ultra-Low Latency): 데이터가 거래소에서 발생한 시점과 우리 시스템(Kafka)에 도달하는 시간 차이를 물리적 한계에 가깝게 줄여야 합니다. 이는 언어, 라이브러리, 네트워크 아키텍처 선정의 최우선 기준이 됩니다.
- 데이터 무결성과 안정성 (Data Integrity & Reliability): 데이터는 빠를 뿐만 아니라, 단 하나도 유실되거나 순서가 뒤바뀌어서는 안 됩니다. WebSocket 연결 끊김, Kafka 장애 등 모든 예외 상황에 대응할 수 있는 강력한 복원력을 갖춰야 합니다.
- 확장성 및 유지보수성 (Scalability & Maintainability): 향후 빗썸, 코인원 등 새로운 거래소를 추가하거나 데이터 포맷을 변경할 때, 전체 시스템에 미치는 영향을 최소화하고 독립적으로 배포 및 수정이 가능해야 합니다.

### 2. 핵심 라이브러리:
- Asynchronous I/O: asyncio (Python 표준 라이브러리)
- WebSocket Client: websockets - asyncio 기반으로 동작하며, 자동 Ping/Pong 처리 등 강력한 기능을 내장한 검증된 라이브러리입니다.
- Kafka Producer: confluent-kafka - C 라이브러리(librdkafka) 기반으로 동작하여 Python 환경에서 가장 높은 성능과 안정성을 제공하는 Kafka 클라이언트입니다.
- 데이터 직렬화: protobuf - 구글에서 공식 지원하는 라이브러리를 사용하여 Protobuf 스키마를 컴파일하고 메시지를 생성합니다.

### 3. 데이터 모델링 (Protocol Buffers)

```proto
syntax = "proto3";

import "google/protobuf/timestamp.proto";

package scalper;

// 거래소 식별자
enum Exchange {
  EXCHANGE_UNSPECIFIED = 0;
  UPBIT = 1;
}

// 전일 대비 등락 상태
enum ChangeType {
  CHANGE_TYPE_UNSPECIFIED = 0;
  RISE = 1;   // 상승
  EVEN = 2;   // 보합
  FALL = 3;   // 하락
}

// 매수/매도 구분
enum AskBid {
  ASK_BID_UNSPECIFIED = 0;
  ASK = 1;    // 매도
  BID = 2;    // 매수
}

// 스트림 데이터 타입
enum StreamType {
  STREAM_TYPE_UNSPECIFIED = 0;
  SNAPSHOT = 1;
  REALTIME = 2;
}

// 실시간 거래 체결 데이터 (Upbit 'trade' 타입)
message Trade {
  Exchange exchange = 1;
  string code = 2;                          // 마켓 코드 (e.g., "KRW-BTC")
  double trade_price = 3;                   // 체결 가격 (tp)
  double trade_volume = 4;                  // 체결량 (tv)
  AskBid ask_bid = 5;                       // 매수/매도 구분 (ab)
  double prev_closing_price = 6;            // 전일 종가 (pcp)
  ChangeType change = 7;                    // 전일 대비 등락 (c)
  double change_price = 8;                  // 전일 대비 변동액 (cp)
  google.protobuf.Timestamp trade_timestamp = 9; // 체결 시각 (ttms)
  int64 sequential_id = 10;                 // 체결 고유 ID (sequential_id)
  StreamType stream_type = 11;              // 스트림 타입 (st)
  
  // -- 내부적으로 추가하는 메타데이터 --
  google.protobuf.Timestamp received_timestamp = 12; // 커넥터가 수신한 시각
}

// 호가창의 한 레벨 (매수 또는 매도)
message OrderBookLevel {
  double price = 1;                         // 호가
  double size = 2;                          // 주문량
}

// 실시간 호가창 변경분 데이터 (Upbit 'orderbook' 타입)
message OrderBookUpdate {
  Exchange exchange = 1;
  string code = 2;                          // 마켓 코드 (cd)
  double total_ask_size = 3;                // 매도 주문 총량 (tas)
  double total_bid_size = 4;                // 매수 주문 총량 (tbs)
  repeated OrderBookLevel asks = 5;         // 매도 호가 목록 (orderbook_units)
  repeated OrderBookLevel bids = 6;         // 매수 호가 목록 (orderbook_units)
  StreamType stream_type = 7;               // 스트림 타입 (st)

  // -- 내부적으로 추가하는 메타데이터 --
  google.protobuf.Timestamp event_timestamp = 8;   // 호가창 변경 이벤트 시각 (업비트 원본 timestamp 필드)
  google.protobuf.Timestamp received_timestamp = 9;  // 커넥터가 수신한 시각
}
```

### 4. 데이터 수신, 변환 및 전송 파이프라인 (핵심 로직)

(1) 파싱 (Parsing): WebSocket으로부터 받은 데이터는 바이너리 형태이므로, json.loads()를 통해 Python이 다룰 수 있는 딕셔너리(Dictionary) 객체로 변환합니다.

(2) 변환 (Transformation): 업비트가 보내주는 JSON 데이터의 필드명(e.g., tp, tv)을 우리가 정의한 Protobuf 메시지(Trade, OrderBookUpdate)의 필드명(e.g., trade_price, trade_volume)에 맞게 매핑하고 타입을 변환하는 함수(transform_trade, transform_orderbook)를 실행합니다.
- 주의: 업비트의 타임스탬프(ttms)는 Unix Millisecond 정수형이므로, 이를 google.protobuf.Timestamp 객체로 변환하는 과정이 반드시 필요합니다.

(3) 메타데이터 보강 (Enrichment): 변환 과정에서, Protobuf 메시지에 정의된 내부 메타데이터 필드인 received_timestamp에 현재 시각을 기록합니다. 이 타임스탬프는 추후 시스템 전체의 지연 시간(Latency)을 측정하고 병목 구간을 분석하는 데 결정적인 역할을 합니다.

(4) 직렬화 (Serialization): 완성된 Protobuf 객체를 .SerializeToString() 메소드를 호출하여 Kafka로 전송하기 위한 바이너리(bytes) 데이터로 변환합니다.

(5) 전송 (Production): confluent-kafka Producer를 사용하여 직렬화된 데이터를 Kafka로 전송합니다. 이때, 가장 중요한 것은 메시지의 key를 마켓 코드(e.g., "KRW-BTC")로 지정하는 것입니다. 아키텍처 설계(260라인)에 따라, 동일한 마켓 코드를 가진 데이터(체결, 호가)는 항상 동일한 Kafka 파티션에 순서대로 저장되어야 하며, 이는 Flink의 keyBy() 연산이 올바르게 동작하기 위한 절대적인 전제 조건입니다.

### 5. 데이터 수집 API 

#### 실시간 데이터 수신: Websocket API
필요성: '거래 체결(Trade)'과 '호가창(Order Book)' 데이터는 실시간성이 생명입니다. REST API처럼 매번 요청을 보내는 방식(Polling)으로는 수십 밀리초(ms)의 지연이 발생하여 스캘핑 전략의 기회를 포착할 수 없습니다. 따라서 서버가 데이터를 발생 즉시 보내주는 Websocket 방식이 필수적입니다.

사용 데이터 타입: trade(실시간 체결), orderbook(실시간 호가)

#### 데이터 동기화: 호가 정보 조회 (Orderbook Snapshot) REST API

필요성: Websocket 연결은 불안정한 네트워크나 서버 점검으로 언제든 끊길 수 있습니다. 연결이 끊겼다가 다시 붙었을 때는 그동안 놓친 데이터가 있을 수 있습니다. 이때 REST API로 현재 호가창의 전체 모습(Snapshot)을 단 한 번 조회하여 로컬 상태를 최신으로 맞춘 후, 다시 Websocket으로 실시간 변경분만 받아야 데이터의 정합성을 100% 보장할 수 있습니다.

### 6. WebSocket 연결 관리 매커니즘 (핵심 로직)

업비트 API 문서와 주신 피드백을 종합하여, 아래와 같이 2중으로 안정성을 확보하는 매커니즘을 구현합니다.

*   **1단계: 자동 Ping/Pong (Low-Level 연결 유지)**
    *   `websockets` 라이브러리는 `ping_interval` 및 `ping_timeout` 파라미터를 제공합니다. 이를 설정하면 라이브러리가 자동으로 주기적인 Ping 프레임을 서버로 보내고 Pong 응답을 확인하여 연결을 유지합니다. 이는 업비트 문서에서 언급된 **'연결 유지 방법 ①: Ping Frame (정석)'** 에 해당하며, 가장 효율적이고 안정적인 방법입니다.
    *   `ping_interval`은 업비트의 Idle Timeout (120초)보다 훨씬 짧은 **60초**로 설정하여 연결이 끊길 위험을 사전에 방지합니다.

*   **2단계: 자동 재연결 with Exponential Backoff (Application-Level 복원력)**
    *   네트워크 불안정, 서버 점검 등 다양한 이유로 연결은 **언제든지 끊어질 수 있다**는 것을 전제로 설계합니다.
    *   연결이 끊어지면(`websockets.exceptions.ConnectionClosed` 예외 발생), 애플리케이션은 즉시 재시도하는 대신 **'지수 백오프(Exponential Backoff)'** 전략을 사용합니다.
        1.  최초 연결 실패 시 1초 대기 후 재시도
        2.  또 실패 시 2초 대기 후 재시도
        3.  또 실패 시 4초 대기 후 재시도 (최대 60초까지 대기 시간 증가)
    *   이 방식은 서버에 과도한 부하를 주지 않으면서, 일시적인 장애로부터 안정적으로 복구할 수 있는 '매너 있는 재시도' 전략입니다.
    *   **상태 동기화:** 재연결 성공 직후에는 데이터 유실을 방지하기 위해, 구독 메시지를 다시 보내고, **특히 호가창 데이터의 경우 REST API를 통해 현재 스냅샷을 다시 조회하여 상태를 완전히 동기화**한 후에 실시간 스트림 처리를 재개합니다.


---

## 2. 데이터 스트리밍 계층 (Data Streaming Layer - Kafka) in detail 

### 1. 제1원칙: 왜 Kafka인가? - 단순한 파이프라인이 아닌 '금융 거래 기록원'

우리는 Kafka를 단순한 데이터 전달 파이프(Pipe)로 사용하지 않습니다. Kafka를 '모든 사건을 시간 순서대로 기록하는 불변의 거래 원장(Immutable Log)'으로 활용하는 것이 핵심 철학입니다.

- 완벽한 디커플링(Decoupling): 데이터 생산자(수집 계층)와 소비자(Flink 분석 계층, 주문 실행 계층)를 완벽하게 분리합니다. Flink 클러스터가 잠시 다운되어도, 데이터 수집기는 Kafka에 계속해서 데이터를 쌓을 수 있습니다. Flink가 복구되면, 중단됐던 시점부터 데이터를 정확히 다시 읽어와 처리할 수 있어 데이터 유실이 원천적으로 불가능해집니다.

- 데이터 재처리 및 백테스팅(Replayability): Kafka에 저장된 데이터는 사라지지 않습니다. 이는 엄청난 자산입니다. 새로운 매매 전략 로직을 개발했을 때, 과거의 특정 시점(e.g., 급등장)부터 데이터를 다시 재생(Replay)하여 새로운 전략이 과거에 어떻게 동작했을지 정확하게 시뮬레이션할 수 있습니다.

- 수평적 확장성(Horizontal Scalability): 미래에 거래량이 폭증하여 Flink 분석 서버가 느려진다면, 단순히 Flink 컨슈머의 수를 늘리는 것만으로 병렬 처리량을 손쉽게 늘릴 수 있습니다. Kafka의 파티션(Partition) 개념이 이를 가능하게 합니다.

### 2. Topic 아키텍처 설계: 데이터의 주소를 명확히 하라

시스템 아키텍처 문서에 따라, 각 데이터의 흐름과 목적에 맞게 Topic을 명확하게 분리하고, 일관된 명명 규칙을 적용합니다.
- 명명 규칙: {source}.{data_type}.{version} (e.g., upbit.trades.v1) - 버전 정보를 포함하여 향후 데이터 스키마 변경 시 유연하게 대응합니다.

핵심 Topic 설계:
- upbit.trades.v1: 업비트의 모든 체결(Trade) 데이터가 이 토픽으로 전송됩니다.
- upbit.orderbooks.v1: 업비트의 모든 호가창(OrderBook) 데이터가 이 토픽으로 전송됩니다.

파티셔닝 전략 (Partitioning Strategy) - 시스템 성능의 핵심:
- 원칙: '동일한 마켓(e.g., KRW-BTC)의 데이터는 반드시 동일한 파티션에 순서대로 저장되어야 한다.'
- 구현: 데이터 수집기(Python Producer)는 Kafka로 데이터를 전송할 때, 메시지의 'Key'를 마켓 코드(e.g., "KRW-BTC")로 지정해야 합니다. Kafka는 동일한 Key를 가진 메시지를 항상 동일한 파티션으로 보내는 것을 보장합니다.
- 왜 중요한가?: Flink는 이 파티션 단위로 데이터를 병렬 처리합니다. keyedStream("KRW-BTC")와 같은 Flink 로직이 올바르게 동작하려면, Kafka 단에서부터 KRW-BTC 관련 데이터(체결, 호가)가 한 줄로 순서대로 들어오는 것이 절대적으로 보장되어야 합니다. 이 전략이 없다면 Flink에서 데이터가 뒤섞여 분석 자체가 불가능해집니다.
- 파티션 수: 초기에는 마켓의 수(수십~수백 개)와 Flink 클러스터의 병렬성(Parallelism)을 고려하여 8 또는 16 정도로 설정하는 것이 적절합니다.

### 3. 데이터 무결성 및 성능 최적화 설정

Producer 설정 (데이터 수집기 측):
- acks=all: Producer가 보낸 메시지가 모든 복제본(Replicas)에 안전하게 저장되었음을 리더 브로커로부터 확인받은 후에야 전송 성공으로 간주합니다. 속도보다 데이터 무결성을 최우선으로 하는 금융 시스템에서는 타협 불가능한 옵션입니다.

- compression.type=zstd (또는 snappy): Protobuf로 1차 압축된 데이터를 Kafka로 전송하기 전에 한 번 더 압축합니다. CPU 자원을 약간 더 사용하는 대신, 네트워크 대역폭과 Kafka 브로커의 디스크 공간을 크게 절약하여 전체 처리량을 높이는 효과적인 트레이드오프입니다.

- linger.ms=5 및 batch.size=16384: 메시지를 즉시 보내지 않고, 5ms 동안 기다리거나 16KB가 모일 때까지 버퍼에 쌓아 한 번에 보냅니다. 이는 Kafka 브로커의 부하를 줄이고 전송 효율을 극대화하여 전체 처리량을 높입니다.

Broker 설정 (Kafka 서버 측):
- replication.factor=3: (프로덕션 환경 기준) Topic의 각 파티션이 3개의 복제본을 갖도록 설정합니다. 브로커 1대가 다운되어도 데이터 유실 없이 서비스를 계속할 수 있습니다. MVP 단계에서는 1로 설정하여 로컬에서 실행합니다.
- log.retention.hours=168: 데이터를 최소 7일간 보관하도록 설정합니다. 이는 백테스팅이나 장애 복구를 위한 충분한 시간을 제공합니다.

### 4. 스키마 관리: Confluent Schema Registry 도입

필요성: Producer가 실수로 잘못된 형식의 Protobuf 메시지를 Kafka에 보내는 것을 막는 '문지기' 역할을 합니다. Flink Consumer는 Schema Registry를 통해 올바른 스키마 정보를 조회하여 데이터를 안전하게 역직렬화할 수 있습니다.

동작 방식:
- Producer는 데이터를 보내기 전, 해당 데이터의 스키마를 Schema Registry에 등록/확인합니다.
승인되면, 데이터와 함께 스키마 ID만 Kafka에 전송합니다. (데이터 크기 감소)
- Consumer는 데이터를 읽을 때 스키마 ID를 보고 Schema Registry에 해당 스키마를 요청하여 데이터를 해석합니다.
- 이는 데이터 형식 불일치로 인한 런타임 에러를 원천적으로 방지하는 가장 강력하고 표준적인 방법입니다

### 5. 로컬 MVP 환경 구축 (docker-compose.yml)

쿠버네티스 없이, 로컬 환경에서 docker-compose up 명령어 하나로 전체 데이터 스트리밍 계층을 실행할 수 있도록 구성합니다. (Schema Registry 포함)

데이터 수집기(Python)와 Flink는 각각 localhost:9092 (Kafka)와 http://localhost:8081 (Schema Registry) 주소를 바라보게 설정하면 됩니다

--- 

## 3. 실시간 분석/신호 생성 계층 (CEP Layer - Flink) in detail 

### 1. 제1원칙: Flink를 사용하는 이유 - '시간'과 '상태'를 완벽하게 통제하기 위함

우리는 Flink를 단순 데이터 처리 툴이 아닌, '과거를 기억하고 현재를 분석하여 미래를 예측하는 시계열 분석 엔진'으로 활용합니다.
- 상태 기반 처리 (Stateful Processing): Flink의 가장 강력한 기능은 '상태(State)'를 완벽하게 관리하는 것입니다. "1분 전 호가창 상태", "지난 5초간의 평균 체결량"과 같은 과거의 모든 맥락을 Flink의 관리 하에 안전하게 저장하고 현재의 데이터와 비교 분석할 수 있습니다. 이는 '호가 밀도 변화율'이나 '평균 체결량 감소'와 같은 시간의 흐름에 따른 변화를 감지해야 하는 우리 전략의 핵심입니다.
- 이벤트 시간 처리 (Event Time Processing): 네트워크 지연 등으로 데이터가 뒤늦게 도착하더라도, Flink는 데이터가 '실제로 발생한 시간(Event Time)'을 기준으로 순서를 바로잡아 처리합니다. 이를 통해 네트워크 장애 상황에서도 분석의 시간적 정합성을 보장하여 잘못된 신호 생성을 방지합니다.
- 밀리초 단위의 저지연 처리: Flink는 인메모리(in-memory) 기반으로 데이터를 처리하여 들어오는 데이터에 즉각적으로 반응합니다. 이는 '찰나의 순간'을 포착해야 하는 우리 스캘핑 전략에 필수적인 요소입니다.


### 2. Flink Job 아키텍처: 역할을 분리하여 복잡성을 제어하라

단일 Flink Job에 모든 로직을 구현하는 것은 유지보수의 재앙을 초래합니다. 시스템 아키텍처 문서에 따라, 역할을 명확히 구분한 두 개의 독립적인 Flink Job으로 파이프라인을 구성합니다.

Job 1: MarketDataEnricher (데이터 전처리 및 보강 잡)
- 역할: Kafka로부터 원시 데이터를 받아, 분석에 용이한 형태로 데이터를 '정제'하고 '보강'하는 역할에만 집중합니다.
- Input: upbit.trades.v1, upbit.orderbooks.v1 Kafka Topics
- Logic:
    - (1) Deserialization: Kafka로부터 받은 Protobuf 바이너리 데이터를 Flink가 이해할 수 있는 데이터 객체(e.g., Python dataclass)로 역직렬화합니다. (Schema Registry 연동)
    - (2) Timestamp 할당: Flink가 이벤트 시간을 기준으로 동작할 수 있도록, 데이터에 포함된 trade_timestamp나 event_timestamp를 Flink의 공식 타임스탬프로 지정합니다.
    - (3) Keying: 모든 데이터를 code (마켓 코드, e.g., "KRW-BTC") 기준으로 keyBy 연산을 수행합니다. 이는 동일 마켓의 데이터가 항상 동일한 Flink Task Manager(작업자)에게 전달되도록 보장하여, 상태 기반 분석의 정합성을 유지하는 핵심 단계입니다.
- Output: 처리된 데이터를 내부 Kafka Topic(e.g., internal.enriched.trades.v1, internal.enriched.orderbooks.v1)으로 전달합니다. (※ MVP 단계에서는 이 Job을 생략하고 Signal Generation Job에서 직접 처리할 수도 있으나, 역할 분리 관점에서 이 구조를 권장합니다.)


Job 2: SignalGenerator (매매 신호 생성 잡)
- 역할: 전처리된 데이터를 바탕으로 기획서에 명시된 'P파(매수 신호)'와 '여진(매도 신호)' 탐지 로직을 수행하는 시스템의 핵심 두뇌입니다.
- Input: MarketDataEnricher로부터 받은 Kafka Topics (또는 원시 Kafka Topics)
- Logic: (아래 4번 항목에서 상세히 설명)
- Output: 생성된 매매 신호를 internal.signals.v1 Kafka Topic으로 전송합니다.

### 3. 데이터 흐름 및 상태 관리 설계 (방안 3: 하이브리드 CQRS + Reconciliation)

#### (1) Source: 3개 스트림 수신

```python
# 기존 시장 데이터
trade_stream = env.add_source(KafkaSource("upbit.trades.v1"))
orderbook_stream = env.add_source(KafkaSource("upbit.orderbooks.v1"))

# [NEW] 주문 실행 피드백 스트림
feedback_stream = env.add_source(KafkaSource("execution.feedback.v1"))

# [NEW] State 복원 스트림
restore_stream = env.add_source(KafkaSource("system.state.restore.v1"))
```

#### (2) Connect & KeyBy: 4개 스트림 연결

```python
trade_stream \
    .connect(orderbook_stream) \
    .connect(feedback_stream) \  # 추가
    .connect(restore_stream) \   # 추가
    .key_by(lambda x: x.code) \
    .process(SignalGeneratorWithFeedback())  # 확장된 ProcessFunction
```

#### (3) 확장된 ProcessFunction (매도 신호 처리 로직에도 TTL State 기록 추가)

```python
from pyflink.datastream.state import StateTtlConfig
from pyflink.common import Time

class SignalGeneratorWithFeedback(CoProcessFunction):
    
    def open(self, runtime_context):
        """Flink Job 시작 시 초기화 및 Bootstrap"""
        
        # 1. 활성 포지션 State (영구)
        self.active_positions = runtime_context.get_map_state(
            MapStateDescriptor("active_positions", Types.STRING(), Types.PICKLED_BYTE_ARRAY())
        )
        
        # 2. 최근 제거된 포지션 TTL State (30초)
        # → Stale 복원 방지를 위한 "최근 제거 블랙리스트"
        ttl_config = StateTtlConfig.new_builder(Time.seconds(30)) \
            .set_update_type(StateTtlConfig.UpdateType.OnCreateAndWrite) \
            .set_state_visibility(StateTtlConfig.StateVisibility.NeverReturnExpired) \
            .build()
        
        desc = MapStateDescriptor("recently_removed", Types.STRING(), Types.LONG())
        desc.enable_time_to_live(ttl_config)
        self.recently_removed_positions = runtime_context.get_map_state(desc)
        
        # 3. PostgreSQL에서 OPEN 포지션 Bootstrap
        if self.is_first_run():
            open_positions = self.load_open_positions_from_db()
            for pos in open_positions:
                self.active_positions.put(pos.code, pos)
            logger.info(f"✅ Bootstrapped {len(open_positions)} positions from PostgreSQL")
    
    def is_first_run(self) -> bool:
        """
        Flink State가 비어있는지 확인
        
        케이스:
        1. 완전 새로운 Job 시작
        2. Checkpoint 실패 후 재시작 (State 유실)
        """
        return self.active_positions.is_empty()
    
    def load_open_positions_from_db(self) -> List[PositionInfo]:
        """
        PostgreSQL에서 OPEN 포지션 로드
        
        주의: Flink의 open()에서 호출되므로 동기(sync) DB 드라이버 사용
        """
        import psycopg2
        
        conn = psycopg2.connect(os.getenv("DATABASE_URL"))
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT 
                tc.code,
                tc.entry_signal_id,
                s.reason as entry_reason,
                t.executed_price as entry_price,
                tc.entry_timestamp
            FROM trade_cycles tc
            JOIN trades t ON tc.entry_trade_id = t.id
            JOIN signals s ON tc.entry_signal_id = s.signal_id
            WHERE tc.status = 'OPEN'
        """)
        
        positions = []
        for row in cursor.fetchall():
            positions.append(PositionInfo(
                entry_signal_id=row[1],
                entry_reason=row[2],
                entry_price=row[3],
                entry_timestamp=row[4]
            ))
        
        conn.close()
        return positions
    
    def process_element1(self, trade, ctx):
        """거래 데이터 처리 (기존 로직)"""
        # P파 감지, 여진 감지 등...
        pass
    
    def process_element2(self, orderbook, ctx):
        """호가창 데이터 처리 (매도 신호 로직 + TTL State 기록)"""
        
        # ... P파 감지 로직 (생략) ...
        
        # 여진 감지 로직
        if 여진_조건_충족():
            code = orderbook.code
            position_info = self.active_positions.get(code)
            
            if position_info:
                # 1. 포지션 제거
                self.active_positions.remove(code)
                
                # 2. 👉 TTL State에 제거 이력 기록 (Stale 복원 방지)
                self.recently_removed_positions.put(code, ctx.timestamp())
                
                # 3. 매도 신호 발행
                ctx.output(signal_tag, TradingSignal(
                    signal_id=str(uuid.uuid4()),
                    code=code,
                    side="SELL",
                    reason="AFTERSHOCK_WAVE_DECAY",
                    price_at_signal=orderbook.asks[0].price,
                    signal_timestamp=ctx.timestamp()
                ))
    
    def process_element3(self, feedback: ExecutionFeedback, ctx):
        """주문 실행 피드백 처리 (주문 실패 시 즉시 State 정정)"""
        
        if feedback.status in ["FAILED", "TIMEOUT"]:
            code = feedback.code
            position_info = self.active_positions.get(code)
            
            if position_info:
                # 1. 포지션 제거
                self.active_positions.remove(code)
                
                # 2. 👉 TTL State에 제거 이력 기록
                self.recently_removed_positions.put(code, ctx.timestamp())
                
                logger.warning(
                    f"⚠️ Position removed due to execution failure: {feedback.signal_id}"
                )
                
                # 3. 시스템 이벤트 발행 (모니터링용)
                ctx.output(system_event_tag, SystemEvent(
                    event_type="POSITION_REMOVED_BY_FEEDBACK",
                    correlation_id=feedback.signal_id,
                    message=feedback.error_message
                ))
    
    def process_element4(self, restore_cmd: StateRestoreCommand, ctx):
        """State 복원 명령 처리 (이중 검증: TTL + Timestamp)"""
        
        code = restore_cmd.code
        
        # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
        # 1차 방어: 최근 제거 이력 확인 (Stale 복원 방지)
        # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
        removal_time = self.recently_removed_positions.get(code)
        
        if removal_time is not None:
            # 최근 30초 이내에 제거한 포지션
            time_since_removal = ctx.timestamp() - removal_time
            logger.warning(
                f"🚫 Stale restore rejected for {code}. "
                f"Removed {time_since_removal}ms ago. "
                f"Reason: {restore_cmd.restore_reason}"
            )
            return  # 복원하지 않음!
        
        # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
        # 2차 방어: Timestamp 비교
        # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
        current = self.active_positions.get(code)
        
        if current is None:
            # 정말 Flink가 모르는 포지션 → 안전하게 복원
            self.active_positions.put(code, restore_cmd.position_info)
            logger.info(f"✅ State restored: {code} - {restore_cmd.restore_reason}")
        else:
            # 이미 존재 → timestamp 비교하여 최신 것 유지
            if restore_cmd.position_info.entry_timestamp > current.entry_timestamp:
                self.active_positions.put(code, restore_cmd.position_info)
                logger.info(f"⚠️ State updated to newer version: {code}")
            else:
                logger.info(f"🚫 Restore ignored (Flink has newer/same data): {code}")
```



#### (4) State 관리:
- last_orderbook_state = ValueState\[OrderBookUpdate]: 직전 호가창 상태를 저장하여 현재와 비교합니다.
- recent_ask_volumes_state = ListState[Tuple[timestamp, volume]]: '호가 밀도 변화율' 계산을 위해 최근 1분간의 상위 N개 매도 호가 총량을 저장합니다.
- recent_trades_state = ListState\[Trade]: '평균 체결 거래량' 계산을 위해 최근 N초간의 체결 내역을 저장합니다.
- p_wave_detected_flag = ValueState\[Boolean]: 'P파'가 감지되었는지 여부를 저장하여, 이후 '여진' 분석 로직을 활성화하는 플래그로 사용합니다.
- active_positions = MapState[SignalReason, PositionInfo] ← 핵심 State

#### (5) Sink: KafkaSink를 통해 생성된 신호(Protobuf 객체)를 internal.signals.v1 토픽으로 전송합니다

- internal.signals.v1 토픽으로 전달되는 신호(Protobuf 객체)는 '주문 실행에 필요한 모든 정보를 담은 구조화된 데이터 패킷' 입니다. 주문 실행 계층이 이 신호 하나만 받으면, 다른 어떤 추가 정보 없이도 즉시 행동에 나설 수 있도록 설계되어야 합니다
- 이를 위해, 우리는 새로운 Protobuf 메시지 타입을 정의해야 합니다.

#### internal.signals.v1 : trading_signal.proto - 매매 신호 메시지 정의

```proto
syntax = "proto3";

import "google/protobuf/timestamp.proto";

package scalper;

// 매매 신호의 방향
enum SignalSide {
  SIDE_UNSPECIFIED = 0;
  BUY = 1;
  SELL = 2;
}

// 신호가 발생한 구체적인 이유 (기획서의 전략명과 1:1 매칭)
enum SignalReason {
  REASON_UNSPECIFIED = 0;
  
  // --- 매수 신호 (Entry Signals) ---
  P_WAVE_EARTHQUAKE_DETECTED = 1;   // "P파(지진) 감지": 호가창 진공 상태 + 스푸핑성 움직임 포착

  // --- 매도 신호 (Exit Signals) ---
  AFTERSHOCK_WAVE_DECAY = 2;        // "여진(파도 소멸) 감지": 평균 체결량 감소 + 호가 불균형 심화
  
  // --- 기타 (리스크 관리 등) ---
  STOP_LOSS_TRIGGERED = 3;          // "손절매": 리스크 관리 규칙에 의한 강제 청산
}

// Flink가 생성하여 주문 실행 계층으로 보내는 최종 매매 신호
message TradingSignal {
  // --- 신호의 핵심 정보 ---
  string signal_id = 1;             // 신호의 고유 ID (멱등성 보장)
  string code = 2;                  // 매매 대상 마켓 코드 (e.g., "KRW-BTC")
  SignalSide side = 3;              // 매매 방향 (BUY or SELL)
  
  // --- 신호의 근거 및 컨텍스트 ---
  SignalReason reason = 4;          // "왜?" - 기획서의 어떤 전략에 근거했는가
  double price_at_signal = 5;       // 신호 발생 시점의 기준 가격
  
  // --- 타임스탬프 및 메타데이터 ---
  google.protobuf/Timestamp signal_timestamp = 6; // Flink Job이 신호를 생성한 정확한 시각 (UTC)
}
```

#### execution_feedback.proto - 주문 실행 피드백 메시지

Execution Engine이 주문 실행 결과를 Flink에게 즉시 통지하기 위한 경량 메시지입니다.

```proto
syntax = "proto3";

import "google/protobuf/timestamp.proto";

package scalper;

// 주문 실행 피드백 메시지 (Flink State 동기화용)
message ExecutionFeedback {
  string signal_id = 1;                    // 원본 신호 ID
  string code = 2;                         // 마켓 코드 (Kafka 파티션 키)
  ExecutionFeedbackStatus status = 3;      // 실행 결과
  string error_message = 4;                // [실패 시] 에러 메시지
  google.protobuf.Timestamp feedback_timestamp = 5;
}

enum ExecutionFeedbackStatus {
  FEEDBACK_UNSPECIFIED = 0;
  SUCCESS = 1;                             // 주문 성공 → Flink는 포지션 유지
  FAILED = 2;                              // 주문 실패 → Flink는 포지션 제거
  TIMEOUT = 3;                             // 타임아웃 → Flink는 포지션 제거
}
```

**핵심 차이점:**
- `ExecutionResult`는 감사 추적용 (모든 정보 포함, DB 저장)
- `ExecutionFeedback`은 Flink State 동기화 전용 (최소 정보만, 빠른 처리)

#### state_restore_command.proto - State 복원 명령 메시지

Reconciliation Job이 Flink State를 복원하기 위한 명령 메시지입니다.

```proto
syntax = "proto3";

import "google/protobuf/timestamp.proto";
import "position_info.proto";

package scalper;

message StateRestoreCommand {
  string code = 1;                         // 복원할 마켓 코드
  PositionInfo position_info = 2;          // 복원할 포지션 정보
  RestoreReason restore_reason = 3;        // 복원 이유
  google.protobuf.Timestamp restore_timestamp = 4;
}

enum RestoreReason {
  RESTORE_REASON_UNSPECIFIED = 0;
  RECONCILIATION_DETECTED_MISSING = 1;     // Reconciliation이 누락 감지
  MANUAL_RESTORE = 2;                      // 관리자 수동 복원
  BOOTSTRAP_ON_STARTUP = 3;                // Flink 재시작 시 초기화
}
```

### 4. 핵심 분석 로직 상세 구현 계획 (PyFlink 기반)

SignalGenerator Job의 CoProcessFunction 내부 로직을 기획서의 전략에 따라 구체화합니다.

#### A. 매수 신호: 'P파(지진)' 감지 로직
- 전조 1: '호가 밀도 변화율' 계산
    - 입력: 새로운 OrderBookUpdate 메시지 수신 시
    - 계산:
        - 현재 메시지의 상위 N개(e.g., 10개) 매도 호가(asks)의 주문량 총합(current_total_ask_size)을 계산합니다.
        - recent_ask_volumes_state에서 지난 1분간의 데이터들을 가져와 평균(avg_ask_size_1min)을 계산합니다. (1분이 지난 데이터는 상태에서 제거)
        - 변화율: (1 - current_total_ask_size / avg_ask_size_1min) * 100
    - 상태 업데이트: 현재 호가 총량과 타임스탬프를 recent_ask_volumes_state에 추가합니다.
    - 판단: 변화율 > X% (e.g., 30%) 이면, P파 조건 1을 충족한 것으로 내부 플래그를 설정합니다.

- 전조 2: '스푸핑성 주문' 감지 (현실적 재해석)
    - 문제점: 업비트 WebSocket은 개별 호가 주문의 ID를 제공하지 않으므로, 기획서의 '주문이 생성되었다가 취소되는 빈도'를 문자 그대로 추적하는 것은 불가능합니다.
    - 대안 (Proxy Metric): '특정 호가의 비정상적 유동성 변화' 를 탐지하는 것으로 재해석합니다. 즉, 특정 가격대에 갑자기 큰 물량이 나타났다가 짧은 시간 내에 사라지는 현상을 포착합니다.
    - 입력: 새로운 OrderBookUpdate 메시지 수신 시
    - 로직:
        - last_orderbook_state의 호가와 현재 호가를 비교하여, 특정 가격(price)에 이전에는 없던 큰 규모(> 전체 호가 잔량의 5%)의 주문량(size)이 새로 나타난 것을 감지합니다.
        - 해당 price를 키로 하여 Flink의 타이머(Timer)를 Y초(e.g., 1.5초) 뒤에 실행되도록 등록하고, MapState에 {price: size} 형태로 저장합니다.
        - 타이머 실행 시:
            - 현재 호가창을 다시 확인하여, 해당 price의 주문량이 대부분 사라졌는지 검증합니다.
            - 사라졌다면 '스푸핑 이벤트'로 간주하고, P파 조건 2를 충족한 것으로 내부 플래그를 설정합니다.

- 최종 매수 신호 생성:
    - IF (P파 조건 1 충족) AND (P파 조건 2 충족) 이 되면, 매수 신호를 발생시킴: 
        - SignalGenerator Job이 'P파(지진)'를 감지하여 매수 신호(TradingSignal)를 생성합니다.
        - 동시에, 'KRW-BTC'의 MapState(flink의 MapState) 에 새로운 엔트리를 추가합니다. `active_positions = MapState[SignalReason, PositionInfo]`
            - 이 MapState는 각 코인별로 존재하며, 다음과 같은 구조를 가집니다.
            - Key: SignalReason (Enum) - 포지션을 오픈시킨 매수 전략의 종류 (e.g., P_WAVE_EARTHQUAKE_DETECTED)
            - Value: PositionInfo (객체) - 해당 포지션의 상세 정보를 담은 객체 (아래 position_info.proto 참고)
        - active_positions.put(SignalReason.P_WAVE_EARTHQUAKE_DETECTED, new_position_info)
        - new_position_info 객체에는 진입 가격, 시각 등의 모든 컨텍스트가 기록됩니다.

#### position_info.proto - 포지션 정보 메시지 정의

```proto
syntax = "proto3";

import "google/protobuf/timestamp.proto";
import "trading_signal.proto"; // SignalReason enum 재사용

package scalper;

// 개별 포지션의 상세 정보를 담는 객체
message PositionInfo {
  string entry_signal_id = 1;       // 이 포지션을 열게 한 매수 신호의 고유 ID
  SignalReason entry_reason = 2;    // 포지션 진입 이유 (매수 전략)
  double entry_price = 3;           // 진입 시점의 기준 가격
  google.protobuf.Timestamp entry_timestamp = 4; // Flink가 포지션 진입을 인지한 시각
  // 추후 필요한 필드 추가 가능 (e.g., 진입 수량)
}
```

#### B. 매도 신호: '여진(파도 소멸)' 감지 로직

이 로직은 Flink의 Keyed State인 active_positions 맵에 현재 처리 중인 전략과 짝이 맞는 '포지션 정보(PositionInfo)'가 기록되어 있을 때 활성화가 됨. 

- 주의 : 결론부터 말씀드리면, active_positions 전역 변수가 아니라, 각 코인별로 독립적으로 존재하는 수백 개의 '개별 상태 저장소'입니다.
- 상태의 격리(State Isolation)는 어떻게 이루어지는가? 핵심은 keyBy('code') 연산에 있음. 

코드로 포현한 매도 로직 실행문 
```python
 # CoProcessFunction 내부 (의사 코드)
 ...    
    # '여진(파도 소멸)' 매도 로직
    if active_positions.contains(SignalReason.P_WAVE_EARTHQUAKE_DETECTED):
        # 열쇠가 있으니, 문을 열고 매도 로직을 실행한다.
        position_info = active_positions.get(SignalReason.P_WAVE_EARTHQUAKE_DETECTED)
        # ... (평균 체결량 감소, 호가 불균형 심화 등) ...
```

전조 1: '평균 체결 거래량의 감소' 추적
    - 구현: Flink의 Sliding Window를 사용합니다.
    - 입력: Trade 스트림
    - Window 설정: TumblingEventTimeWindows.of(Time.seconds(3)) 또는 SlidingEventTimeWindows.of(Time.seconds(5), Time.seconds(1)) (5초 크기, 1초 간격)
    - 계산: 각 윈도우 내 trade_volume의 평균을 계산합니다.
    - 판단: ValueState에 저장된 직전 윈도우의 평균값과 비교하여, 평균 체결량이 감소 추세로 전환되었는지 확인합니다. (e.g., 2회 연속 감소)
- 전조 2: '상대 호가 대비 불균형 심화' 감지
    - 입력: 새로운 OrderBookUpdate 메시지 수신 시
    - 계산: 현재가 위 N개 호가의 총 매도 잔량(total_ask_size)과 아래 N개 호가의 총 매수 잔량(total_bid_size)의 비율(imbalance_ratio = total_ask_size / total_bid_size)을 계산합니다.
    - 판단: imbalance_ratio > N (e.g., 2.0) 이면, 매도 압력이 우세해진 것으로 판단합니다.

- 최종 매도 신호 생성:
    - IF (평균 체결량 감소 추세) AND (호가 불균형 심화) 조건이 충족되면, active_positions 맵에서 P_WAVE_EARTHQUAKE_DETECTED 키와 값을 제거하고 매도 신호를 internal.signals.v1 토픽으로 전송합니다.

#### 주의 : 스트림 처리는 모든 코인에 대한 하나의 통일된 데이터 스트림으로 흐른다. 

결론부터 말씀드리면, "매수/매도에 대한 독립적인 스트림이 있는 것"도 아니고, "매수 스트림이 실행된 후 바로 매도 스트림이 실행되는 것"도 아닙니다.

정확한 모델은 "모든 코인에 대한 하나의 통일된 데이터 스트림이 계속 흐르고 있고, 그 스트림을 처리하는 우리의 로직(ProcessFunction)이 '현재 상태(State)'에 따라 행동을 바꾸는 것" 입니다.

코인별 '담당자'를 상상해 보십시오
- 이 개념을 이해하는 가장 좋은 방법은 Flink의 CoProcessFunction을 각 코인별로 배정된, 24시간 깨어있는 '담당자(또는 경비원)' 라고 상상하는 것입니다.
- 우리에게는 "KRW-BTC 담당자", "KRW-ETH 담당자" 등 수백 명의 담당자가 있습니다.
- 모든 trade와 orderbook 데이터는 거대한 컨베이어 벨트를 타고 흘러갑니다.
- 각 담당자는 컨베이어 벨트에서 오직 자기 담당 코인의 데이터만 집어서 확인합니다. (이것이 keyBy('code')의 역할입니다.)
- 이 '담당자'는 두 가지 행동 모드를 가집니다.
    - '대기 상태 (Scanning Mode)': 포지션이 없는 평상시 모드
    - '추적 상태 (Tracking Mode)': 매수 신호 이후 포지션을 보유한 모드

--- 
## 4. 주문 실행 계층 (Order Execution Layer) in detail 

이 계층의 설계는 단 하나의 실수가 곧 실제 자산의 손실로 이어지기 때문에, '속도' 만큼이나 '극도의 안정성'과 '방어적 설계'가 무엇보다 중요합니다. Flink가 아무리 훌륭한 신호를 1ms 만에 만들어내도, 이 계층이 찰나의 순간에 머뭇거리거나, 같은 주문을 두 번 내거나, 비정상적인 가격에 주문을 체결시킨다면 모든 것이 수포로 돌아갑니다.

### 1. 제1원칙: "절대, 절대로 돈을 잃게 만들지 마라"

주문 실행 계층은 세 가지 원칙을 반드시 지켜야 합니다.
- 멱등성 (Idempotency): "같은 매수 신호를 100번 받아도, 주문은 반드시 단 한 번만 실행되어야 한다."  Kafka의 재처리나 프로세스 장애 등 어떤 상황에서도, 하나의 매매 신호는 반드시 단 한 번의 주문 실행으로 이어져야 합니다. 이를 위해 거래소(Upbit)가 제공하는 identifier 기반 멱등성 보장 기능을 시스템의 유일하고 절대적인 Source of Truth로 삼습니다.
- 장애 허용 (Fault-Tolerant): "Flink 분석 클러스터가 불타 없어져도, 이미 접수된 주문은 절대 꼬여서는 안 된다." 주문 실행 계층은 Flink와 Kafka를 통해 완벽하게 비동기적으로 분리되어, 분석 계층의 장애가 주문 실행의 안정성에 영향을 미치지 않도록 해야 합니다. 특정 신호 처리에 실패하더라도(e.g., 업비트 API 일시 장애), 해당 메시지는 일부 재시도 이후 계속해서 실패한다면(2회 이상) Dead Letter Queue(DLQ)로 보내져야 합니다. 이를 통해 실패한 메시지 하나가 전체 주문 실행 파이프라인을 막는 것을 방지합니다.
- 최종 방어선 (Last Line of Defense): "상식 밖의 신호는 거부해야 한다." Flink가 보낸 신호가 명백히 비정상적일 경우(e.g., 시장가보다 10% 높은 가격의 매수 신호), 이를 그대로 실행하는 것이 아니라 시스템을 보호하기 위해 주문을 거부하고 경고를 발생시켜야 합니다.
- 순차 처리 보장 (Sequential Processing): Kafka 파티션은 단일 Consumer 스레드에 의해 순서대로 처리되는 특성을 가집니다. 이는 별도의 분산 잠금(Distributed Lock) 없이도 동일 마켓에 대한 신호들이 순차적으로 처리됨을 보장하여, 동시성 문제를 원천적으로 방지합니다.

### 2. 기술 스택 및 아키텍처

언어 및 라이브러리:
- Python & asyncio: 빠른 개발 속도와 비동기 네트워크 처리에 대한 성숙한 생태계를 고려하여 Python을 채택합니다.
- Kafka Consumer: confluent-kafka 라이브러리를 사용하여 internal.signals.v1 토픽을 비동기적으로 구독합니다.
- Exchange API Client: pyupbit 또는 ccxt와 같은 검증된 비공식 라이브러리를 사용하되, REST API 요청 부분은 aiohttp를 사용하여 직접 구현하여 완전한 비동기 처리를 보장하는 것을 권장합니다.

### 컴포넌트 아키텍처: 주문 실행 계층은 하나의 독립된 Python 애플리케이션(마이크로서비스)으로, 내부는 다음과 같이 구성됩니다.

- Kafka Signal Consumer: internal.signals.v1 토픽을 구독하여 TradingSignal 메시지를 지속적으로 수신합니다.
- Pre-execution Validator (사전 실행 검증기): 리스크 관리 규칙 및 신호의 유효 시간(freshness)에 따라 주문 실행 여부를 최종 판단합니다.
- Idempotency Exchange API Gateway: 실제 거래소(업비트)의 Private API와 통신하여 주문을 생성/조회/취소합니다. 업비트의 identifier를 활용하여 모든 주문이 단 한 번만 실행되도록 보장하는 핵심 로직을 수행합니다.
- Result Publisher & DLQ Handler:: 주문 실행 결과를 execution.results.v1 Kafka 토픽으로 전송하여 모든 활동을 기록으로 남깁니다. Kafka 장애 시에는 파일 로그 등 비상 채널에 기록하고 알림을 발생시키는 폴백 로직을 포함합니다.
    - (구매는 했는데 Publish 에 실패한다면)

### 3. 장애 대응 철학: "진입은 엄격하게, 청산은 어떻게든"

모든 자동화 시스템은 장애가 발생할 수 있다는 것을 전제로 설계되어야 합니다. 특히 주문 실행 중 발생하는 장애는 자산에 직접적인 영향을 미치므로, 매수(진입)와 매도(청산)의 장애 대응 전략을 명확히 분리합니다.

#### 진입(Entry) 시나리오: 안전하게 포기 (Fail-Safe)

스캘핑에서 진입 타이밍은 절대적입니다. 프로세스 재시작 등으로 인해 신호 발생 후 수십 초(예: 20초)가 지연되었다면, 이미 기회는 사라진 것입니다.

원칙: 불확실하거나 지연된 진입 신호는 과감히 포기합니다. 기회를 놓치는 비용(Opportunity Cost)이 잘못된 진입으로 인한 실제 손실보다 낫습니다.

#### 청산(Exit) 시나리오: 어떻게든 실행 (Fail-Fast & Retry)

일단 포지션을 보유하면, 시장 변동성 리스크에 직접 노출됩니다. 따라서 청산 신호는 어떻게든 실행되어야 합니다.

원칙: API 타임아웃 발생 시 즉시 재시도하고, 반복된 실패시에는 해당 신호를 DLQ로 보내어 관리자의 즉각적인 수동 개입을 유도합니다. 

### 4. 핵심 로직 상세 구현 계획: Kafka와 Upbit API를 이용한 단일 책임 설계

전제 조건: 
- 업비트 주문 API 호출 시, identifier 필드에 TradingSignal의 signal_id를 반드시 포함시켜야 합니다.
- Kafka의 internal.signals.v1 토픽은 code(마켓 코드)로 파티셔닝되어, 동일 마켓의 신호는 항상 동일 Consumer가 순서대로 처리함을 보장합니다.
- MVP 버전에서는 50,000원만이 가용된 자산이라고 생각하고 운용하라. 

#### (1) [수신 및 유효 시간 검사]

\[수신] Kafka Signal Consumer가 TradingSignal 메시지를 받습니다.

Protobuf 메시지를 역직렬화하여 TradingSignal 객체로 변환합니다.

TradingSignal 의 signal_timestamp를 현재 시간과 비교합니다. IF (now() - signal_timestamp) > 20 seconds 이고 매수 신호라면, "신호가 너무 오래됨"으로 판단하고 처리를 포기합니다.

#### (2) [사전 검증]

최대 포지션 한도, Slippage 보호(price_at_signal과 현재 호가 비교) 등 리스크 관리 규칙을 검증합니다. 실패 시 ExecutionResult 를 만들어서 결과를 보고합니다. 
- 매수 신호의 경우: price_at_signal이 현재 REST API로 조회한 최우선 매도호가(best_ask_price)보다 비정상적으로 높은지(e.g., 2% 이상) 확인합니다.
- 매도 신호의 경우: price_at_signal이 현재 최우선 매수호가(best_bid_price)보다 비정상적으로 낮은지 확인합니다.
- 검증 실패 시: 주문을 실행하지 않고, 실패 사유를 담은 결과를 execution.results.v1 토픽으로 전송하고 치명적인 에러 로그를 남깁니다.

#### (3) [주문 실행] Exchange API Gateway가 실제 주문을 전송합니다. (DLQ 처리 포함)

- 주문 종류: 기획서의 전략상 '즉각적인 추격'이 핵심이므로, 시장가(Market Order) 주문을 사용하는 것이 기본 원칙입니다. (시장가 매수: market, 시장가 매도: ask)
- API 호출: 업비트의 주문 API 엔드포인트에 aiohttp를 사용하여 비동기적으로 POST 요청을 보냅니다. API 키 인증 헤더를 포함해야 하며, 멱등성 API 실행을 위해 identifier 를 요청 본문(body) 에 꼭 포함해야합니다.  
- 타임아웃: 모든 API 요청에는 짧은 타임아웃(e.g., 2초)을 설정하여, 거래소 API 응답 지연이 전체 시스템을 마비시키는 것을 방지합니다.
- 멱등성 결과 처리: 
    - 201 Created: 가장 일반적인 매수/매도 성공 케이스입니다.
    - 409 Conflict: 이 응답을 받았다는 것은 "이전 프로세스가 주문에는 성공했지만, 뒷정리를 못하고 죽었다"는 것을 100% 확신할 수 있는 증거입니다. 따라서 현재 프로세스는 주문을 보내지 않고, 대신 이전 주문의 결과를 조회하여 시스템의 상태를 정상적으로 복구하고 이어서 재개하면 됩니다. 

- DLQ 처리: 
    - 업비트 서버 자체의 문제(5xx 에러)나 네트워크 문제로 인해 반복적으로 주문 실행에 실패하는 경우, 해당 메시지는 무한정 재시도되며 전체 시스템을 지연시킬 수 있습니다. 이를 방지하기 위해, 몇 번의 재시도 후에도 실패하는 메시지는 Dead Letter Queue(DLQ) 로 격리하여 개발자의 수동 분석을 기다리게 하고, 메인 Consumer는 다음 메시지를 처리하러 넘어갑니다.

#### (4) [피드백 및 결과 발행] - Flink State 동기화의 핵심

주문 실행 직후, **2개의 메시지를 순차적으로 발행**합니다.

**4-1. 즉시 피드백 발행 (Fast Path - Flink State 동기화)**

```python
async def handle_signal(signal: TradingSignal):
    """매매 신호 처리 및 이중 발행 로직"""
    
    try:
        # 1. 주문 실행
        order_response = await upbit_api.place_order(
            market=signal.code,
            side="bid" if signal.side == "BUY" else "ask",
            price=None,  # 시장가
            identifier=signal.signal_id  # 멱등성 보장
        )
        
        # 2-A. 👉 즉시 피드백 발행 (Flink용, 20-50ms 목표)
        feedback = ExecutionFeedback(
            signal_id=signal.signal_id,
            code=signal.code,
            status=ExecutionFeedbackStatus.SUCCESS,
            feedback_timestamp=Timestamp().GetCurrentTime()
        )
        
        await kafka_producer.send(
            topic="execution.feedback.v1",
            key=signal.code.encode('utf-8'),  # 파티션 키
            value=feedback.SerializeToString()
        )
        
        logger.info(f"✅ Feedback published for {signal.signal_id}")
        
        # 2-B. 상세 결과 발행 (Archivist용, 감사 추적)
        result = ExecutionResult(
            result_id=str(uuid.uuid4()),
            original_signal=signal,
            status=ExecutionStatus.SUCCESS,
            exchange_order_id=order_response['uuid'],
            executed_price=order_response['price'],
            executed_volume=order_response['volume'],
            fee=order_response['paid_fee'],
            execution_timestamp=Timestamp().GetCurrentTime()
        )
        
        await kafka_producer.send(
            topic="execution.results.v1",
            key=signal.code.encode('utf-8'),
            value=result.SerializeToString()
        )
        
        logger.info(f"📊 Result published for {signal.signal_id}")
        
    except InsufficientFundsError as e:
        # 주문 실패 - 피드백 필수!
        feedback = ExecutionFeedback(
            signal_id=signal.signal_id,
            code=signal.code,
            status=ExecutionFeedbackStatus.FAILED,
            error_message=f"Insufficient funds: {str(e)}",
            feedback_timestamp=Timestamp().GetCurrentTime()
        )
        
        await kafka_producer.send(
            topic="execution.feedback.v1",
            key=signal.code.encode('utf-8'),
            value=feedback.SerializeToString()
        )
        
        logger.error(f"❌ Order failed, feedback published: {signal.signal_id}")
        
        # 실패 결과도 기록
        result = ExecutionResult(
            result_id=str(uuid.uuid4()),
            original_signal=signal,
            status=ExecutionStatus.VALIDATION_FAILED,
            error_message=str(e),
            execution_timestamp=Timestamp().GetCurrentTime()
        )
        
        await kafka_producer.send(
            topic="execution.results.v1",
            key=signal.code.encode('utf-8'),
            value=result.SerializeToString()
        )
```

**핵심 차이점:**
- `execution.feedback.v1`: **최소 정보**, 즉시 발행, **Flink State 동기화 전용** (20-50ms 목표)
- `execution.results.v1`: 전체 정보, 감사 추적, PostgreSQL 영구 저장용 (수백 ms 허용)

**왜 2개로 분리?**
1. **지연 최소화**: Flink는 피드백만 빠르게 받아 State 정정 (저지연)
2. **감사 완전성**: Archivist는 상세 정보를 DB에 저장 (완전성)
3. **책임 분리**: Flink는 실시간, PostgreSQL은 영구 보관

**발행 순서가 중요한 이유:**
```python
# ✅ 올바른 순서
await send_feedback()   # 먼저 Flink에게 알림
await send_result()     # 그 다음 감사 기록

# ❌ 잘못된 순서
await send_result()     # Archivist가 먼저 받으면
await send_feedback()   # Flink가 늦게 알게 됨 (수십 ms 손해)
```

#### (4-2) [상세 결과 기록]

거래소로부터 받은 체결 결과를 바탕으로 ExecutionResult 메시지를 생성하여 execution.results.v1 Kafka 토픽으로 발행합니다. (위 코드의 2-B 단계 참조)

### (5). 데이터 정합성 보장: Transactional 처리

ExecutionResult 메시지가 Kafka에 중복 발행될 수 있는 미세한 엣지 케이스가 존재합니다. (주문에 성공한 프로세스가 긴 GC 로 인해서 프로세스 A 컨슈머가 리밸런싱되어서 프로세스 B도 주문 작업을 시작하는 경우)

해결책 (Kafka Transactional Producer): 신호 메시지의 소비(offset commit)와 결과 메시지의 발행(produce)을 하나의 원자적 트랜잭션으로 묶어, Exactly-Once Semantics를 보장하는 가장 완벽한 방법입니다.

(추가) (DB UNIQUE 제약): 최종 저장소인 PostgreSQL의 trade_log 테이블에 original_signal_id 컬럼을 만들고 UNIQUE 제약 조건을 설정합니다. 이를 통해 Kafka에 중복 메시지가 있더라도 최종 데이터베이스에는 단 하나의 레코드만 저장되도록 보장할 수 있습니다. 

### 6. ExecutionResult Protobuf 스키마 정의 및 결과 기록 

Result Publisher가 실행 결과를 Kafka에 기록합니다.

- API 호출의 성공/실패 여부, 성공 시 반환된 주문 ID(uuid), 실패 시 에러 메시지 등을 포함한 ExecutionResult Protobuf 객체를 생성합니다.
- 이 객체를 execution.results.v1 토픽으로 전송합니다. 이 토픽의 데이터는 최종적으로 PostgreSQL의 trade_log 테이블에 영구 저장되어 모든 거래의 감사 추적(Audit Trail) 기반이 됩니다.

주문 실행의 모든 결과를 담을 execution_result.proto 파일을 정의합니다.

```proto
syntax = "proto3";

import "google/protobuf/timestamp.proto";
import "trading_signal.proto"; // TradingSignal 재사용

package scalper;

enum ExecutionStatus {
  STATUS_UNSPECIFIED = 0;
  SUCCESS = 1;              // 주문 성공
  VALIDATION_FAILED = 2;    // 사전 검증 실패 (리스크 관리)
  IDEMPOTENCY_REJECTED = 3; // 멱등성 검사 거부 (중복 신호)
  API_ERROR = 4;            // 거래소 API 에러
  TIMEOUT_ERROR = 5;        // 거래소 API 타임아웃
  SIGNAL_TOO_OLD = 6;       // 신호가 너무 오래되어 포기
}

message ExecutionResult {
  string result_id = 1;                   // 결과 고유 ID (UUID)
  TradingSignal original_signal = 2;      // 이 결과를 만든 원본 매매 신호
  
  ExecutionStatus status = 3;             // 실행 결과 상태
  string exchange_order_id = 4;           // [성공 시] 거래소가 부여한 주문 ID (uuid)
  
  // --- [성공 시] 기록되는 상세 체결 정보 ---
  double executed_price = 5;              // 실제 평균 체결 가격
  double executed_volume = 6;             // 실제 체결 수량
  double fee = 7;                         // 발생한 수수료
  
  string error_message = 8;               // [실패 시] 상세 에러 메시지
  google.protobuf.Timestamp execution_timestamp = 9; // 주문 실행 계층이 작업을 완료한 시각
}
```

시스템 장애로붜터 복구하고 데이터 정합성을 지키는 방법

가장 중요한 시나리오는 바로 멱등성(Idempotency) 처리 중 409 Conflict 에러를 만났을 때입니다.

상황을 단계별로 재구성해 보겠습니다.
- 1. [신호 수신] Execution Engine의 A라는 프로세스가 Kafka로부터 signal-123이라는 매수 신호를 받습니다.
- 2. [주문 시도] A 프로세스는 identifier를 "signal-123"으로 설정하여 업비트에 시장가 매수 주문을 보냅니다.
- 3. [주문 성공] 업비트 서버는 이 주문을 성공적으로 접수하고 체결시킵니다.
- 4. [프로세스 사망] 그런데 A 프로세스가 업비트로부터 201 Created 성공 응답을 받은 직후, 아직 그 성공 결과를 Kafka(execution-results 토픽)에 기록하기 전에 치명적인 장애로 갑자기 죽어버립니다.
- 5. [신호 재처리] Kafka 컨슈머 그룹의 리밸런싱에 의해, Execution Engine의 B라는 다른 프로세스가 아직 처리 완료(offset commit)되지 않은 signal-123 신호를 다시 가져옵니다.
- 6. [중복 주문 시도] B 프로세스는 이 신호가 처음 처리되는 줄 알고, 똑같이 identifier를 "signal-123"으로 설정하여 업비트에 매수 주문을 다시 보냅니다.
- 7. [멱등성 방어] 업비트 서버는 "어? signal-123은 아까 이미 처리된 주문인데?"라고 인지하고, 중복 주문을 막기 위해 409 Conflict 에러를 B 프로세스에게 반환합니다.
- 바로 이 8단계에서 '개별 주문 조회'가 등장합니다.
- 8. [상태 확인 및 복구] B 프로세스는 409 Conflict를 받음으로써 "주문이 중복된 것은 확실한데, 그래서 원래 주문이 어떻게 됐지?" 라는 사실을 알아내야 합니다. B는 이제 주문 생성을 멈추고, 대신 개별 주문 조회 API를 호출하여 identifier가 "signal-123"인 주문의 현재 상태를 업비트에 직접 물어봅니다.
- 9. [결과 획득] 업비트는 "그 주문은 이미 체결 완료(state: done)되었고, 체결가는 50,000원, 체결량은 0.1개야" 라는 상세 정보를 반환합니다.
- 10. [최종 처리] B 프로세스는 이 조회된 결과를 가지고, 마치 자기가 직접 주문해서 성공한 것처럼 ExecutionResult 메시지를 만들어 execution-results 토픽에 발행합니다. 


---

## 4.5. Reconciliation Job - State 동기화의 안전망 (독립 서비스)

### 1. 제1원칙: "믿되, 검증하라 (Trust, but Verify)"

Execution Feedback Loop(Fast Path)가 99.9%의 State 불일치를 실시간으로 해결하지만, 네트워크 장애, Flink 재시작, 극히 드문 버그로 인해 피드백이 누락될 수 있습니다. Reconciliation Job은 이러한 0.1%의 edge case를 처리하는 **최후의 안전망**입니다.

### 2. 아키텍처: 독립적인 Python 마이크로서비스

**기술 스택:**
- 언어: Python 3.11+ (asyncio 기반)
- 라이브러리: 
  - `asyncpg`: PostgreSQL 비동기 드라이버
  - `confluent-kafka`: Kafka Producer
  - `APScheduler`: 주기적 작업 스케줄링

**배포:**
- Docker 컨테이너로 패키징
- Flink/Kafka 클러스터와 완전히 독립
- 단일 인스턴스 실행 (분산 잠금 불필요)

### 3. 핵심 로직: 10초 주기 검증 루프

```python
import asyncio
import asyncpg
from confluent_kafka import Producer
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)

class ReconciliationJob:
    def __init__(self, db_pool: asyncpg.Pool, kafka_producer: Producer):
        self.db = db_pool
        self.kafka = kafka_producer
    
    async def run_reconciliation_loop(self):
        """10초마다 실행되는 메인 루프"""
        while True:
            try:
                await asyncio.sleep(10)  # 10초 대기
                await self.check_and_restore()
            except Exception as e:
                logger.error(f"Reconciliation error: {e}")
    
    async def check_and_restore(self):
        """불일치 감지 및 복원 명령 발행"""
        
        # 1️⃣ PostgreSQL에서 OPEN 포지션 조회
        open_positions = await self.db.fetch("""
            SELECT 
                tc.code,
                tc.entry_signal_id,
                s.reason as entry_reason,
                t.executed_price as entry_price,
                tc.entry_timestamp
            FROM trade_cycles tc
            JOIN trades t ON tc.entry_trade_id = t.id
            JOIN signals s ON tc.entry_signal_id = s.signal_id
            WHERE tc.status = 'OPEN'
        """)
        
        logger.info(f"📊 Found {len(open_positions)} OPEN positions in PostgreSQL")
        
        for position in open_positions:
            # 2️⃣ 최근 활동 확인 (False Positive 방지)
            recent_exit_signal = await self.db.fetchrow("""
                SELECT signal_id 
                FROM signals 
                WHERE code = $1 
                  AND side = 'SELL'
                  AND signal_timestamp > NOW() - INTERVAL '10 seconds'
            """, position['code'])
            
            if recent_exit_signal:
                # 최근에 매도 신호가 발생했음 → 곧 CLOSE될 예정
                logger.debug(f"⏳ {position['code']}: Recent EXIT signal detected, skipping")
                continue
            
            # 3️⃣ 오래된 포지션인지 확인 (>1분)
            position_age = datetime.utcnow() - position['entry_timestamp']
            
            if position_age.total_seconds() < 60:
                # 1분 이내 신규 포지션 → Flink가 아직 처리 중일 수 있음
                logger.debug(f"🆕 {position['code']}: Too recent ({position_age}s), skipping")
                continue
            
            # 4️⃣ 불일치 감지 → 복원 명령 발행
            logger.warning(
                f"🚨 Detected missing position in Flink: {position['code']} "
                f"(age: {position_age})"
            )
            
            await self.publish_restore_command(position)
    
    async def publish_restore_command(self, position):
        """system.state.restore.v1 토픽으로 복원 명령 발행"""
        
        from scalper_pb2 import StateRestoreCommand, PositionInfo, RestoreReason
        from google.protobuf.timestamp_pb2 import Timestamp
        
        # Protobuf 메시지 생성
        position_info = PositionInfo(
            entry_signal_id=position['entry_signal_id'],
            entry_reason=position['entry_reason'],
            entry_price=position['entry_price'],
            entry_timestamp=self._to_protobuf_timestamp(position['entry_timestamp'])
        )
        
        restore_cmd = StateRestoreCommand(
            code=position['code'],
            position_info=position_info,
            restore_reason=RestoreReason.RECONCILIATION_DETECTED_MISSING,
            restore_timestamp=self._to_protobuf_timestamp(datetime.utcnow())
        )
        
        # Kafka 발행
        self.kafka.produce(
            topic='system.state.restore.v1',
            key=position['code'].encode('utf-8'),  # 파티션 키
            value=restore_cmd.SerializeToString(),
            callback=self._delivery_callback
        )
        
        self.kafka.flush()
        
        logger.info(f"✅ Restore command published for {position['code']}")
    
    def _delivery_callback(self, err, msg):
        """Kafka 발행 결과 확인"""
        if err:
            logger.error(f"❌ Failed to publish restore command: {err}")
        else:
            logger.debug(f"📨 Restore command delivered to partition {msg.partition()}")
    
    def _to_protobuf_timestamp(self, dt: datetime) -> Timestamp:
        """Python datetime → Protobuf Timestamp 변환"""
        ts = Timestamp()
        ts.FromDatetime(dt)
        return ts


# 실행 엔트리포인트
async def main():
    # PostgreSQL 연결 풀 생성
    db_pool = await asyncpg.create_pool(
        dsn=os.getenv("DATABASE_URL"),
        min_size=1,
        max_size=3
    )
    
    # Kafka Producer 생성
    kafka_producer = Producer({
        'bootstrap.servers': os.getenv("KAFKA_BROKERS", "localhost:9092"),
        'client.id': 'reconciliation-job'
    })
    
    # Reconciliation Job 시작
    job = ReconciliationJob(db_pool, kafka_producer)
    
    logger.info("🚀 Reconciliation Job started (interval: 10s)")
    
    await job.run_reconciliation_loop()


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(main())
```

### 4. 동작 시나리오

#### 시나리오 1: 정상 운영 (메시지 발행 없음)

```
T+0s:   Reconciliation 실행
        → PostgreSQL: 5개 OPEN 포지션
        → 모두 최근 10초 내 활동 확인됨
        → 판단: "정상"
        → 결과: 아무것도 안 함 ✅

T+10s:  Reconciliation 실행
        → PostgreSQL: 4개 OPEN (1개 닫힘)
        → 모두 정상
        → 결과: 아무것도 안 함 ✅

발행된 메시지: 0건
```

#### 시나리오 2: Flink 재시작 후 State 유실

```
T+0s:   Flink 정상 운영
        → active_positions: {"KRW-BTC": ...} ✅

T+10s:  💥 Flink 죽음 (Checkpoint 실패)

T+15s:  Flink 재시작
        → active_positions: {} ❌ (State 유실)

T+20s:  Reconciliation 실행
        → PostgreSQL: KRW-BTC OPEN 발견
        → Entry timestamp: T-60s (1분 전)
        → 최근 EXIT 신호: 없음
        → 판단: "Flink가 모르는 포지션!"
        → system.state.restore.v1 발행 📨

T+20.1s: Flink 수신
         → active_positions.put("KRW-BTC", ...) ✅
         → 매도 로직 재활성화

결과: State 복원 성공 ✅
```

#### 시나리오 3: False Positive 방지 (매도 직후)

```
T+0s:   Flink 매도 신호 생성
        → active_positions.remove("KRW-BTC") ✅

T+0.1s: 주문 성공
        → execution.results.v1 발행

T+0.5s: Reconciliation 실행 (불운한 타이밍)
        → PostgreSQL: KRW-BTC OPEN (아직 업데이트 안 됨)
        → 최근 EXIT 신호: T+0s ✅ (10초 이내!)
        → 판단: "곧 닫힐 예정. 무시"
        → 결과: 아무것도 안 함 ✅

T+2s:   Archivist가 DB 업데이트
        → trade_cycles: KRW-BTC CLOSED ✅

결과: False Positive 회피 ✅
```

### 5. 모니터링 및 알림

```python
# Prometheus 메트릭 노출
from prometheus_client import Counter, Gauge, Histogram

reconciliation_runs = Counter('reconciliation_runs_total', 'Total reconciliation runs')
open_positions_gauge = Gauge('open_positions_count', 'Current OPEN positions in DB')
restore_commands_sent = Counter('restore_commands_total', 'Restore commands published')
reconciliation_duration = Histogram('reconciliation_duration_seconds', 'Reconciliation execution time')

class ReconciliationJob:
    async def check_and_restore(self):
        with reconciliation_duration.time():
            reconciliation_runs.inc()
            
            open_positions = await self.db.fetch(...)
            open_positions_gauge.set(len(open_positions))
            
            # ... 로직 ...
            
            if restore_발행:
                restore_commands_sent.inc()
```

### 6. Edge Case 처리

| 상황 | 처리 방법 |
|------|----------|
| **Reconciliation 자체가 죽으면?** | Health check 실패 → Kubernetes가 자동 재시작 |
| **Kafka 장애로 발행 실패?** | 로그 기록 + 다음 주기(10초 후)에 재시도 |
| **PostgreSQL 지연으로 조회 느림?** | Timeout 설정 (5초) + Skip this cycle |
| **Reconciliation을 여러 개 띄우면?** | MVP: 단일 인스턴스만 실행 (replicas=1) <br> 프로덕션: PostgreSQL Advisory Lock 사용 |

### 7. 프로덕션 고려사항

```python
# PostgreSQL Advisory Lock (다중 인스턴스 대비)
async def run_with_lock(self):
    async with self.db.acquire() as conn:
        # 분산 잠금 획득 시도
        lock_acquired = await conn.fetchval(
            "SELECT pg_try_advisory_lock($1)", 
            RECONCILIATION_LOCK_ID
        )
        
        if not lock_acquired:
            logger.info("Another instance is running, skipping")
            return
        
        try:
            await self.check_and_restore()
        finally:
            await conn.execute(
                "SELECT pg_advisory_unlock($1)", 
                RECONCILIATION_LOCK_ID
            )
```

---

## 5. 데이터베이스 및 관리 계층 (Persistence & Management Layer) in detail 

이 계층은 단순히 데이터를 저장하는 창고가 아닙니다. 시스템의 모든 활동을 기록하는 '불변의 역사서'이자, 과거의 데이터로부터 전략을 개선하는 '학습의 기반'이며, 전체 시스템의 행동을 통제하는 '중앙 관제소'입니다. 이 계층의 설계는 시스템의 신뢰성, 감사 가능성, 그리고 장기적인 진화 가능성을 결정합니다.

### 1. 제1원칙: "모든 것을 기억하고, 모든 것으로부터 배우라"
우리는 이 계층을 다음 네 가지 핵심 원칙 하에 설계합니다.

- 감사 가능성 (Auditability): 시스템이 내린 모든 결정(매매 신호)과 행동(주문 실행)은 왜, 언제, 어떤 데이터를 기반으로 이루어졌는지 완벽하게 역추적할 수 있어야 합니다. 이는 장애 분석과 신뢰성 확보의 근간입니다.
- 분석 가능성 (Analyzability): 단순한 거래 기록을 넘어, 전략의 성과를 다각도로 측정하고, 성공과 실패의 패턴을 발견하며, 하이퍼파라미터를 최적화할 수 있는 정제된 데이터를 제공해야 합니다. 이 계층은 '데이터'를 '통찰력'으로 바꾸는 용광로입니다.
- 통제 가능성 (Controllability): 시스템의 두뇌(Flink)와 손발(Execution Engine)이 사용할 전략, 리스크 한도 등의 핵심 파라미터를 중앙에서 관리하고, 필요시 시스템 중단 없이 실시간으로 변경할 수 있는 유연성을 제공해야 합니다.
- 불변성 (Immutability): 발생한 모든 이벤트(신호, 주문, 체결)는 사실 그대로 기록되며, 절대 수정되거나 삭제되지 않는 것을 원칙으로 합니다.


### 2. 데이터베이스 스키마 설계: 시스템의 기억 구조

PostgreSQL의 강력한 기능(JSONB, Transaction, Index 등)을 적극 활용하여 다음과 같이 스키마를 설계합니다.

#### strategy_configs - 전략 하이퍼파라미터 관리

전략의 모든 두뇌를 이곳에서 관리합니다. 버전 관리를 통해 A/B 테스트와 점진적인 성능 개선을 지원합니다.

Column	Type	Description
id	BIGSERIAL	PK
strategy_id	VARCHAR	전략의 고유 식별자 (e.g., 'P_WAVE_V1')
config_version	INT	동일 전략 내 하이퍼파라미터 버전 (e.g., 1, 2, 3...)
hyperparameters	JSONB	전략에 사용되는 모든 하이퍼파라미터 (e.g., {"pwave": {"density_threshold_pct": 30}, "risk": ...})
is_active	BOOLEAN	현재 Flink 및 주문 실행기가 참조해야 할 활성 버전인지 여부
description	TEXT	해당 버전의 특징이나 변경 사항에 대한 설명
created_at	TIMESTAMPTZ	레코드 생성 시각

- Unique Constraint: (strategy_id, config_version)

#### signals - 모든 생성 신호 기록

실행 여부와 관계없이 Flink가 생성한 모든 매매 신호를 기록하여 전략의 오탐/미탐 여부를 분석하는 데 사용합니다.

Column	Type	Description
id	BIGSERIAL	PK
signal_id	UUID	신호 고유 ID (Protobuf의 signal_id, UNIQUE)
code	VARCHAR	마켓 코드 (e.g., "KRW-BTC")
side	VARCHAR	"BUY" or "SELL"
reason	VARCHAR	신호 생성 이유 (e.g., "P_WAVE_EARTHQUAKE_DETECTED")
price_at_signal	NUMERIC	신호 발생 시점의 기준 가격
signal_timestamp	TIMESTAMPTZ	Flink가 신호를 생성한 시각 (Event Time)
created_at	TIMESTAMPTZ	DB에 기록된 시각

- Indexes: signal_id, (code, signal_timestamp)


#### trades - 모든 주문 실행 결과 기록

주문 실행 계층의 모든 활동을 기록하는 감사 추적의 핵심 테이블입니다.

Column	Type	Description
id	BIGSERIAL	PK
trade_id	UUID	거래 결과 고유 ID (ExecutionResult의 result_id, UNIQUE)
original_signal_id	UUID	이 주문을 유발한 원본 신호 ID (FK to signals.signal_id)
exchange_order_id	VARCHAR	거래소가 부여한 주문 ID
status	VARCHAR	SUCCESS, VALIDATION_FAILED, API_ERROR 등 실행 결과
code	VARCHAR	마켓 코드
side	VARCHAR	"BUY" or "SELL"
executed_price	NUMERIC	실제 평균 체결 가격 (체결 성공 시)
executed_volume	NUMERIC	실제 체결 수량 (체결 성공 시)
fee	NUMERIC	발생한 수수료 (체결 성공 시)
error_message	TEXT	실행 실패 시 상세 에러 메시지
execution_timestamp	TIMESTAMPTZ	주문 실행 계층이 작업을 완료한 시각

- Indexes: trade_id, original_signal_id, exchange_order_id, (code, execution_timestamp)

#### trade_cycles - 진입/청산 사이클 및 손익(P&L) 관리

개별 거래의 성과를 측정하기 위한 최종 분석 테이블입니다.

Column	Type	Description
id	BIGSERIAL	PK
code	VARCHAR	마켓 코드
entry_trade_id	BIGINT	진입 거래 ID (FK to trades.id)
entry_signal_id	UUID	진입 신호 ID (FK to signals.signal_id, 복원용)
exit_trade_id	BIGINT	청산 거래 ID (FK to trades.id, NULLABLE)
status	VARCHAR	"OPEN" or "CLOSED"
pnl	NUMERIC	손익 (수수료 포함)
pnl_percentage	NUMERIC	수익률 (%)
holding_duration_ms	BIGINT	포지션 보유 시간 (밀리초)
entry_timestamp	TIMESTAMPTZ	진입 시각
exit_timestamp	TIMESTAMPTZ	청산 시각 (NULLABLE)

- Indexes: (status, code), entry_trade_id, entry_signal_id, exit_trade_id

#### system_events 테이블 

프로젝트의 궁극적인 성공을 위해, 시스템의 운영 상태를 기록하는 새로운 테이블을 추가해야 합니다.

시스템 컴포넌트 간의 '상태 전이(State Transition)' 기록
- 현재 스키마는 "Flink가 BUY 신호를 만들었다"(signals) 와 "주문 실행기가 체결에 성공했다"(trades)는 결과는 기록하지만, 그 두 사건 사이의 과정에서 발생하는 시스템 내부의 이벤트를 기록하지 않습니다.
- 질문 1: Flink가 신호를 Kafka에 발행한 시각과 주문 실행기가 그 메시지를 소비한 시각의 차이(Latency)는 얼마인가?
- 질문 2: 주문 실행기가 API 요청을 보냈지만 타임아웃이 발생하여 재시도했다는 사실을 어떻게 알 수 있는가?
- 질문 3: Archivist 서비스가 장애로 인해 몇 시간 동안 Kafka 데이터를 DB에 쓰지 못했다는 사실을 어떻게 기록하고 추적할 것인가?
- 이러한 '운영 데이터'의 부재는 장애 발생 시 원인 분석을 매우 어렵게 만들고, 시스템의 잠재적인 병목 구간을 파악하지 못하게 하는 문제를 해결할 수 있음. 

언제 이를 발행하는가? system.events.v1 Kafka 토픽에서 이를 수신해서 DB 에 기입하면 됨. 

스키마 구조: 
Column	Type	Description
id	BIGSERIAL	PK
event_id	UUID	이벤트 고유 ID
correlation_id	UUID	연관된 signal_id 또는 trade_id
service_name	VARCHAR	이벤트를 발생시킨 서비스 이름 (e.g., 'Flink', 'ExecutionEngine', 'Archivist')
event_type	VARCHAR	이벤트 타입 (e.g., 'SIGNAL_PRODUCED', 'SIGNAL_CONSUMED', 'API_RETRY')
event_status	VARCHAR	'SUCCESS', 'FAILURE'
event_message	TEXT	상세 메시지 또는 에러 로그
event_timestamp	TIMESTAMPTZ	이벤트 발생 시각

### 3. 데이터 흐름 아키텍처: '기록원(Archivist)' 서비스

Kafka 토픽의 데이터를 PostgreSQL에 안정적으로 저장하기 위한 별도의 마이크로서비스를 구현합니다.

컴포넌트: Archivist Service (Python, asyncio, confluent-kafka, asyncpg 기반)

역할:
- internal.signals.v1 토픽을 구독하여 signals 테이블에 데이터를 삽입합니다.
- execution.results.v1 토픽을 구독하여 trades 테이블에 데이터를 삽입합니다.

핵심 로직 (Trade Cycle 매칭):
- trades 테이블에 SUCCESS 상태의 SELL 거래가 기록될 때, 해당 code에 대해 status가 OPEN인 trade_cycles 레코드를 찾습니다. 매칭되는 레코드가 있으면, 해당 레코드를 CLOSED로 업데이트하고 exit_trade_id, pnl, holding_duration_ms 등 최종 성과 지표를 계산하여 채워 넣습니다.
- SUCCESS 상태의 BUY 거래가 기록되면, 새로운 trade_cycles 레코드를 OPEN 상태로 생성합니다.

데이터 정합성:
- Kafka의 At-Least-Once Delivery 특성으로 인해 동일 메시지가 중복 처리될 수 있습니다. signals.signal_id와 trades.trade_id에 설정된 UNIQUE 제약 조건을 활용하여 데이터베이스 레벨에서 멱등성을 보장합니다. 서비스 로직은 INSERT ... ON CONFLICT DO NOTHING 구문을 사용하여 중복 삽입 에러를 방지합니다.

---

## 6. Scalper Admin & Dashboard 서비스 in detail 

### 1. 핵심 책임:
- 하이퍼파라미터 관리: strategy_configs 테이블에 대한 CRUD 인터페이스를 제공합니다. 관리자는 웹 UI를 통해 각 전략의 파라미터를 직관적으로 수정하고, 버전을 관리하며, 활성 버전을 지정할 수 있습니다.
- 전략 업데이트 트리거: 관리자가 UI에서 '활성화' 버튼을 누르면, 이 서비스가 책임지고 system.config.updates.v1 Kafka 토픽으로 변경 알림 메시지를 발행(Publish)합니다.
- 성과 분석 대시보드: PostgreSQL의 v_trade_performance 뷰와 같은 분석용 뷰를 조회하여, KPI 지표들을 시각화된 차트와 테이블로 제공합니다.


### 2. 기술 스택 예시 (Python 기반):
- 백엔드 (API 서버): FastAPI
    - 이유: asyncio 기반으로 동작하여 비동기 DB 드라이버(asyncpg)와 잘 맞고, 자동 API 문서 생성 기능이 뛰어나 개발이 빠릅니다.
- 프론트엔드 (UI):
    - Jinja2 + htmx: 더 간단한 관리 페이지를 원한다면, FastAPI에 내장된 템플릿 엔진을 사용하여 서버 사이드 렌더링 방식으로 빠르게 구현할 수도 있습니다.
- 데이터베이스 접속: SQLAlchemy 2.0 (비동기 지원) 또는 asyncpg 직접 사용

### 3. 사용자 시나리오 예시:

- (1) 관리자가 웹 브라우저로 http://admin.my-scalper.com에 접속합니다.
- (2) 로그인 후, 대시보드에서 현재 누적 P&L과 승률을 확인합니다.
- (3) '전략 관리' 탭으로 이동하여 P_WAVE_V1 전략의 상세 페이지로 들어갑니다.
- (4) pwave.density.threshold_pct 값을 30%에서 35%로 수정한 뒤 '저장 및 활성화' 버튼을 클릭합니다.
- (5) Scalper Admin 백엔드는 다음 두 가지 작업을 수행합니다.
    - PostgreSQL의 strategy_configs 테이블에 해당 레코드를 업데이트하고 is_active 플래그를 조정합니다.
    - Kafka Producer를 통해 system.config.updates.v1 토픽으로 { "strategy_id": "P_WAVE_V1" } 메시지를 전송합니다.
- (6) 실시간으로 동작 중이던 Flink Job과 주문 실행 계층은 이 Kafka 메시지를 수신하고 즉시 메모리에 로드된 설정을 새로운 35% 값으로 교체합니다. 시스템은 단 1초의 중단도 없이 새로운 전략으로 업데이트됩니다.

### 4. 실시간 하이퍼파라미터 관리: '무중단 전략 업데이트'

전체 시스템을 재시작하지 않고 실시간으로 전략 파라미터를 변경하는 것은 운영 효율성에 매우 중요합니다.

업데이트 프로세스:
- DB 변경: 관리자가 strategy_configs 테이블에 새로운 버전의 설정을 추가하거나 기존 설정을 수정한 뒤, is_active 플래그를 조정합니다.
- 변경 전파 (Publish): 관리 툴이나 스크립트를 통해 system.config.updates.v1 Kafka 토픽으로 변경 사실을 알리는 메시지를 전송합니다. (e.g., { "event": "CONFIG_UPDATED", "strategy_id": "P_WAVE_V1" })
- 실시간 수신 (Subscribe): Flink Job과 주문 실행 계층은 이 system.config.updates.v1 토픽을 구독하는 별도의 경량 스레드/태스크를 가집니다.
- 메모리 반영 (Reload): 업데이트 메시지를 수신하면, 각 컴포넌트는 즉시 DB의 strategy_configs 테이블을 다시 쿼리하여 최신 활성 설정을 메모리로 불러와 기존 설정을 대체합니다.
- Flink 구현: 이 메커니즘은 Flink의 Broadcast State 패턴을 사용하여 완벽하게 구현할 수 있습니다. 설정 변경 스트림을 모든 SignalGenerator 인스턴스에 브로드캐스트하여 모든 작업자가 동시에 최신 하이퍼파라미터를 적용하도록 보장합니다.

### 5. 성과 분석 및 대시보드: '전략 계기판' 설계

수집된 데이터를 활용하여 전략의 성과를 직관적으로 파악할 수 있는 계기판을 설계합니다.

핵심성과지표 (KPIs):
- 수익성: 누적 손익(Cumulative P&L), 일/주/월별 손익, 평균 손익, 손익비(Profit Factor)
- 승률: 전체 승률, 코인별 승률, 진입/청산 이유별 승률
- 리스크: 최대 낙폭(Max Drawdown), 샤프 지수(Sharpe Ratio)
- 효율성: 평균 포지션 보유 시간, 일일 평균 거래 횟수
- 거래 품질: 평균 슬리피지(신호 가격 대비 체결 가격의 차이)

구현:
- PostgreSQL의 Views 또는 Materialized Views를 생성하여 위 KPI들을 미리 계산해 둡니다.
- 예시 View (v_trade_performance)

```sql
        CREATE VIEW v_trade_performance AS
        SELECT
            c.id,
            c.code,
            c.status,
            c.pnl,
            c.pnl_percentage,
            c.holding_duration_ms,
            entry_s.reason as entry_reason,
            exit_s.reason as exit_reason,
            c.entry_timestamp,
            c.exit_timestamp
        FROM trade_cycles c
        JOIN trades entry_t ON c.entry_trade_id = entry_t.id
        LEFT JOIN trades exit_t ON c.exit_trade_id = exit_t.id
        JOIN signals entry_s ON entry_t.original_signal_id = entry_s.signal_id
        LEFT JOIN signals exit_s ON exit_t.original_signal_id = exit_s.signal_id;
```

- Metabase, Grafana 같은 BI 툴을 이 View에 연결하여 대시보드를 시각화합니다.

