# 시스템 아키텍처와 실질적인 구현 디테일 

핵심은 '속도'와 '안정성', 그리고 '확장성'입니다. 수십 밀리초(ms)의 차이로 성패가 갈리는 전략이므로, 모든 아키텍처는 지연 시간(Latency)을 최소화하는 방향으로 설계되어야 합니다.

---

## 🚀 시스템 아키텍처 (System Architecture)

전체 시스템은 크게 **5개의 핵심 계층**으로 구성됩니다.

### **1. 데이터 수집 계층 (Data Ingestion Layer)** 
* **역할:** 업비트와 빗썸 거래소로부터 실시간 데이터를 가장 빠르게 수집하여 Kafka로 전송합니다.
* **컴포넌트:**
    * **Exchange Connectors (Upbit/Bithumb):** 각 거래소별로 독립적인 경량 마이크로서비스로 구현합니다.
        * **WebSocket Connector:** 실시간 '거래 체결(Trade Print)'과 '호가창(Order Book)' 데이터는 지연 시간을 최소화하기 위해 반드시 WebSocket API를 사용합니다.
    * **구현 언어:** Rust, Go, C++ 등 저지연 네트워킹에 강점이 있는 언어를 추천합니다. (Java/Kotlin도 가능)
    * **핵심 고려사항:** 각 거래소의 API Rate Limit을 철저히 준수해야 하며, 연결이 끊겼을 때를 대비한 재연결 로직과 데이터 유실 방지 메커니즘이 필수입니다.

---
### **2. 데이터 스트리밍 계층 (Data Streaming Layer - Kafka)**
* **역할:** 모든 원시 시장 데이터를 중앙에서 안정적으로 받아들이고, 후속 처리 시스템(Flink)이 소비할 수 있도록 버퍼링하는 역할을 합니다. 시스템의 '중앙 혈관'입니다.
* **Kafka Topics:**
    * `upbit.trades.v1`: 실시간 거래 체결 데이터
    * `upbit.orderbooks.v1`: 실시간 호가창 변경분(diff) 또는 스냅샷 데이터
    * `internal.enriched.trades.v1`, `internal.enriched.orderbooks.v1`: Kafka로부터 원시 데이터(orderbook, trade)를 받아, 분석에 용이한 형태로 데이터를 '정제'하고 '보강'해서 발행하기 위한 토픽 
    * `internal-signals`: Flink에서 생성된 매수/매도 신호
    * `execution-results`: 주문 실행 결과 (성공, 실패, 부분 체결 등)
    * `execution.feedback.v1`**: 주문 실행 결과를 Flink에게 피드백 (State 동기화용)
    * `system.state.restore.v1`**: Reconciliation Job이 Flink State 복원 명령 발행

* **핵심 고려사항:** 데이터 직렬화 포맷으로 **Avro** 또는 **Protocol Buffers**를 사용하여 메시지 크기를 줄이고 처리 속도를 높입니다. 데이터 처리량에 따라 파티션 수를 적절히 조절하여 병렬 처리를 극대화합니다.

---
### **3. 실시간 분석/신호 생성 계층 (CEP Layer - Flink)**
* **역할:** 시스템의 '두뇌'입니다. Kafka로부터 데이터를 받아 기획 문서에 명시된 'P파'와 '여진'을 실시간으로 감지하고 매매 신호를 생성합니다.
* **Flink Jobs (여러 개로 분리하여 관리):**
    * **Job 1: Market Data Processor**
        * 각 거래소의 원시 데이터를(e.g., `upbit.trades.v1`) 입력받아 정규화된(Normalized) 데이터 모델로 변환합니다.
        * 호가창 데이터와 체결 데이터를 코인별로 `keyedStream`을 사용하여 묶어줍니다. 이를 통해 특정 코인에 대한 모든 분석이 동일한 Flink Task Manager에서 처리되도록 보장합니다.
    * **Job 2: Signal Generation (P-wave & Aftershock Degtection)**
        * **Stateful Processing**을 적극적으로 활용합니다. Flink의 관리형 상태(Managed State)에 이전 호가창 데이터, 최근 N초간의 거래량 등을 저장합니다.
        * **'호가 밀도 변화율' 계산:** `ProcessFunction` 을 사용하여 현재 호가창 상태와 직전 상태를 비교, 매도 물량의 급격한 감소를 감지합니다.
        * **'스푸핑성 주문 패턴 감지(Proxy Metric)':** `특정 호가에 이전에는 없던 대규모 주문량(e.g., 전체 호가 잔량의 5% 이상)이 나타났다가, Flink 타이머로 설정한 짧은 시간(e.g., 1.5초) 내에 해당 물량이 대부분 사라지는 현상을 '스푸핑성 패턴'으로 간주하여 상태 기반으로 추적합니다.
        * **'평균 체결 거래량 감소' 추적:** 고래 체결 감지 후, 후속 매수 거래들의 체결량을 `Tumbling Window`나 `Sliding Window`를 이용해 이동 평균을 계산하고, 이 평균값이 감소하는 추세를 감지합니다.
        * **'상대 호가 불균형 심화' 감지:** 현재 호가창 스냅샷에서 매수/매도 잔량을 비교하여 비율을 계산하고 임계치를 넘는지 확인합니다.
        * 위 조건들이 충족되면, 매수/매도 신호(e.g., `{ "symbol": "BTC/KRW", "side": "BUY", "reason": "P-WAVE_DETECTED", "timestamp": ... }`)를 `internal-signals` Kafka 토픽으로 전송합니다.
        * **'결정적 signal id 생성':** 매매 신호에 대한 메시지가 발행하고 나서 중복된 메시지 수신을 할 경우 다른 signal id 가 생성되서 이중 매수/매도 처리가 발생할 가능성이 있음. 그러므로 같은 데이터라면 같은 signal id 가 생성되도록 되야함. (reason + timestamp + code + side 등을 이용해 멱등성 처리를 위한 결정적 signal id 생성)

---
### **4. 주문 실행 계층 (Order Execution Layer)**
* **역할:** Flink가 생성한 '매매 신호'를 받아 실제 거래소에 주문을 전송하는, 매우 높은 신뢰성이 요구되는 '손' 역할을 합니다.
* **컴포넌트:**
    * **Execution Engine:** `internal-signals` 토픽을 구독(consume)하는 독립적인 마이크로서비스입니다.
    * **로직:**
        1.  매매 신호 수신
        2.  거래소 Private API를 통해 시장가 주문 전송 (즉시 실행)
        3.  주문 실행 결과를 `execution-results` 토픽으로 전송하여 모든 활동을 기록합니다.
        4.  사후 체결 품질 분석 (슬리피지, 지연 시간 측정)
* **핵심 고려사항:**
    * **멱등성(Idempotency):** 동일한 신호가 중복으로 처리되어 주문이 여러 번 나가는 것을 방지해야 합니다. 신호에 고유 ID를 부여하여 처리 여부를 확인합니다.
    * **장애 격리:** Flink 클러스터의 장애가 주문 실행에 직접적인 영향을 주지 않도록 Kafka를 통해 비동기적으로 분리하는 것이 매우 중요합니다.

---
### **5. 데이터베이스 및 관리 계층 (Persistence & Management Layer)**
* **역할:** 시스템의 모든 활동을 기록하고, 설정을 관리하며, 성과를 분석하는 기반을 제공합니다.
*   **컴포넌트:**
    *   **Archivist Service (Raw Data Logger):**
        *   **역할:** 실시간 원시 데이터를 Kafka(`upbit.trades.v1`, `upbit.orderbooks.v1`)에서 구독하여 TimescaleDB에 영구 저장하는 역할(ETL)을 수행합니다. 이것이 바로 백테스팅 시스템의 'Historical Data Store'를 채우는 데이터 파이프라인입니다.
        *   **기술:** Python, `confluent-kafka` (Consumer), `asyncpg` (PostgreSQL Driver)
    *   **Archivist Service (Trade Cycle Manager):**
        *   **역할:** 주문 실행 결과(`execution.results.v1`)와 신호(`internal.signals.v1`) 데이터를 구독하여, `trades`, `signals`, `trade_cycles` 테이블에 최종 거래 내역과 성과를 기록하고 관리합니다.
* **PostgreSQL 활용:**
    * **Configuration Table:** `X%`, `Y초` 등 전략의 모든 **하이퍼파라미터**를 저장합니다. Flink 잡이나 Execution Engine은 시작 시 이 테이블을 읽어 설정을 로드합니다. (실시간 변경은 별도 메커니즘 필요)
    * **Trade Log Table:** `execution-results` 토픽의 데이터를 저장하여 모든 매매 내역(진입 가격, 청산 가격, 수익, 신호 이유 등)을 영구적으로 기록합니다.
    * **Monitoring/Dashboard:** Grafana, Metabase 같은 BI 툴과 PostgreSQL을 연동하여 실시간 P&L(손익), 승률, 슬리피지 등을 시각화합니다.
    * **Backtesting Data Storage:** 과거의 원시 데이터를 저장해두고, 이를 Flink 잡에 주입하여 새로운 하이퍼파라미터로 전략을 시뮬레이션하는 데 사용될 수 있습니다.
    * **Backtesting Data Storage (TimescaleDB):** `Raw Data Logger`에 의해 수집된 모든 원시 데이터를 저장합니다.

---
### **6. 하이퍼파리미터 정리**
* P파(매수 신호) 관련:
    * pwave.density.window_seconds: 호가 밀도 변화율 계산을 위한 시간 윈도우 (초)
    * pwave.density.threshold_pct: 호가 밀도 변화율 트리거 임계값 (%)
    * pwave.spoofing.volume_threshold: 스푸핑으로 간주할 최소 주문량
    * pwave.spoofing.lifespan_ms: 스푸핑 주문의 최대 존속 시간 (ms)

* 여진(매도 신호) 관련:
    * aftershock.avg_trade_size.window_seconds: 평균 체결량 감소 추적을 위한 시간 윈도우
    * aftershock.avg_trade_size.decrease_threshold_pct: 평균 체결량 감소 트리거 임계값 (%)
    * aftershock.imbalance.depth: 호가 불균형 계산 시 확인할 호가 단계 수 (e.g., 10)
    * aftershock.imbalance.ratio_threshold: 매도벽/매수벽 불균형 트리거 비율 (e.g., 2.0)

* 리스크 관리 관련:
    * rsk.max_position_per_coin_krw: 코인당 최대 진입 금액 (KRW)
    * risk.stop_loss_pct: 강제 손절매 비율 (%)
    
---
### **7. 백테스팅(backtesting) 아키텍처: 과거를 통한 미래 전략 검증**

#### 1. 제1원칙: "실전과 동일한 두뇌로, 과거를 초고속으로 재연하라"

스캘핑 전략의 생명은 수십 개의 하이퍼파라미터에 대한 지속적인 최적화에 있습니다. 백테스팅 시스템은 단순한 시뮬레이터를 넘어, **'과거 시장을 그대로 복제한 가상 현실'**이어야 합니다. 이를 위해 우리는 다음 세 가지 원칙을 절대적으로 준수합니다.

-   **코드 재사용성 100% (100% Code Reusability):** 백테스팅은 실전에서 사용하는 Flink의 **'신호 생성(Signal Generation) 잡' 코드를 단 한 줄도 수정하지 않고 그대로 사용**해야 합니다. 이것이 보장되지 않는 모든 백테스팅은 유효하지 않습니다.
-   **높은 현실성 (High-Fidelity Simulation):** 거래 수수료, 슬리피지(Slippage), 그리고 신호 생성부터 주문 체결까지의 지연 시간(Latency)을 최대한 현실과 가깝게 시뮬레이션하여, 백테스팅 결과의 신뢰도를 극대화합니다.
-   **초고속 반복 (Rapid Iteration):** 하루치 데이터를 수 분 내에 처리할 수 있도록 설계하여, 다양한 하이퍼파라미터 조합에 대한 실험을 빠르게 반복하고 최적의 조합을 찾아낼 수 있어야 합니다.

#### 2. 백테스팅 시스템 아키텍처

핵심 아이디어는 **'두뇌(Flink)'는 그대로 두고, '눈과 귀(데이터 소스)'와 '손발(주문 실행기)'만 가상으로 교체**하는 것입니다.

```
                  [ Historical Data Store ]
                  (TimescaleDB)
                           │
                           │ 1. 과거 데이터 Read
                           ▼
                  [ Data Replay Engine ]
        (과거 데이터를 Kafka Topic으로 초고속 Replay)
                           │
                           │ 2. upbit.trades.v1, upbit.orderbooks.v1
                           ▼
[ Kafka ]───────────────────────────────────────────┐
    │ ▲                    │                        │
    │ │ 4. internal-signals.v1 │                        │ 6. execution-results.v1
    │ │                    ▼                        │
    │ └─────────[ Flink Signal Generation Job ]     │
    │                   (실전 코드와 100% 동일)       │
    │                                               │
    └────────────────────[ Simulated Execution Engine ]
                                  │ ▲
                                  │ │ 3. 실시간 시장 상황 참조
                                  │ │    (Slippage 계산용)
                                  │ └───────────────────────
                                  │
                                  │ 5. 가상 주문 실행
                                  ▼
                            [ PostgreSQL ]
                          (백테스팅 결과 저장 및 분석)
```

**구성 요소:**

1.  **Historical Data Store (과거 데이터 저장소):**
    *   역할: 업비트로부터 수집된 모든 원시 거래 체결(Trade) 및 호가창(Orderbook) 데이터를 고해상도 타임스탬프와 함께 영구 저장합니다.
    *   기술: 시계열 데이터 처리에 특화된 TimescaleDB (PostgreSQL 확장)를 사용합니다.

2.  **Data Replay Engine (데이터 재연 엔진):**
    *   역할: 지정된 과거 기간(e.g., 어제 오전 9시~10시)의 데이터를 저장소에서 읽어, 실시간 스트림처럼 Kafka의 `upbit.trades.v1`, `upbit.orderbooks.v1` 토픽으로 **재생(Replay)**합니다.
    *   **핵심 기능 (시간 제어):** Flink의 **이벤트 시간(Event Time)** 처리 기능을 100% 활용하기 위해, 데이터는 최대한 빠른 속도로 Kafka에 전송되지만 각 메시지에는 **과거의 원본 타임스탬프가 그대로 보존**됩니다. Flink는 이 타임스탬프를 기준으로 시간을 인식하고, 마치 과거로 돌아간 것처럼 정확하게 데이터를 처리합니다.

3.  **Flink Signal Generation Job (신호 생성 잡 - 변경 없음):**
    *   실전에서 사용하는 신호 생성 로직을 **그대로 사용**합니다. 재연된 과거 데이터를 기반으로 매수/매도 신호를 생성하여 `internal-signals.v1` 토픽으로 발행합니다.

4.  **Simulated Execution Engine (가상 주문 실행 엔진):**
    *   역할: 실전용 '주문 실행 계층'을 대체하는 백테스팅의 핵심 컴포넌트입니다.
    *   `internal-signals.v1` 토픽을 구독하여 매매 신호를 수신합니다.
    *   실제 거래소에 주문을 보내는 대신, **Data Replay Engine이 재생 중인 과거 호가창 데이터를 참조**하여 다음과 같은 현실적인 시뮬레이션을 수행합니다.
        *   **슬리피지(Slippage) 시뮬레이션:** 매수 신호가 발생한 시점의 호가창 상태를 보고, 시장가 주문이 체결될 때 발생했을 가격 변동(e.g., 0.05% 불리한 가격에 체결)을 계산합니다.
        *   **지연(Latency) 시뮬레이션:** 신호 생성부터 체결까지 현실에서 발생하는 평균 지연 시간(e.g., 50ms)을 의도적으로 추가합니다.
        *   **수수료 계산:** 거래소 수수료(e.g., 0.05%)를 차감합니다.
    *   모든 시뮬레이션이 끝나면, 실제 주문 실행 결과와 동일한 포맷의 `ExecutionResult` 메시지를 생성하여 `execution.results.v1` 토픽으로 발행합니다. Flink State 동기화를 위한 `execution.feedback.v1`도 동일하게 발행합니다.

5.  **PostgreSQL & Archivist (결과 저장 및 분석):**
    *   기존의 Archivist 서비스가 `execution.results.v1` 토픽의 데이터를 그대로 구독하여 백테스팅 결과를 `trades` 및 `trade_cycles` 테이블에 기록합니다. 백테스팅 실행별로 고유 ID를 부여하여 여러 실험 결과를 분리하여 관리합니다.
    *   백테스팅이 완료되면, 기존에 구축된 **대시보드와 분석 쿼리를 통해 즉시 성과(P&L, 승률, MDD 등)를 확인**할 수 있습니다.

#### 3. 백테스팅 실행 워크플로우

1.  **준비:** 분석가는 테스트하고 싶은 **하이퍼파라미터 세트**(`strategy_configs` 테이블의 `config_version` 참조)와 **테스트 기간**을 지정합니다.
2.  **실행:** 백테스팅 전용 `docker-compose` 또는 스크립트를 실행하여 위 아키텍처를 구동합니다.
3.  **재생:** Data Replay Engine이 지정된 기간의 데이터를 Kafka로 스트리밍합니다.
4.  **처리:** Flink는 이벤트 시간을 기준으로 데이터를 처리하며, 마치 실제 상황처럼 신호를 생성합니다.
5.  **시뮬레이션:** Simulated Execution Engine이 신호를 받아 가상 체결을 만들고 결과를 Kafka로 발행합니다.
6.  **기록:** Archivist가 최종 결과를 PostgreSQL에 저장합니다.
7.  **분석:** 데이터 재생이 끝나면, 분석가는 Metabase/Grafana 대시보드나 SQL 쿼리를 통해 해당 `config_version`의 성과를 즉시 분석하고, 다음 실험을 위한 통찰력을 얻습니다.

#### 4. 이 아키텍처의 장점

-   **신뢰성:** 실전 로직을 그대로 사용하므로, 백테스팅과 실제 매매 간의 불일치(Discrepancy)가 거의 없습니다. "백테스팅에서는 수익이었는데, 실전에서는 왜 손실이지?"라는 문제를 원천적으로 방지합니다.
-   **속도:** 하루 분량의 데이터를 수 분 내에 처리하여, 다양한 아이디어를 빠르게 테스트하고 전략을 점진적으로 개선하는 'Agile'한 전략 개발이 가능합니다.
-   **비용 효율성:** 과거 데이터만 있다면, 실제 자금을 투입하지 않고도 수백, 수천 번의 모의 트레이딩을 통해 전략의 잠재적 리스크와 수익성을 완벽하게 검증할 수 있습니다.
-   **확장성:** 새로운 전략 아이디어가 생기면, 새로운 Flink 잡을 개발하여 동일한 백테스팅 파이프라인에 연결하기만 하면 됩니다.

이러한 백테스팅 시스템은 단순한 기능이 아니라, **끊임없이 변화하는 시장에 적응하고 장기적으로 살아남는 알고리즘 트레이딩 시스템을 만들기 위한 필수적인 '면역 체계'이자 '훈련장'**입니다.

---

## State 동기화 아키텍처 (하이브리드 CQRS + Reconciliation Loop)

**핵심 설계 철학:** "빠른 쓰기(Write), 느린 일관성 보장(Eventual Consistency)"

이 시스템의 가장 중요한 설계 결정 중 하나는 Flink State와 PostgreSQL 간의 상태 동기화 메커니즘입니다. 스캘핑 전략의 특성상 밀리초 단위의 지연도 수익에 직접적인 영향을 미치므로, 강한 일관성(Strong Consistency)을 추구하는 대신 저지연(Low Latency)과 최종 일관성(Eventual Consistency)을 선택합니다.

**구성 요소:**

1. **Flink State (Primary Source of Truth for Real-time Decisions)**
   - 역할: 실시간 매매 결정을 위한 주(主) 상태 저장소
   - 특징: 인메모리 기반, 1-5ms 응답 시간, Checkpoint를 통한 복원
   - 저장 데이터: `active_positions` (현재 보유 중인 포지션 정보)

2. **PostgreSQL (Audit Trail & Long-term Backup)**
   - 역할: 영구 감사 추적 및 장기 백업
   - 특징: 디스크 기반, 수백 ms 지연 허용, ACID 트랜잭션 보장
   - 저장 데이터: `trade_cycles` 테이블 (모든 포지션의 진입/청산 이력)

3. **Execution Feedback Loop (Fast Path - 20-50ms)**
   - 역할: 주문 실패 시 Flink State를 즉시 정정
   - 동작: 주문 실행 직후 → `execution.feedback.v1` 발행 → Flink 수신 (20-50ms)
   - 처리: 99.9%의 State 불일치를 실시간으로 방지

4. **Reconciliation Job (Slow Path - 10초 주기)**
   - 역할: 피드백이 누락된 경우의 안전망 (0.1% edge case 처리)
   - 동작: 10초마다 PostgreSQL 조회 → 불일치 감지 → `system.state.restore.v1` 발행 → Flink 복원
   - 처리: Flink 재시작이나 네트워크 장애로 인한 State 유실 복구

**데이터 흐름 시나리오:**

```
[정상 케이스 - 99.9%]
T+0ms:    Flink 매수 신호 생성
          → active_positions.put("KRW-BTC", position_info) ✅
          
T+10ms:   Execution Engine 주문 체결 성공
          → execution.feedback.v1 발행 (status=SUCCESS)
          
T+30ms:   Flink 피드백 수신
          → active_positions 유지 확인 ✅
          
T+1s:     execution.results.v1 발행 (상세 정보)
          
T+2s:     Archivist가 PostgreSQL에 기록
          → trade_cycles INSERT (status=OPEN) ✅

결과: Flink State ✅  PostgreSQL ✅ (일관성 유지)

[장애 복구 케이스 - 0.1%]
T+0ms:    Flink 매수 신호 생성 → State 추가 ✅
T+10ms:   주문 성공 → PostgreSQL 기록 ✅
T+50ms:   💥 Flink 재시작 (Checkpoint 실패)
T+60ms:   Flink State 유실 ❌ (active_positions 비어있음)
---
T+10s:    Reconciliation Job 실행
          → PostgreSQL 조회: "KRW-BTC OPEN 포지션 발견"
          → 최근 매도 신호 없음 확인
          → 판단: "Flink가 모르는 포지션 존재"
          → system.state.restore.v1 발행 📨
          
T+10.1s:  Flink 복원 명령 수신
          → active_positions.put("KRW-BTC", ...) ✅
          → 매도 로직 재활성화

결과: Flink State ✅ (복원됨)  PostgreSQL ✅ (최종 일관성 달성)
```

**트레이드오프 분석:**

| 측면 | 선택 | 이유 |
|------|------|------|
| **일관성 모델** | Eventual Consistency | 스캘핑의 저지연 요구사항 우선 |
| **Primary SSOT** | Flink State (실시간) | 1-5ms 응답 시간 확보 |
| **Secondary SSOT** | PostgreSQL (감사) | 영구 보관 및 복구 지점 |
| **동기화 지연** | 최대 10초 | Reconciliation 주기 |
| **복잡도** | 높음 | 2개 스트림 + TTL State + 별도 Job 필요 |

**이 설계를 선택한 이유:**
- ✅ 저지연: 매매 결정에 영향을 주지 않음 (Flink State만 참조)
- ✅ 강력한 복원력: 2중 안전장치 (피드백 + Reconciliation)
- ✅ 감사 추적: PostgreSQL에 모든 이력 영구 보존
- ⚠️ 단점: 최대 10초 동안 일시적 불일치 가능 (허용 가능한 수준)


---

## 🌊 데이터 흐름 및 Flink 핵심 로직 예시

1.  **[수집]** Upbit Connector가 WebSocket으로 BTC/KRW 호가창에 100억 매도벽이 사라지는 것을 감지하고, 이 정보를 `upbit.orderbooks.v1`, `upbit.trades.v1` 토픽으로 전송합니다.
2.  **[전송]** Kafka가 이 메시지를 수신하여 Flink가 소비할 수 있도록 대기시킵니다.
3.  **[분석]** Flink의 `Signal Generation` 잡이 이 메시지를 읽습니다.
    * 잡은 Flink State에 저장된 직전 호가창 데이터와 비교합니다.
    * **'호가 밀도 변화율'**이 설정된 임계치(e.g., 30%)를 넘었다고 판단합니다.
    * 동시에 다른 조건('단기 대량 호가 출현 빈도' 등)도 충족되는지 확인합니다.
    * 모든 'P파' 조건이 맞으면, `{ "side": "BUY", ... }` 신호를 생성하여 `internal-signals` 토픽으로 전송합니다.
4.  **[실행]** Execution Engine이 `internal-signals` 토픽에서 BUY 신호를 읽습니다.
    * 리스크 관리 규칙을 통과하면, 즉시 빗썸 API를 통해 BTC 시장가 매수 주문을 전송합니다.
    * 주문 체결 결과를 받아 `execution-results` 토픽에 기록합니다.
5.  **[기록]** 별도의 Consumer가 `execution-results` 토픽의 데이터를 PostgreSQL의 `trade_log` 테이블에 저장합니다.

---

## 🛠️ 주요 설계 고려사항 (Senior's Checklist)

* **지연 시간 (Latency):**
    * **물리적 위치:** 가능하면 거래소 서버와 가장 가까운 클라우드 리전(e.g., AWS ap-northeast-2)에 전체 시스템을 배포하여 네트워크 지연을 최소화해야 합니다.
    * **Flink 최적화:** Flink의 `RocksDBStateBackend`를 사용하고, GC 튜닝(G1GC or ZGC) 및 메모리 설정을 최적화하여 Checkpointing으로 인한 지연을 줄여야 합니다.
* **장애 복구 (Fault Tolerance):**
    * **Flink Checkpointing:** 반드시 활성화하여 Task Manager에 장애가 발생해도 Kafka의 offset과 Flink의 내부 상태(e.g., 이동 평균값)를 복구하여 데이터 유실 없이 계산을 재개할 수 있도록 해야 합니다.
    * **Execution Engine:** 이 서비스는 무상태(Stateless)로 설계하여 여러 인스턴스를 띄워 안정성을 확보하는 것이 좋습니다.
* **데이터 스키마 관리:**
    * **Schema Registry** (e.g., Confluent Schema Registry)를 사용하여 Kafka 토픽의 데이터 구조(Avro/Protobuf)를 중앙에서 관리하고, 데이터 형식 불일치로 인한 런타임 에러를 방지해야 합니다.
* **백테스팅 (Backtesting):**
    * 실제 돈을 투입하기 전에 전략의 유효성을 검증하는 것은 필수입니다. Flink는 과거 데이터를 Kafka에 재전송(replay)하여 동일한 로직으로 시뮬레이션할 수 있는 강력한 기능을 제공합니다. 이 환경을 반드시 구축해야 합니다.

이 설계는 기획 문서의 복잡한 실시간 분석 요구사항을 Flink의 강력한 상태 기반 스트림 처리 능력으로 해결하고, Kafka를 통해 각 컴포넌트를 분리하여 시스템 전체의 안정성과 확장성을 확보하는 데 중점을 두었습니다.

--- 
# 시스템 아키텍처를 실제로 구현해보기 위한 구현 디테일 

## 기술 스택 선정 (Python 기반)

프로그래밍 언어: Python
- 선택 이유: Rust 대비 학습 곡선이 낮고 생태계가 성숙하여 빠른 MVP 개발에 절대적으로 유리합니다. asyncio를 통해 비동기 I/O를 효율적으로 처리할 수 있어, 네트워크 통신이 대부분인 우리 커넥터의 성능을 충분히 확보할 수 있습니다.

- 고려사항: Python의 GIL(Global Interpreter Lock)로 인해 CPU 집약적인 작업에는 한계가 있으나, 우리 커넥터는 I/O 바운드(대부분의 시간을 네트워크 응답 대기에 사용) 작업이므로 asyncio를 통해 병목 현상을 최소화할 수 있습니다. 성능은 MVP 단계에서 충분하며, 추후 최적화가 필요할 시 Rust나 Go로의 전환을 고려할 수 있습니다.

--- 

## 1. 데이터 수집 계층 (Data Ingestion Layer) in detail 

### 1. 데이터 수집 계층의 핵심 목표
단순히 데이터를 가져오는 것을 넘어, 아래 3가지 원칙을 만족시켜야 합니다.
- 초저지연 (Ultra-Low Latency): 데이터가 거래소에서 발생한 시점과 우리 시스템(Kafka)에 도달하는 시간 차이를 물리적 한계에 가깝게 줄여야 합니다. 이는 언어, 라이브러리, 네트워크 아키텍처 선정의 최우선 기준이 됩니다.
- 데이터 무결성과 안정성 (Data Integrity & Reliability): 데이터는 빠를 뿐만 아니라, 가능한 유실되면 안되고 순서는 절대 뒤바뀌어서는 안 됩니다. WebSocket 연결 끊김, Kafka 장애 등 모든 예외 상황에 대응할 수 있는 강력한 복원력을 갖춰야 합니다.
- 확장성 및 유지보수성 (Scalability & Maintainability): 향후 빗썸, 코인원 등 새로운 거래소를 추가하거나 데이터 포맷을 변경할 때, 전체 시스템에 미치는 영향을 최소화하고 독립적으로 배포 및 수정이 가능해야 합니다.
- 데이터의 신선도 우선(freshness) : 매수/매도에 대한 신호(signal)을 발견하고, 주문 실행까지의 저지연성이 중요하므로 메시지 큐로의 재시도는 제외. 

### 2. 디테일 설계: 

- asyncio 기반 비동기 설계 
- Protobuf 사용으로 네트워크 효율성 확보
- 웹소켓 재연결 로직 포함
- ~~State Management: WebSocket 연결 상태, 마지막 수신 시퀀스 ID 관리~~ (제외: 마지막 시퀀스 ID 가 유실되었을 경우, REST API 로 조회를 해야할텐데 지연이 크게 발생됨) 
- 비동기 배치 Kafka Producer 전송으로 성능 개선
- Graceful Shutdown: 프로세스 종료 시 데이터 유실 방지
- Observability: 운영 중 문제 파악을 위한 메트릭/로깅 필수


### 3. 핵심 라이브러리:
- Asynchronous I/O: asyncio (Python 표준 라이브러리)
- WebSocket Client: websockets - asyncio 기반으로 동작하며, 자동 Ping/Pong 처리 등 강력한 기능을 내장한 검증된 라이브러리입니다.
- Kafka Producer: confluent-kafka - C 라이브러리(librdkafka) 기반으로 동작하여 Python 환경에서 가장 높은 성능과 안정성을 제공하는 Kafka 클라이언트입니다.
- 데이터 직렬화: protobuf - 구글에서 공식 지원하는 라이브러리를 사용하여 Protobuf 스키마를 컴파일하고 메시지를 생성합니다.

### 4. 데이터 모델링 (Protocol Buffers)

```proto
syntax = "proto3";

import "google/protobuf/timestamp.proto";

package scalper;

// 거래소 식별자
enum Exchange {
  EXCHANGE_UNSPECIFIED = 0;
  UPBIT = 1;
}

// 전일 대비 등락 상태
enum ChangeType {
  CHANGE_TYPE_UNSPECIFIED = 0;
  RISE = 1;   // 상승
  EVEN = 2;   // 보합
  FALL = 3;   // 하락
}

// 매수/매도 구분
enum AskBid {
  ASK_BID_UNSPECIFIED = 0;
  ASK = 1;    // 매도
  BID = 2;    // 매수
}

// 스트림 데이터 타입
enum StreamType {
  STREAM_TYPE_UNSPECIFIED = 0;
  SNAPSHOT = 1;
  REALTIME = 2;
}

// 실시간 거래 체결 데이터 (Upbit 'trade' 타입)
message Trade {
  Exchange exchange = 1;
  string code = 2;                          // 마켓 코드 (e.g., "KRW-BTC")
  double trade_price = 3;                   // 체결 가격 (tp)
  double trade_volume = 4;                  // 체결량 (tv)
  AskBid ask_bid = 5;                       // 매수/매도 구분 (ab)
  double prev_closing_price = 6;            // 전일 종가 (pcp)
  ChangeType change = 7;                    // 전일 대비 등락 (c)
  double change_price = 8;                  // 전일 대비 변동액 (cp)
  google.protobuf.Timestamp trade_timestamp = 9; // 체결 시각 (ttms)
  int64 sequential_id = 10;                 // 체결 고유 ID (sequential_id)
  StreamType stream_type = 11;              // 스트림 타입 (st)
  
  // -- 내부적으로 추가하는 메타데이터 --
  google.protobuf.Timestamp received_timestamp = 12; // 커넥터가 수신한 시각
}

// 호가창의 한 레벨 (매수 또는 매도)
message OrderBookLevel {
  double price = 1;                         // 호가
  double size = 2;                          // 주문량
}

// 실시간 호가창 변경분 데이터 (Upbit 'orderbook' 타입)
message OrderBookUpdate {
  Exchange exchange = 1;
  string code = 2;                          // 마켓 코드 (cd)
  double total_ask_size = 3;                // 매도 주문 총량 (tas)
  double total_bid_size = 4;                // 매수 주문 총량 (tbs)
  repeated OrderBookLevel asks = 5;         // 매도 호가 목록 (orderbook_units)
  repeated OrderBookLevel bids = 6;         // 매수 호가 목록 (orderbook_units)
  StreamType stream_type = 7;               // 스트림 타입 (st)

  // -- 내부적으로 추가하는 메타데이터 --
  google.protobuf.Timestamp event_timestamp = 8;   // 호가창 변경 이벤트 시각 (업비트 원본 timestamp 필드)
  google.protobuf.Timestamp received_timestamp = 9;  // 커넥터가 수신한 시각
}
```

### 5. 데이터 수신, 변환 및 전송 파이프라인 (핵심 로직)

(1) 파싱 (Parsing): WebSocket으로부터 받은 데이터는 바이너리 형태이므로, json.loads()를 통해 Python이 다룰 수 있는 딕셔너리(Dictionary) 객체로 변환합니다.

(2) 변환 (Transformation): 업비트가 보내주는 JSON 데이터의 필드명(e.g., tp, tv)을 우리가 정의한 Protobuf 메시지(Trade, OrderBookUpdate)의 필드명(e.g., trade_price, trade_volume)에 맞게 매핑하고 타입을 변환하는 함수(transform_trade, transform_orderbook)를 실행합니다.
- 주의: 업비트의 타임스탬프(ttms)는 Unix Millisecond 정수형이므로, 이를 google.protobuf.Timestamp 객체로 변환하는 과정이 반드시 필요합니다.

(3) 메타데이터 보강 (Enrichment): 변환 과정에서, Protobuf 메시지에 정의된 내부 메타데이터 필드인 received_timestamp에 현재 시각을 기록합니다. 이 타임스탬프는 추후 시스템 전체의 지연 시간(Latency)을 측정하고 병목 구간을 분석하는 데 결정적인 역할을 합니다.

(4) 직렬화 (Serialization): 완성된 Protobuf 객체를 .SerializeToString() 메소드를 호출하여 Kafka로 전송하기 위한 바이너리(bytes) 데이터로 변환합니다.

(5) 전송 (Production): confluent-kafka Producer를 사용하여 직렬화된 데이터를 Kafka로 전송합니다. 이때, 가장 중요한 것은 메시지의 key를 마켓 코드(e.g., "KRW-BTC")로 지정하는 것입니다. 아키텍처 설계(260라인)에 따라, 동일한 마켓 코드를 가진 데이터(체결, 호가)는 항상 동일한 Kafka 파티션에 순서대로 저장되어야 하며, 이는 Flink의 keyBy() 연산이 올바르게 동작하기 위한 절대적인 전제 조건입니다.

### 6. 데이터 수집 API 

#### 실시간 데이터 수신: Websocket API
필요성: '거래 체결(Trade)'과 '호가창(Order Book)' 데이터는 실시간성이 생명입니다. REST API처럼 매번 요청을 보내는 방식(Polling)으로는 수십 밀리초(ms)의 지연이 발생하여 스캘핑 전략의 기회를 포착할 수 없습니다. 따라서 서버가 데이터를 발생 즉시 보내주는 Websocket 방식이 필수적입니다.

사용 데이터 타입: trade(실시간 체결), orderbook(실시간 호가)

### 7. WebSocket 연결 관리 매커니즘 (핵심 로직)

업비트 API 문서와 주신 피드백을 종합하여, 아래와 같이 2중으로 안정성을 확보하는 매커니즘을 구현합니다.

*   **1단계: 자동 Ping/Pong (Low-Level 연결 유지)**
    *   `websockets` 라이브러리는 `ping_interval` 및 `ping_timeout` 파라미터를 제공합니다. 이를 설정하면 라이브러리가 자동으로 주기적인 Ping 프레임을 서버로 보내고 Pong 응답을 확인하여 연결을 유지합니다. 이는 업비트 문서에서 언급된 **'연결 유지 방법 ①: Ping Frame (정석)'** 에 해당하며, 가장 효율적이고 안정적인 방법입니다.
    *   `ping_interval`은 업비트의 Idle Timeout (120초)보다 훨씬 짧은 **60초**로 설정하여 연결이 끊길 위험을 사전에 방지합니다.

*   **2단계: 자동 재연결 with Exponential Backoff (Application-Level 복원력)**
    *   네트워크 불안정, 서버 점검 등 다양한 이유로 연결은 **언제든지 끊어질 수 있다**는 것을 전제로 설계합니다.
    *   연결이 끊어지면(`websockets.exceptions.ConnectionClosed` 예외 발생), 애플리케이션은 즉시 재시도하는 대신 **'지수 백오프(Exponential Backoff)'** 전략을 사용합니다.
        1.  최초 연결 실패 시 1초 대기 후 재시도
        2.  또 실패 시 2초 대기 후 재시도
        3.  또 실패 시 4초 대기 후 재시도 (최대 60초까지 대기 시간 증가)
    *   이 방식은 서버에 과도한 부하를 주지 않으면서, 일시적인 장애로부터 안정적으로 복구할 수 있는 '매너 있는 재시도' 전략입니다.
    *   **상태 동기화:** 재연결 성공 직후에는 데이터 유실을 방지하기 위해, 구독 메시지를 다시 보내고, **특히 호가창 데이터의 경우 REST API를 통해 현재 스냅샷을 다시 조회하여 상태를 완전히 동기화**한 후에 실시간 스트림 처리를 재개합니다.

### 8. 비동기 배치 Kafka Producer 전송으로 성능 개선 

현상: WebSocket의 초당 수천 메시지를 Producer가 따라가지 못해 메모리 큐가 폭발하는 백프레셔 발생할 수 있음. 

근본 원인: Kafka 자체의 성능 문제가 아닌, 메시지 하나마다 ACK를 기다리는 동기(Synchronous) 전송 방식의 비효율. 각 메시지 전송에 네트워크 왕복 시간(RTT)이 누적되어 초당 50개 수준으로 처리량이 급감.

#### 해결책: 비동기 배치(Asynchronous Batch) 전송

동작 방식:
- linger.ms=5: 메시지를 즉시 보내지 않고, 최대 5ms 동안 버퍼에 모읍니다.
- batch.size=16384: 버퍼가 16KB(약 100개 메시지)에 도달하면 즉시 전송합니다.
- 비동기 produce(): Producer는 ACK를 기다리지 않고 내부 큐에 메시지를 추가한 뒤 즉시 다음 작업을 수행합니다.
- 파이프라이닝: max.in.flight.requests.per.connection=5 설정을 통해, ACK를 기다리는 동안에도 최대 5개의 배치를 동시에 전송하여 네트워크를 쉬지 않고 사용합니다.
- 압축 알고리즘 선택: lz4 (CPU 사용량 적음, 압축률 높음, 속도: 빠름) 

#### 스캘핑 전략 최적화: "신선도 우선"

retries=0: 재시도를 과감히 포기합니다. 일시적 장애로 500ms 이상 지연된 데이터는 이미 스캘핑 전략에서 가치를 잃었으므로, 재시도하는 대신 버리고 새로운 기회를 포착하는 것이 유리합니다.
request.timeout.ms=500: 500ms 내에 응답이 없으면 해당 배치는 실패로 간주하고 즉시 폐기합니다.

#### 결론 

- 저지연성: linger.ms로 제어되는 예측 가능한 지연 시간 (5~15ms).
- 데이터 무결성: acks='all' 설정으로 전송 성공이 보장된 데이터는 유실되지 않음.
- 순서 보장: code를 파티션 키로 사용하고, max.in.flight 설정을 통해 동일 키에 대한 순서를 Kafka가 보장.
- 확장성: 단일 브로커로도 급등/급락 상황(1,000 msg/s)을 5배의 여유로 처리 가능.

---

## 2. 데이터 스트리밍 계층 (Data Streaming Layer - Kafka) in detail 

### 1. 제1원칙: 왜 Kafka인가? - 단순한 파이프라인이 아닌 '금융 거래 기록원'

우리는 Kafka를 단순한 데이터 전달 파이프(Pipe)로 사용하지 않습니다. Kafka를 '모든 사건을 시간 순서대로 기록하는 불변의 거래 원장(Immutable Log)'으로 활용하는 것이 핵심 철학입니다.

- 완벽한 디커플링(Decoupling): 데이터 생산자(수집 계층)와 소비자(Flink 분석 계층, 주문 실행 계층)를 완벽하게 분리합니다. Flink 클러스터가 잠시 다운되어도, 데이터 수집기는 Kafka에 계속해서 데이터를 쌓을 수 있습니다. Flink가 복구되면, 중단됐던 시점부터 데이터를 정확히 다시 읽어와 처리할 수 있어 데이터 유실이 원천적으로 불가능해집니다.

- 데이터 재처리 및 백테스팅(Replayability): Kafka에 저장된 데이터는 사라지지 않습니다. 이는 엄청난 자산입니다. 새로운 매매 전략 로직을 개발했을 때, 과거의 특정 시점(e.g., 급등장)부터 데이터를 다시 재생(Replay)하여 새로운 전략이 과거에 어떻게 동작했을지 정확하게 시뮬레이션할 수 있습니다.

- 수평적 확장성(Horizontal Scalability): 미래에 거래량이 폭증하여 Flink 분석 서버가 느려진다면, 단순히 Flink 컨슈머의 수를 늘리는 것만으로 병렬 처리량을 손쉽게 늘릴 수 있습니다. Kafka의 파티션(Partition) 개념이 이를 가능하게 합니다.

### 2. Topic 아키텍처 설계: 데이터의 주소를 명확히 하라

시스템 아키텍처 문서에 따라, 각 데이터의 흐름과 목적에 맞게 Topic을 명확하게 분리하고, 일관된 명명 규칙을 적용합니다.
- 명명 규칙: {source}.{data_type}.{version} (e.g., upbit.trades.v1) - 버전 정보를 포함하여 향후 데이터 스키마 변경 시 유연하게 대응합니다.

핵심 Topic 설계:
- upbit.trades.v1: 업비트의 모든 체결(Trade) 데이터가 이 토픽으로 전송됩니다.
- upbit.orderbooks.v1: 업비트의 모든 호가창(OrderBook) 데이터가 이 토픽으로 전송됩니다.

파티셔닝 전략 (Partitioning Strategy) - 시스템 성능의 핵심:
- 원칙: '동일한 마켓(e.g., KRW-BTC)의 데이터는 반드시 동일한 파티션에 순서대로 저장되어야 한다.'
- 구현: 데이터 수집기(Python Producer)는 Kafka로 데이터를 전송할 때, 메시지의 'Key'를 마켓 코드(e.g., "KRW-BTC")로 지정해야 합니다. Kafka는 동일한 Key를 가진 메시지를 항상 동일한 파티션으로 보내는 것을 보장합니다.
- 왜 중요한가?: Flink는 이 파티션 단위로 데이터를 병렬 처리합니다. keyedStream("KRW-BTC")와 같은 Flink 로직이 올바르게 동작하려면, Kafka 단에서부터 KRW-BTC 관련 데이터(체결, 호가)가 한 줄로 순서대로 들어오는 것이 절대적으로 보장되어야 합니다. 이 전략이 없다면 Flink에서 데이터가 뒤섞여 분석 자체가 불가능해집니다.
- 파티션 수: 초기에는 마켓의 수(수십~수백 개)와 Flink 클러스터의 병렬성(Parallelism)을 고려하여 8 또는 16 정도로 설정하는 것이 적절합니다.

### 3. 데이터 무결성 및 성능 최적화 설정

Producer 설정 (데이터 수집기 측):
- acks=all: Producer가 보낸 메시지가 모든 복제본(Replicas)에 안전하게 저장되었음을 리더 브로커로부터 확인받은 후에야 전송 성공으로 간주합니다. 속도보다 데이터 무결성을 최우선으로 하는 금융 시스템에서는 타협 불가능한 옵션입니다.

- compression.type=zstd (또는 snappy): Protobuf로 1차 압축된 데이터를 Kafka로 전송하기 전에 한 번 더 압축합니다. CPU 자원을 약간 더 사용하는 대신, 네트워크 대역폭과 Kafka 브로커의 디스크 공간을 크게 절약하여 전체 처리량을 높이는 효과적인 트레이드오프입니다.

- linger.ms=5 및 batch.size=16384: 메시지를 즉시 보내지 않고, 5ms 동안 기다리거나 16KB가 모일 때까지 버퍼에 쌓아 한 번에 보냅니다. 이는 Kafka 브로커의 부하를 줄이고 전송 효율을 극대화하여 전체 처리량을 높입니다.

Broker 설정 (Kafka 서버 측):
- replication.factor=3: (프로덕션 환경 기준) Topic의 각 파티션이 3개의 복제본을 갖도록 설정합니다. 브로커 1대가 다운되어도 데이터 유실 없이 서비스를 계속할 수 있습니다. MVP 단계에서는 1로 설정하여 로컬에서 실행합니다.
- log.retention.hours=168: 데이터를 최소 7일간 보관하도록 설정합니다. 이는 백테스팅이나 장애 복구를 위한 충분한 시간을 제공합니다.

### 4. 스키마 관리: Confluent Schema Registry 도입

필요성: Producer가 실수로 잘못된 형식의 Protobuf 메시지를 Kafka에 보내는 것을 막는 '문지기' 역할을 합니다. Flink Consumer는 Schema Registry를 통해 올바른 스키마 정보를 조회하여 데이터를 안전하게 역직렬화할 수 있습니다.

동작 방식:
- Producer는 데이터를 보내기 전, 해당 데이터의 스키마를 Schema Registry에 등록/확인합니다.
승인되면, 데이터와 함께 스키마 ID만 Kafka에 전송합니다. (데이터 크기 감소)
- Consumer는 데이터를 읽을 때 스키마 ID를 보고 Schema Registry에 해당 스키마를 요청하여 데이터를 해석합니다.
- 이는 데이터 형식 불일치로 인한 런타임 에러를 원천적으로 방지하는 가장 강력하고 표준적인 방법입니다

### 5. 로컬 MVP 환경 구축 (docker-compose.yml)

쿠버네티스 없이, 로컬 환경에서 docker-compose up 명령어 하나로 전체 데이터 스트리밍 계층을 실행할 수 있도록 구성합니다. (Schema Registry 포함)

데이터 수집기(Python)와 Flink는 각각 localhost:9092 (Kafka)와 http://localhost:8081 (Schema Registry) 주소를 바라보게 설정하면 됩니다

--- 

## 3. 실시간 분석/신호 생성 계층 (CEP Layer - Flink) in detail 

### 1. 제1원칙: Flink를 사용하는 이유 - '시간'과 '상태'를 완벽하게 통제하기 위함

우리는 Flink를 단순 데이터 처리 툴이 아닌, '과거를 기억하고 현재를 분석하여 미래를 예측하는 시계열 분석 엔진'으로 활용합니다.
- 상태 기반 처리 (Stateful Processing): Flink의 가장 강력한 기능은 '상태(State)'를 완벽하게 관리하는 것입니다. "1분 전 호가창 상태", "지난 5초간의 평균 체결량"과 같은 과거의 모든 맥락을 Flink의 관리 하에 안전하게 저장하고 현재의 데이터와 비교 분석할 수 있습니다. 이는 '호가 밀도 변화율'이나 '평균 체결량 감소'와 같은 시간의 흐름에 따른 변화를 감지해야 하는 우리 전략의 핵심입니다.
- 이벤트 시간 처리 (Event Time Processing): 네트워크 지연 등으로 데이터가 뒤늦게 도착하더라도, Flink는 데이터가 '실제로 발생한 시간(Event Time)'을 기준으로 순서를 바로잡아 처리합니다. 이를 통해 네트워크 장애 상황에서도 분석의 시간적 정합성을 보장하여 잘못된 신호 생성을 방지합니다.
- 밀리초 단위의 저지연 처리: Flink는 인메모리(in-memory) 기반으로 데이터를 처리하여 들어오는 데이터에 즉각적으로 반응합니다. 이는 '찰나의 순간'을 포착해야 하는 우리 스캘핑 전략에 필수적인 요소입니다.

---
### 2. Flink Job 아키텍처: 역할을 분리하여 복잡성을 제어하라

단일 Flink Job에 모든 로직을 구현하는 것은 유지보수의 재앙을 초래합니다. 시스템 아키텍처 문서에 따라, 역할을 명확히 구분한 두 개의 독립적인 Flink Job으로 파이프라인을 구성합니다.

Job 1: MarketDataEnricher (데이터 전처리 및 보강 잡)
- 역할: Kafka로부터 원시 데이터를 받아, 분석에 용이한 형태로 데이터를 '정제'하고 '보강'하는 역할에만 집중합니다.
- Input: upbit.trades.v1, upbit.orderbooks.v1 Kafka Topics
- Logic:
    - (1) Deserialization: Kafka로부터 받은 Protobuf 바이너리 데이터를 Flink가 이해할 수 있는 데이터 객체(e.g., Python dataclass)로 역직렬화합니다. (Schema Registry 연동)
    - (2) Timestamp 할당: Flink가 이벤트 시간을 기준으로 동작할 수 있도록, 데이터에 포함된 trade_timestamp나 event_timestamp를 Flink의 공식 타임스탬프로 지정합니다.
    - (3) Keying: 모든 데이터를 code (마켓 코드, e.g., "KRW-BTC") 기준으로 keyBy 연산을 수행합니다. 이는 동일 마켓의 데이터가 항상 동일한 Flink Task Manager(작업자)에게 전달되도록 보장하여, 상태 기반 분석의 정합성을 유지하는 핵심 단계입니다.
- Output: 처리된 데이터를 내부 Kafka Topic(e.g., internal.enriched.trades.v1, internal.enriched.orderbooks.v1)으로 전달합니다. 


Job 2: SignalGenerator (매매 신호 생성 잡)
- 역할: 전처리된 데이터를 바탕으로 기획서에 명시된 'P파(매수 신호)'와 '여진(매도 신호)' 탐지 로직을 수행하는 시스템의 핵심 두뇌입니다.
- Input: MarketDataEnricher로부터 받은 Kafka Topics (또는 원시 Kafka Topics)
- Logic: (아래 3번 항목에서 상세히 설명)
- Output: 생성된 매매 신호를 internal.signals.v1 Kafka Topic으로 전송합니다.


---
### 3. 핵심 분석 로직 상세 구현 계획 (PyFlink 기반)

SignalGenerator Job의 CoProcessFunction 내부 로직을 기획서의 전략에 따라 구체화합니다.

#### 3.1 매수 신호: 'P파(지진)' 감지 로직
- 전조 1: '호가 밀도 변화율' 계산
    - 입력: 새로운 OrderBookUpdate 메시지 수신 시
    - 계산:
        - 현재 메시지의 상위 N개(e.g., 10개) 매도 호가(asks)의 주문량 총합(current_total_ask_size)을 계산합니다.
        - recent_ask_volumes_state에서 지난 1분간의 데이터들을 가져와 평균(avg_ask_size_1min)을 계산합니다. (1분이 지난 데이터는 상태에서 제거)
        - 변화율: (1 - current_total_ask_size / avg_ask_size_1min) * 100
    - 상태 업데이트: 현재 호가 총량과 타임스탬프를 recent_ask_volumes_state에 추가합니다.
    - 판단: 변화율 > X% (e.g., 30%) 이면, P파 조건 1을 충족한 것으로 내부 플래그를 설정합니다.

- 전조 2: '스푸핑성 주문' 감지 (현실적 재해석)
    - 문제점: 업비트 WebSocket은 개별 호가 주문의 ID를 제공하지 않으므로, 기획서의 '주문이 생성되었다가 취소되는 빈도'를 문자 그대로 추적하는 것은 불가능합니다.
    - 대안 (Proxy Metric): '특정 호가의 비정상적 유동성 변화' 를 탐지하는 것으로 재해석합니다. 즉, 특정 가격대에 갑자기 큰 물량이 나타났다가 짧은 시간 내에 사라지는 현상을 포착합니다.
    - 입력: 새로운 OrderBookUpdate 메시지 수신 시
    - 로직:
        - last_orderbook_state의 호가와 현재 호가를 비교하여, 특정 가격(price)에 이전에는 없던 큰 규모(> 전체 호가 잔량의 5%)의 주문량(size)이 새로 나타난 것을 감지합니다.
        - 해당 price를 키로 하여 Flink의 타이머(Timer)를 Y초(e.g., 1.5초) 뒤에 실행되도록 등록하고, MapState에 {price: size} 형태로 저장합니다.
        - 타이머 실행 시:
            - 현재 호가창을 다시 확인하여, 해당 price의 주문량이 대부분 사라졌는지 검증합니다.
            - 사라졌다면 '스푸핑 이벤트'로 간주하고, P파 조건 2를 충족한 것으로 내부 플래그를 설정합니다.

- 최종 매수 신호 생성:
    - IF (P파 조건 1 충족) AND (P파 조건 2 충족) 이 되면, 매수 신호를 발생시킴: 
        - SignalGenerator Job이 'P파(지진)'를 감지하여 매수 신호(TradingSignal)를 생성합니다.
        - 동시에, 'KRW-BTC'의 MapState(flink의 MapState) 에 새로운 엔트리를 추가합니다. `active_positions = MapState[SignalReason, PositionInfo]`
            - 이 MapState는 각 코인별로 존재하며, 다음과 같은 구조를 가집니다.
            - Key: SignalReason (Enum) - 포지션을 오픈시킨 매수 전략의 종류 (e.g., P_WAVE_EARTHQUAKE_DETECTED)
            - Value: PositionInfo (객체) - 해당 포지션의 상세 정보를 담은 객체 (아래 position_info.proto 참고)
        - active_positions.put(SignalReason.P_WAVE_EARTHQUAKE_DETECTED, new_position_info)
        - new_position_info 객체에는 진입 가격, 시각 등의 모든 컨텍스트가 기록됩니다.

#### 3.2 position_info.proto - 포지션 정보 메시지 정의

```proto
syntax = "proto3";

import "google/protobuf/timestamp.proto";
import "trading_signal.proto"; // SignalReason enum 재사용

package scalper;

// 개별 포지션의 상세 정보를 담는 객체
message PositionInfo {
  string entry_signal_id = 1;       // 이 포지션을 열게 한 매수 신호의 고유 ID
  SignalReason entry_reason = 2;    // 포지션 진입 이유 (매수 전략)
  double entry_price = 3;           // 진입 시점의 기준 가격
  google.protobuf.Timestamp entry_timestamp = 4; // Flink가 포지션 진입을 인지한 시각
  // 추후 필요한 필드 추가 가능 (e.g., 진입 수량)
}
```

#### 3.3 매도 신호: '여진(파도 소멸)' 감지 로직

이 로직은 Flink의 Keyed State인 active_positions 맵에 현재 처리 중인 전략과 짝이 맞는 '포지션 정보(PositionInfo)'가 기록되어 있을 때 활성화가 됨. 

- 주의 : 결론부터 말씀드리면, active_positions 전역 변수가 아니라, 각 코인별로 독립적으로 존재하는 수백 개의 '개별 상태 저장소'입니다.
- 상태의 격리(State Isolation)는 어떻게 이루어지는가? 핵심은 keyBy('code') 연산에 있음. 

코드로 포현한 매도 로직 실행문 
```python
 # CoProcessFunction 내부 (의사 코드)
 ...    
    # '여진(파도 소멸)' 매도 로직
    if active_positions.contains(SignalReason.P_WAVE_EARTHQUAKE_DETECTED):
        # 열쇠가 있으니, 문을 열고 매도 로직을 실행한다.
        position_info = active_positions.get(SignalReason.P_WAVE_EARTHQUAKE_DETECTED)
        # ... (평균 체결량 감소, 호가 불균형 심화 등) ...
```

전조 1: '평균 체결 거래량의 감소' 추적
    - 구현: Flink의 Sliding Window를 사용합니다.
    - 입력: Trade 스트림
    - Window 설정: SlidingEventTimeWindows.of(Time.seconds(5), Time.seconds(1)) (5초 크기, 1초 간격)
    - 계산: 각 윈도우 내 trade_volume의 평균을 계산합니다.
    - 판단: ValueState에 저장된 직전 윈도우의 평균값과 비교하여, 평균 체결량이 감소 추세로 전환되었는지 확인합니다. (e.g., 2회 연속 감소)
- 전조 2: '상대 호가 대비 불균형 심화' 감지
    - 입력: 새로운 OrderBookUpdate 메시지 수신 시
    - 계산: 현재가 위 N개 호가의 총 매도 잔량(total_ask_size)과 아래 N개 호가의 총 매수 잔량(total_bid_size)의 비율(imbalance_ratio = total_ask_size / total_bid_size)을 계산합니다.
    - 판단: imbalance_ratio > N (e.g., 2.0) 이면, 매도 압력이 우세해진 것으로 판단합니다.

- 최종 매도 신호 생성:
    - IF (평균 체결량 감소 추세) AND (호가 불균형 심화) 조건이 충족되면, active_positions 맵에서 P_WAVE_EARTHQUAKE_DETECTED 키와 값을 제거하고 매도 신호를 internal.signals.v1 토픽으로 전송합니다.

#### 3.4 주의 : 스트림 처리는 모든 코인에 대한 하나의 통일된 데이터 스트림으로 흐른다. 

결론부터 말씀드리면, "매수/매도에 대한 독립적인 스트림이 있는 것"도 아니고, "매수 스트림이 실행된 후 바로 매도 스트림이 실행되는 것"도 아닙니다.

정확한 모델은 "모든 코인에 대한 하나의 통일된 데이터 스트림이 계속 흐르고 있고, 그 스트림을 처리하는 우리의 로직(ProcessFunction)이 '현재 상태(State)'에 따라 행동을 바꾸는 것" 입니다.

코인별 '담당자'를 상상해 보십시오
- 이 개념을 이해하는 가장 좋은 방법은 Flink의 CoProcessFunction을 각 코인별로 배정된, 24시간 깨어있는 '담당자(또는 경비원)' 라고 상상하는 것입니다.
- 우리에게는 "KRW-BTC 담당자", "KRW-ETH 담당자" 등 수백 명의 담당자가 있습니다.
- 모든 trade와 orderbook 데이터는 거대한 컨베이어 벨트를 타고 흘러갑니다.
- 각 담당자는 컨베이어 벨트에서 오직 자기 담당 코인의 데이터만 집어서 확인합니다. (이것이 keyBy('code')의 역할입니다.)
- 이 '담당자'는 두 가지 행동 모드를 가집니다.
    - '대기 상태 (Scanning Mode)': 포지션이 없는 평상시 모드
    - '추적 상태 (Tracking Mode)': 매수 신호 이후 포지션을 보유한 모드


---
### 4. Flink 내부 State 관리:

SignalGenerator 잡의 모든 로직은 Flink의 관리형 상태(Managed State)를 기반으로 동작합니다. 이는 각 마켓 코드(keyBy(code))별로 독립적으로 유지되는 Flink의 핵심 기억 장치입니다.

#### 4.1 active_positions = MapState[String, PositionInfo] ← 핵심 State

역할: 현재 시스템이 보유하고 있는 활성 포지션 정보를 저장하는 실시간 사실의 원천(Source of Truth)입니다.

구조: 마켓 코드("KRW-BTC")를 Key로, 해당 포지션의 상세 정보(PositionInfo 객체)를 Value로 가집니다. PositionInfo 내부에는 진입 이유(entry_reason), 진입 가격 등이 포함됩니다.

동작:
- 매수 신호 생성 시, active_positions.put(code, new_position_info)를 통해 새로운 포지션 정보가 추가됩니다.
- 매도 로직은 active_positions.get(code)를 통해 현재 포지션이 있는지 확인하고, 있다면 position_info를 가져와 청산 조건을 검사합니다.
- 매도 신호 생성 또는 주문 실패 피드백 수신 시, active_positions.remove(code)를 통해 해당 포지션 정보가 제거됩니다.

특징: 영구적으로 저장되며, Flink Checkpoint에 의해 안정적으로 백업됩니다.

#### 4.2 recently_removed_positions = MapState[String, PositionRemovalInfo] ← Stale 복원 방지용 안전장치

역할: 'State 동기화' 과정에서 발생할 수 있는 레이스 컨디션(Race Condition)을 방지하는 단기 기억(Short-term Memory) 상태입니다. Reconciliation Job(10초 주기)이 Flink(수십 ms)보다 느리다는 점을 보완하는게 핵심이며, 이미 청산된 포지션의 재등록을 방지하는 안전장치입니다.

문제 상황 (이 State가 없다면):
- (1) T+0s: Flink가 BTC 포지션을 매도하고 active_positions에서 제거합니다.
- (2) T+2s: DB 업데이트가 지연되어, trade_cycles 테이블에는 아직 BTC가 OPEN 상태입니다.
- (3) T+10s: Reconciliation Job이 DB를 보고 "어? Flink가 BTC 포지션을 잃어버렸네!"라고 오판하여 복원(restore) 명령을 보냅니다.
- (4) T+10.1s: Flink는 이 명령을 받고 이미 청산한 '좀비 포지션'을 active_positions에 되살리게 됩니다.

해결책 (동작 방식):
- 포지션이 active_positions에서 제거될 때, recently_removed_positions에 마켓 코드와 제거 시점의 타임스탬프, signal id(구체적인 포지션 정보)를 기록합니다.
- 이 상태에는 30초의 TTL(Time-To-Live)이 설정되어 있어, 30초가 지나면 자동으로 사라집니다.
- Flink가 복원(restore) 명령을 받으면, active_positions에 추가하기 전에 먼저 이 '최근 제거 목록'을 확인합니다.
- 만약 목록에 해당 코드가 존재한다면, "이것은 방금 닫은 포지션에 대한 낡은(Stale) 복원 명령이다"라고 판단하고 복원을 거부합니다

PositionRemovalInfo class 
```python
@dataclass
class PositionRemovalInfo:
    signal_id: str           # 제거된 포지션의 원본 signal_id
    removed_timestamp: int   # 제거 시각 (ms)
```

**MapState 정의:**
- Key: 마켓 코드 (e.g., "KRW-BTC")
- Value: `PositionRemovalInfo` 객체
- TTL: 30초 (자동 만료)


#### 4.3 last_orderbook_state = ValueState\[OrderBookUpdate]

역할: 직전 호가창 상태를 저장하여 현재 수신된 호가창과 비교, '호가 밀도 변화율' 등 변화를 감지하는 데 사용됩니다.

#### 4.4 recent_ask_volumes_state = ListState[Tuple[timestamp, volume]]

역할: '호가 밀도 변화율' 계산을 위해 최근 1분간의 상위 N개 매도 호가 총량을 시계열로 저장합니다.

#### 4.5 recent_trades_state = ListState\[Trade]

역할: '평균 체결 거래량' 계산을 위해 최근 N초간의 체결 내역을 저장합니다.

---
### 5. SignalGenerator: 데이터 스트림 연결 및 상태 관리 구현

앞서 'State 동기화 아키텍처' 섹션에서 설명한 하이브리드 CQRS 및 Reconciliation Loop 개념을 `SignalGenerator` 잡에 실제로 구현하는 방법을 자세히 살펴보겠습니다. 이를 위해 시장 데이터 스트림 외에도, 주문 실행 결과를 피드백받는 스트림과 외부에서 상태를 복원하는 스트림을 추가로 연결해야 합니다. 이 복합 스트림을 처리하기 위해 Flink의 `CoProcessFunction`을 활용합니다.

#### (1) Source: 4개 스트림 수신

```python
# 기존 시장 데이터 -> 보강된 내부 데이터
enriched_trade_stream = env.add_source(KafkaSource("internal.enriched.trades.v1"))
enriched_orderbook_stream = env.add_source(KafkaSource("internal.enriched.orderbooks.v1"))

# [NEW] 주문 실행 피드백 스트림
feedback_stream = env.add_source(KafkaSource("execution.feedback.v1"))

# [NEW] State 복원 스트림
restore_stream = env.add_source(KafkaSource("system.state.restore.v1"))
```

#### (2) Connect & KeyBy: 4개 스트림 연결

```python
enriched_trade_stream \
    .connect(enriched_orderbook_stream) \
    .connect(feedback_stream) \  # 추가
    .connect(restore_stream) \   # 추가
    .key_by(lambda x: x.code) \
    .process(SignalGeneratorWithFeedback())  # 확장된 ProcessFunction
```

#### (3-1) 확장된 ProcessFunction (매도 신호 처리 로직에도 TTL State 기록 추가)

**핵심 설계:**

`SignalGeneratorWithFeedback`는 Flink의 `CoProcessFunction`을 확장하여 4개의 독립적인 데이터 스트림을 단일 State로 통합 관리합니다.

**처리 스트림:**
1. **Trade Stream** (`process_element1`): P파/여진 감지, 신호 생성
2. **OrderBook Stream** (`process_element2`): 호가 밀도 분석, 매도 로직
3. **Feedback Stream** (`process_element3`): 주문 실패 시 State 즉시 정정
4. **Restore Stream** (`process_element4`): Reconciliation 명령 처리


**State 관리 전략:**
```python
class SignalGeneratorWithFeedback(CoProcessFunction):
    
    def open(self, runtime_context):
        # 1. 영구 State: 활성 포지션
        self.active_positions = runtime_context.get_map_state(...)
        
        # 2. TTL State: 최근 제거 포지션 (30초, Stale 복원 방지)
        ttl_config = StateTtlConfig.new_builder(Time.seconds(30)).build()
        self.recently_removed_positions = runtime_context.get_map_state(...)
        
        # 3. Bootstrap: Flink 재시작 시 PostgreSQL에서 OPEN 포지션 복원
        if self.is_first_run():
            self.load_open_positions_from_db()
```

**핵심 로직 1: 매도 신호 + TTL State 기록**

매도 신호 생성 시, 포지션을 제거하는 동시에 `recently_removed_positions`에 제거 시각을 기록합니다. 이는 Reconciliation의 "낡은 복원 명령"을 필터링하는 핵심 안전장치입니다.

```python
def process_element2(self, orderbook, ctx):
    if 여진_조건_충족():
        # 1. 포지션 제거
        self.active_positions.remove(code)
        
        # 2. TTL State 기록 (Stale 복원 방지)
        # 2. TTL State 기록 (Signal ID 포함 - Race Condition 방지)
        self.recently_removed_positions.put(
            code, 
            PositionRemovalInfo(
                signal_id=position_info.entry_signal_id,  # ✅ 핵심: 어떤 포지션인지 기록
                removed_timestamp=ctx.timestamp()
            )
        )
        
        # 3. 매도 신호 발행
        ctx.output(signal_tag, TradingSignal(...))
```

**핵심 로직 2: 피드백 처리 + Signal ID 검증**

주문 실패 피드백 수신 시, **현재 State의 `entry_signal_id`와 피드백의 `signal_id`를 비교**하여 Stale 피드백으로 인한 유효 포지션 삭제를 방지합니다.

```python
def process_element3(self, feedback: ExecutionFeedback, ctx):
    if feedback.status in ["FAILED", "TIMEOUT"]:
        position_info = self.active_positions.get(code)
        
        # Signal ID 멱등성 검증
        if position_info and position_info.entry_signal_id == feedback.signal_id:
            self.active_positions.remove(code)
            # TTL State 기록 (Signal ID 포함)
            self.recently_removed_positions.put(
                code,
                PositionRemovalInfo(
                    signal_id=feedback.signal_id,  # ✅ 실패한 포지션의 ID 기록
                    removed_timestamp=ctx.timestamp()
                )
            )
```

**핵심 로직 3: State 복원 + 이중 검증**

Reconciliation 명령 수신 시, TTL State와 Timestamp를 동시에 검증하여 잘못된 복원을 차단합니다.
- (1) 1차 방어: TTL State 확인
- (2) 2차 방어: Timestamp 비교 
- (3) 3차 방어: 제거된 포지션과 복원 대상이 동일한지 Signal ID로 확인 / 같은 포지션 → Stale 복원 명령인거임 / 다른 포지션 → 안전하게 복원 진행
- 모든 검증 통과 → 복원 실행

#### (3-2) [핵심 안정성 강화] 멱등성 있는 피드백 처리

execution.feedback.v1 피드백은 Flink의 상태를 현실과 동기화하는 핵심 메커니즘이지만, 네트워크 지연이나 Kafka 리밸런싱으로 인해 메시지가 지연되거나 중복 수신될 수 있습니다. 현재 로직은 이러한 비정상적인 상황에 매우 취약합니다.

문제 시나리오: Stale 피드백으로 인한 유효 포지션 삭제
```
[T+0ms] BUY 신호1 생성
        → signal_id = "aaa-111"
        → active_positions.put("KRW-BTC", position1) ✅
        
[T+10ms] 주문 실행 → 네트워크 타임아웃 💥
         → FAILED feedback 발행 (signal_id="aaa-111")
         → Kafka로는 전송되었으나, Flink 도착 지연

[T+15ms] 실제로는 업비트에서 체결 성공!
         → 하지만 Execution Engine은 이를 FAILED로 처리

[T+20ms] 새로운 P파 감지!
         → BUY 신호2 생성 (signal_id="bbb-222")
         → active_positions.put("KRW-BTC", position2) ✅
         → 💡 position1을 position2로 덮어씀

[T+25ms] 지연되었던 FAILED feedback (signal_id="aaa-111") 도착
         → Flink: "KRW-BTC에 포지션(position2)이 있네? 제거!"
         → active_positions.remove("KRW-BTC") 💥
         
[결과]
-   `position1`: 실제 체결되었지만 Flink는 모름 (유령 포지션)
-   `position2`: 유효한 포지션이지만 Flink State에서 삭제됨 → **절대 매도 신호를 생성할 수 없어 자산이 영원히 동결됨**
```

해결책: Signal ID를 통한 멱등성 검증
이 문제를 해결하기 위해, 피드백을 처리할 때 "내가 지금 삭제하려는 포지션이 이 피드백이 의도한 바로 그 포지션인가?"를 반드시 확인해야 합니다.
이를 위해 ExecutionFeedback 메시지의 signal_id와 현재 active_positions에 저장된 PositionInfo의 entry_signal_id를 비교하는 로직을 추가합니다.

```python
# 현재 State의 signal_id와 피드백의 signal_id가 일치하는가?
if current_position.entry_signal_id == feedback.signal_id:
    # 일치! → 이 피드백은 현재 포지션에 대한 것이 맞다.
    self.active_positions.remove(code)
    self.recently_removed_positions.put(code, ctx.timestamp())
    logger.warning(f"✅ Position correctly removed by feedback: {feedback.signal_id}")
```

#### (3-3) state_restore_command.proto - State 복원 명령 메시지

Reconciliation Job이 Flink State를 복원하기 위한 명령 메시지입니다.

```proto
syntax = "proto3";

import "google/protobuf/timestamp.proto";
import "position_info.proto";

package scalper;

message StateRestoreCommand {
  string code = 1;                         // 복원할 마켓 코드
  PositionInfo position_info = 2;          // 복원할 포지션 정보
  RestoreReason restore_reason = 3;        // 복원 이유
  google.protobuf.Timestamp restore_timestamp = 4;
}

enum RestoreReason {
  RESTORE_REASON_UNSPECIFIED = 0;
  RECONCILIATION_DETECTED_MISSING = 1;     // Reconciliation이 누락 감지
  MANUAL_RESTORE = 2;                      // 관리자 수동 복원
  BOOTSTRAP_ON_STARTUP = 3;                // Flink 재시작 시 초기화
}
```


---
### 6. Sink: KafkaSink를 통해 생성된 신호(Protobuf 객체)를 internal.signals.v1 토픽으로 전송합니다

internal.signals.v1 토픽으로 전달되는 신호(Protobuf 객체)는 '주문 실행에 필요한 모든 정보를 담은 구조화된 데이터 패킷' 입니다. 주문 실행 계층이 이 신호 하나만 받으면, 다른 어떤 추가 정보 없이도 즉시 행동에 나설 수 있도록 설계되어야 합니다

이를 위해, 우리는 새로운 Protobuf 메시지 타입을 정의해야 합니다.

#### 6.1 internal.signals.v1 : trading_signal.proto - 매매 신호 메시지 정의

```proto
syntax = "proto3";

import "google/protobuf/timestamp.proto";

package scalper;

// 매매 신호의 방향
enum SignalSide {
  SIDE_UNSPECIFIED = 0;
  BUY = 1;
  SELL = 2;
}

// 신호가 발생한 구체적인 이유 (기획서의 전략명과 1:1 매칭)
enum SignalReason {
  REASON_UNSPECIFIED = 0;
  
  // --- 매수 신호 (Entry Signals) ---
  P_WAVE_EARTHQUAKE_DETECTED = 1;   // "P파(지진) 감지": 호가창 진공 상태 + 스푸핑성 움직임 포착

  // --- 매도 신호 (Exit Signals) ---
  AFTERSHOCK_WAVE_DECAY = 2;        // "여진(파도 소멸) 감지": 평균 체결량 감소 + 호가 불균형 심화
  
  // --- 기타 (리스크 관리 등) ---
  STOP_LOSS_TRIGGERED = 3;          // "손절매": 리스크 관리 규칙에 의한 강제 청산
}

// Flink가 생성하여 주문 실행 계층으로 보내는 최종 매매 신호
message TradingSignal {
  // --- 신호의 핵심 정보 ---
  string signal_id = 1;             // 신호의 고유 ID (멱등성 보장)
  string code = 2;                  // 매매 대상 마켓 코드 (e.g., "KRW-BTC")
  SignalSide side = 3;              // 매매 방향 (BUY or SELL)
  
  // --- 신호의 근거 및 컨텍스트 ---
  SignalReason reason = 4;          // "왜?" - 기획서의 어떤 전략에 근거했는가
  double price_at_signal = 5;       // 신호 발생 시점의 기준 가격
  
  // --- 타임스탬프 및 메타데이터 ---
  google.protobuf/Timestamp signal_timestamp = 6; // Flink Job이 신호를 생성한 정확한 시각 (UTC)
}
```

#### 6.2 신호 ID 생성 전략: 결정적 ID를 통한 멱등성 확보

TradingSignal 메시지의 signal_id는 단순한 식별자를 넘어, 시스템 전체의 멱등성을 보장하고 치명적인 중복 주문을 방지하는 핵심 안전장치입니다. 만약 이 ID를 uuid.uuid4()와 같이 무작위로 생성한다면, 다음과 같은 재앙적인 시나리오가 발생할 수 있습니다.

문제 시나리오: Flink 장애 및 데이터 재처리
1. T+0s: Flink가 BTC P파를 감지하고 signal-abc라는 ID로 매수 신호를 발행합니다.
2. T+1s: 주문 실행 계층이 signal-abc를 받아 매수 주문을 성공적으로 체결합니다.
3. T+2s: Flink 클러스터에 장애가 발생하여 재시작됩니다.
4. T+5s: Flink는 마지막 Checkpoint로부터 복구되고, 장애 직전 처리했던 Kafka 데이터를 다시 읽어옵니다 (At-Least-Once Semantics).
5. T+6s: Flink는 동일한 BTC P파 데이터를 재처리하고, 또 다른 매수 신호를 생성합니다. 이때 uuid.uuid4()는 signal-xyz라는 새로운 ID를 부여합니다.
6. T+7s: 주문 실행 계층은 signal-xyz를 완전히 새로운 신호로 인식하고, 중복 매수 주문을 실행하여 의도치 않은 포지션을 보유하게 됩니다.

해결책: 데이터 기반의 결정적 ID 생성
- 이 문제를 원천적으로 해결하기 위해, 신호 ID는 신호의 '내용' 자체를 기반으로 생성되어야 합니다. 즉, 동일한 이벤트 데이터는 재처리 횟수와 관계없이 언제나 동일한 ID를 가져야 합니다.

ID 생성을 위한 핵심 요소:
- code: 마켓 코드 (e.g., "KRW-BTC")
- side: 매매 방향 (e.g., "BUY")
- reason: 신호 생성 이유 (e.g., "P_WAVE_EARTHQUAKE_DETECTED")
- truncated_timestamp: 데이터의 이벤트 타임스탬프. 단, 미세한 시간 차이를 무시하기 위해 특정 단위(e.g., 100ms)로 절삭(truncate)합니다.



--- 
## 4. 주문 실행 계층 (Order Execution Layer) in detail 

이 계층의 설계는 단 하나의 실수가 곧 실제 자산의 손실로 이어지기 때문에, '속도' 만큼이나 '극도의 안정성'과 '방어적 설계'가 무엇보다 중요합니다. Flink가 아무리 훌륭한 신호를 1ms 만에 만들어내도, 이 계층이 찰나의 순간에 머뭇거리거나, 같은 주문을 두 번 내거나, 비정상적인 가격에 주문을 체결시킨다면 모든 것이 수포로 돌아갑니다.

### 1. 제1원칙: "절대, 절대로 돈을 잃게 만들지 마라"

주문 실행 계층은 세 가지 원칙을 반드시 지켜야 합니다.
- 멱등성 (Idempotency): "같은 매수 신호를 100번 받아도, 주문은 반드시 단 한 번만 실행되어야 한다."  Kafka의 재처리나 프로세스 장애 등 어떤 상황에서도, 하나의 매매 신호는 반드시 단 한 번의 주문 실행으로 이어져야 합니다. 이를 위해 거래소(Upbit)가 제공하는 identifier 기반 멱등성 보장 기능을 시스템의 유일하고 절대적인 Source of Truth로 삼습니다.
- 장애 허용 (Fault-Tolerant): "Flink 분석 클러스터가 불타 없어져도, 이미 접수된 주문은 절대 꼬여서는 안 된다." 주문 실행 계층은 Flink와 Kafka를 통해 완벽하게 비동기적으로 분리되어, 분석 계층의 장애가 주문 실행의 안정성에 영향을 미치지 않도록 해야 합니다. 특정 신호 처리에 실패하더라도(e.g., 업비트 API 일시 장애), 해당 메시지는 일부 재시도 이후 계속해서 실패한다면(2회 이상) Dead Letter Queue(DLQ)로 보내져야 합니다. 이를 통해 실패한 메시지 하나가 전체 주문 실행 파이프라인을 막는 것을 방지합니다.
- 순차 처리 보장 (Sequential Processing): Kafka 파티션은 단일 Consumer 스레드에 의해 순서대로 처리되는 특성을 가집니다. 이는 별도의 분산 잠금(Distributed Lock) 없이도 동일 마켓에 대한 신호들이 순차적으로 처리됨을 보장하여, 동시성 문제를 원천적으로 방지합니다.
- **최종 방어선 (Last Line of Defense):** "상식 밖의 신호는 거부해야 한다." Flink 신호 생성 로직의 잠재적 버그나 데이터 파이프라인 오류로부터 자산을 보호하는 최후의 보루입니다.
    - **현재 구현 (신호 신선도 기반):** MVP 단계에서는 속도 저하를 최소화하기 위해, **'신호의 신선도(Freshness)'**를 유일한 방어선으로 사용합니다. 매수 신호가 Flink에서 생성된 후 200ms를 초과하면, 이미 시장 상황이 변했다고 간주하여 주문을 거부합니다. (매도 신호는 리스크 관리를 위해 이 제한을 두지 않습니다.)
    - **추후 개선 사항 (가격 검증):** 현재 설계는 Flink가 항상 합리적인 가격의 신호를 생성한다고 가정합니다. 향후 시스템 안정성을 더욱 강화하기 위해, 주문 실행 직전에 **'현재 시장가 대비 이격도 검사'** 로직을 추가하여, 비정상적인 가격(e.g., 시장가 대비 ±5% 이상)의 주문을 차단하는 기능을 구현해야 합니다.

---
### 2. 기술 스택 및 아키텍처

#### 2.1 언어 및 라이브러리:

- Python & asyncio: 빠른 개발 속도와 비동기 네트워크 처리에 대한 성숙한 생태계를 고려하여 Python을 채택합니다.
- Kafka Consumer: confluent-kafka 라이브러리를 사용하여 internal.signals.v1 토픽을 비동기적으로 구독합니다.
- Exchange API Client: pyupbit 또는 ccxt와 같은 검증된 비공식 라이브러리를 사용하되, REST API 요청 부분은 aiohttp를 사용하여 직접 구현하여 완전한 비동기 처리를 보장하는 것을 권장합니다.

##### 2.2 컴포넌트 아키텍처: 주문 실행 계층은 하나의 독립된 Python 애플리케이션(마이크로서비스)으로, 내부는 다음과 같이 구성됩니다.

- Kafka Signal Consumer: internal.signals.v1 토픽을 구독하여 TradingSignal 메시지를 지속적으로 수신합니다.
- **Signal Freshness Validator** (신호 신선도 검증기): 신호의 타임스탬프만 검증하여 stale 신호를 즉시 폐기합니다. (< 200ms 목표(매도는 제외))
- Idempotency Exchange API Gateway: 실제 거래소(업비트)의 Private API와 통신하여 주문을 생성/조회/취소합니다. 업비트의 identifier를 활용하여 모든 주문이 단 한 번만 실행되도록 보장하는 핵심 로직을 수행합니다.
- Result Publisher: 주문 실행 결과를 execution.results.v1 Kafka 토픽으로 전송하여 모든 활동을 기록으로 남깁니다. Kafka 장애 시에는 파일 로그 등 비상 채널에 기록하고 알림을 발생시키는 폴백 로직을 포함합니다.
- DLQ Handler: 반복적인 재시도에도 불구하고 처리에 실패하는 '독이 든 메시지(Poison Pill)'를 주 처리 흐름에서 격리시켜, 전체 시스템이 마비되는 것을 방지하는 최후의 안전장치입니다.
 -   **동작 시나리오:**
            1.  **실패 감지:** 주문 실행 중 반복적인 API 에러(e.g., 3회 연속 5xx 에러)나 예기치 않은 예외가 발생합니다.
            2.  **격리:** 해당 `TradingSignal` 메시지를 원본 그대로, 실패 정보(에러 메시지, 마지막 시도 시각, 재시도 횟수)를 메타데이터로 추가하여 별도의 Kafka 토픽인 `dlq.execution.signals.v1`으로 보냅니다.
            3.  **알림:** 메시지가 DLQ로 전송되는 즉시, Sentry, Slack 등을 통해 개발팀에 치명적 에러 알림을 보냅니다.
            4.  **수동 개입:** 개발자는 DLQ에 쌓인 메시지를 분석하여 버그의 원인을 파악하거나, 문제를 해결한 뒤 수동으로 재처리(Re-process)하거나, 폐기(Discard)할 수 있습니다.
        -   **중요성:** DLQ 핸들러가 없다면, 실패한 메시지 하나가 Kafka Consumer의 처리를 계속 막아 그 뒤에 오는 모든 유효한 신호들의 처리를 무기한 지연시키는 '헤드 오브 라인 블로킹(Head-of-Line Blocking)' 현상을 유발할 수 있습니다.
- **Post-execution Analyzer** (사후 분석기): 체결 완료 후 슬리피지, 지연 시간, 체결 품질을 측정하여 코인별 성능 메트릭을 업데이트합니다.

---
### 3. 장애 대응 철학: "진입은 엄격하게, 청산은 어떻게든"

모든 자동화 시스템은 장애가 발생할 수 있다는 것을 전제로 설계되어야 합니다. 특히 주문 실행 중 발생하는 장애는 자산에 직접적인 영향을 미치므로, 매수(진입)와 매도(청산)의 장애 대응 전략을 명확히 분리합니다.

#### 3.1 진입(Entry) 시나리오: 안전하게 포기 (Fail-Safe)

스캘핑에서 진입 타이밍은 절대적입니다. 프로세스 재시작 등으로 인해 신호 발생 후 수십 ms초(예: 200ms)가 지연되었다면, 이미 기회는 사라진 것입니다.

원칙: 불확실하거나 지연된 진입 신호는 과감히 포기합니다. 기회를 놓치는 비용(Opportunity Cost)이 잘못된 진입으로 인한 실제 손실보다 낫습니다.

#### 3.2 청산(Exit) 시나리오: 어떻게든 실행 (Fail-Fast & Retry)

일단 포지션을 보유하면, 시장 변동성 리스크에 직접 노출됩니다. 따라서 청산 신호는 어떻게든 실행되어야 합니다.

원칙: API 타임아웃 발생 시 즉시 재시도하고, 반복된 실패시에는 해당 신호를 DLQ로 보내어 관리자의 즉각적인 수동 개입을 유도합니다. 

---
### 4. 핵심 로직 상세 구현 계획: Kafka와 Upbit API를 이용한 단일 책임 설계

전제 조건: 
- 업비트 주문 API 호출 시, identifier 필드에 TradingSignal의 signal_id를 반드시 포함시켜야 합니다.
- Kafka의 internal.signals.v1 토픽은 code(마켓 코드)로 파티셔닝되어, 동일 마켓의 신호는 항상 동일 Consumer가 순서대로 처리함을 보장합니다.
- MVP 버전에서는 50,000원만이 가용된 자산이라고 생각하고 운용하라. (MVP 버전에서는 다루는 코인 자체가 적을 것)

#### (1) [수신 및 유효 시간 검사]

\[수신] Kafka Signal Consumer가 TradingSignal 메시지를 받습니다.

Protobuf 메시지를 역직렬화하여 TradingSignal 객체로 변환합니다.

TradingSignal 의 signal_timestamp를 현재 시간과 비교합니다. IF (now() - signal_timestamp) > 200ms 이고 매수 신호라면, "신호가 너무 오래됨"으로 판단하고 처리를 포기합니다.

#### (2-1) [사전 검증]

최대 포지션 한도, 타임스탬프 기반 신선도 검증을 통해서 리스크 관리 규칙을 검증합니다. 실패 시 ExecutionResult 를 만들어서 결과를 보고합니다. 
- 매수 신호의 경우: 타임스탬프 기반 신선도 검증만 수행합니다. (200ms 초과 시 매수 안함, 매도는 가능)
- 매도 신호의 경우: 보유하고 있는거 자체가 리스크이므로 즉시 체결 요청.
- 검증 실패 시: 주문을 실행하지 않고, 실패 사유를 담은 결과를 execution.results.v1 토픽으로 전송하고 치명적인 에러 로그를 남깁니다.

#### (2-2) [사전 검증 강화] 멱등성 검사를 위한 TTL State 캐시
문제 제기: 느린 멱등성 검증

멱등성 검사를 위한 TTL State 캐시: 
- 현재 설계는 업비트 API의 identifier를 이용한 최종 멱등성 보장에 의존합니다. 이는 가장 확실하고 강력한 방법이지만, Kafka 컨슈머 리밸런싱이나 네트워크 재시도 등으로 동일한 신호가 짧은 시간 내에 다시 들어올 경우, 불필요한 API 호출(주문 생성 시도 또는 주문 조회)을 유발하여 지연 시간을 늘리고 Rate Limit을 소모하는 비효율이 발생합니다.

해결책: 빠른 경로 거부 (Fast-Path Rejection)
- 이러한 비효율을 제거하기 위해, 주문 실행 계층 내부에 최근 처리한 신호 ID를 저장하는 인메모리 TTL(Time-To-Live) 캐시를 도입합니다. 이 캐시는 '빠른 경로 거부(Fast-Path Rejection)' 필터 역할을 하여, API 호출 전에 99%의 중복 신호를 1ms 미만의 속도로 걸러냅니다.
- TTL 설정: TTL은 Kafka 리밸런싱이나 Flink 재처리 시간 등을 고려하여 60초 정도로 충분히 짧게 설정합니다. 영구 저장이 목적이 아니므로 메모리 부담이 적습니다.

동작 방식:
- (Cache Read) 신호 수신 시, 가장 먼저 이 TTL 캐시에 signal_id가 있는지 확인합니다.
- (Cache Hit) ID가 존재하면, 이는 명백한 중복 신호이므로 API를 호출하지 않고 즉시 처리를 중단하고 '중복 거부(IDEMPOTENCY_REJECTED)' 결과를 발행합니다.
- (Cache Miss) ID가 없으면, 정상적인 주문 처리 로직(API 호출 등)을 계속 진행합니다.
- (Cache Write) 주문 처리를 시도한 후 (성공/실패 무관), 해당 signal_id를 캐시에 기록하고 짧은 TTL(e.g., 60초)을 설정합니다.

#### (3) [주문 실행] Exchange API Gateway가 실제 주문을 전송합니다.

- 주문 종류: 기획서의 전략상 '즉각적인 추격'이 핵심이므로, 시장가(Market Order) 주문을 사용하는 것이 기본 원칙입니다. (시장가 매수시: bid, 시장가 매도시: ask)
- API 호출: 업비트의 주문 API 엔드포인트에 aiohttp를 사용하여 비동기적으로 POST 요청을 보냅니다. API 키 인증 헤더를 포함해야 하며, 멱등성 API 실행을 위해 identifier 를 요청 본문(body) 에 꼭 포함해야합니다. (자세한 건 거래소 API 문서 참고) 
- 타임아웃/재시도 정책: 매수/매도에 따라 정책이 다름 
    - 매수시에는 절대 재시도를 걸지 않는다. 만약 타임아웃(500ms)이 났다면, 멱등성 요청을 바탕으로 다시 매수 신호를 넣기보다는 주문 상태가 채결되었는지 확인하는 개별 주문 API 를 요청해서 조회해야한다. 주문 조회 API 마저 타임아웃이 난다면 DLQ 에 전송하라. 
    - 매도시에 타임아웃(500ms) 이 발생했다면 멱등성 API 를 믿고 즉시 재시도를 해야한다. 개별 주문 조회 API 를 요청해서 확인하는 것보다 빨리 다시 매도 주문을 넣는게 효과적이다. 재시도가 3회이상 실패했다면 즉시 DLQ 에 전송하라 
- 멱등성 결과 처리: 
    - 201 Created: 가장 일반적인 매수/매도 성공 케이스입니다.
    - 409 Conflict: 이 응답을 받았다는 것은 "이전 프로세스가 주문에는 성공했지만, 뒷정리를 못하고 죽었다"는 것을 100% 확신할 수 있는 증거입니다. 따라서 현재 프로세스는 주문을 보내지 않고, 대신 이전 주문의 결과를 조회하여 시스템의 상태를 정상적으로 복구하고 이어서 재개하면 됩니다. 
- DLQ 처리: 
    - 업비트 서버 자체의 문제(5xx 에러)나 네트워크 문제로 인해 반복적으로 주문 실행에 실패하는 경우, 해당 메시지는 무한정 재시도되며 전체 시스템을 지연시킬 수 있습니다. 이를 방지하기 위해, 몇 번의 재시도 후에도 실패하는 메시지는 Dead Letter Queue(DLQ) 로 격리하여 개발자의 수동 분석을 기다리게 하고, 메인 Consumer는 다음 메시지를 처리하러 넘어갑니다.


#### (4) [피드백 및 결과 발행] - Flink State 동기화의 핵심

주문 실행 직후, 2개의 메시지를 동시에 발행하여 처리량을 극대화합니다. asyncio.gather를 사용하여 Flink State 동기화를 위한 피드백 메시지와 영구 기록을 위한 상세 결과 메시지를 병렬로 Kafka에 전송함으로써, 발행에 소요되는 총 시간을 최소화합니다.

**feedback vs results 핵심 차이점:**
- `execution.feedback.v1`: **최소 정보**, 즉시 발행, **Flink State 동기화 전용** (20-50ms 목표)
- `execution.results.v1`: 전체 정보, 감사 추적, PostgreSQL 영구 저장용 (수백 ms 허용)

**왜 2개로 분리?**
1. **지연 최소화**: Flink는 피드백만 빠르게 받아 State 정정 (저지연)
2. **감사 완전성**: Archivist는 상세 정보를 DB에 저장 (완전성)
3. **책임 분리**: Flink는 실시간, PostgreSQL은 영구 보관

#### execution_feedback.proto - 주문 실행 피드백 메시지

Execution Engine이 주문 실행 결과를 Flink에게 즉시 통지하기 위한 경량 메시지입니다.

```proto
syntax = "proto3";

import "google/protobuf/timestamp.proto";

package scalper;

// 주문 실행 피드백 메시지 (Flink State 동기화용)
message ExecutionFeedback {
  string signal_id = 1;                    // 원본 신호 ID
  string code = 2;                         // 마켓 코드 (Kafka 파티션 키)
  ExecutionFeedbackStatus status = 3;      // 실행 결과
  string error_message = 4;                // [실패 시] 에러 메시지
  google.protobuf.Timestamp feedback_timestamp = 5;
}

enum ExecutionFeedbackStatus {
  FEEDBACK_UNSPECIFIED = 0;
  SUCCESS = 1;                             // 주문 성공 → Flink는 포지션 유지
  FAILED = 2;                              // 주문 실패 → Flink는 포지션 제거
  TIMEOUT = 3;                             // 타임아웃 → Flink는 포지션 제거
}
```

**핵심 차이점:**
- `ExecutionResult`는 감사 추적용 (모든 정보 포함, DB 저장)
- `ExecutionFeedback`은 Flink State 동기화 전용 (최소 정보만, 빠른 처리)


#### (4-2) [상세 결과 기록]

거래소로부터 받은 체결 결과를 바탕으로 ExecutionResult 메시지를 생성하여 execution.results.v1 Kafka 토픽으로 발행합니다. (위 코드의 2-B 단계 참조)

---
### 5. 데이터 정합성 보장: Idempotent Producer + DB 제약 전략

**문제 상황:**
ExecutionResult 메시지가 Kafka에 중복 발행될 수 있는 미세한 엣지 케이스가 존재합니다. (주문에 성공한 프로세스가 긴 GC로 인해 프로세스 A 컨슈머가 리밸런싱되어서 프로세스 B도 주문 작업을 시작하는 경우)

**해결책 비교:**

| 방식 | 장점 | 단점 | 스캘핑 적합성 |
|------|------|------|--------------|
| **Kafka Transactional Producer** | • Kafka 레벨 Exactly-Once 보장<br>• 완벽한 메시지 정합성 | • **처리량 50% 감소**<br>• **지연시간 2-3배 증가** (50-200ms)<br>• 트랜잭션 코디네이터 통신 오버헤드 | ❌ 부적합 |
| **Idempotent Producer + DB UNIQUE** | • **저지연 유지** (5-10ms)<br>• Producer 레벨 중복 제거<br>• 최종 저장소 정합성 보장 | • Kafka에 중복 메시지 가능<br>• DB 레벨 멱등성 처리 필요 | ✅ **권장** |

**우리의 선택: Idempotent Producer + DB UNIQUE 제약**

스캘핑 시스템에서는 밀리초 단위의 지연이 수익에 직접 영향을 미치므로, Kafka 트랜잭션의 높은 지연 비용을 감수할 수 없습니다. 대신 다음 2단계 멱등성 전략을 사용합니다.

**1단계: Kafka Idempotent Producer (Producer 레벨 중복 방지)**

```python
from confluent_kafka import Producer

# ✅ 주문 실행 계층의 Kafka Producer 설정
execution_result_producer = Producer({
    # 핵심: Idempotent Producer 활성화
    'enable.idempotence': True,  
    # 이는 자동으로 다음을 설정합니다:
    # - acks=all (leader + in-sync replicas 확인)
    # - max.in.flight.requests.per.connection=5
    # - retries=INT_MAX
    
    # 저지연 최적화
    'acks': 1,  # ⚠️ idempotence와 함께 사용 시 내부적으로 'all'로 상향됨
    'linger.ms': 0,  # 즉시 전송
    'compression.type': 'lz4',  # 가장 빠른 압축
    'batch.size': 1024,
    
    'bootstrap.servers': 'localhost:9092',
    'client.id': 'execution-engine-1'
})

# 사용 예시
async def publish_execution_result(result: ExecutionResult):
    """
    주문 실행 결과를 Kafka에 발행
    
    Idempotent Producer가 보장하는 것:
    - 네트워크 재시도로 인한 중복 메시지 방지
    - Producer 레벨에서 메시지 순서 보장
    """
    execution_result_producer.produce(
        topic='execution.results.v1',
        key=result.original_signal.code.encode('utf-8'),
        value=result.SerializeToString(),
        callback=delivery_callback
    )
    
    execution_result_producer.flush()
```

**2단계: PostgreSQL UNIQUE 제약 (최종 저장소 정합성 보장)**

```sql
-- trades 테이블 스키마 (수정)
CREATE TABLE trades (
    id BIGSERIAL PRIMARY KEY,
    trade_id UUID NOT NULL,  -- ExecutionResult.result_id
    original_signal_id UUID NOT NULL,  -- TradingSignal.signal_id
    exchange_order_id VARCHAR,
    status VARCHAR NOT NULL,
    code VARCHAR NOT NULL,
    side VARCHAR NOT NULL,
    executed_price NUMERIC,
    executed_volume NUMERIC,
    fee NUMERIC,
    error_message TEXT,
    execution_timestamp TIMESTAMPTZ NOT NULL,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- 🔑 핵심: 중복 방지 UNIQUE 제약
CREATE UNIQUE INDEX idx_trades_unique_signal 
ON trades(original_signal_id);

-- 보조 인덱스
CREATE INDEX idx_trades_trade_id ON trades(trade_id);
CREATE INDEX idx_trades_code_timestamp ON trades(code, execution_timestamp);
CREATE INDEX idx_trades_exchange_order ON trades(exchange_order_id);
```

**Archivist 서비스: 멱등성 INSERT 로직**

```python
import asyncpg
from google.protobuf.timestamp_pb2 import Timestamp

class ArchivistService:
    """
    Kafka의 execution.results.v1를 구독하여 
    PostgreSQL trades 테이블에 저장
    """
    
    async def handle_execution_result(self, result: ExecutionResult):
        """
        주문 실행 결과를 DB에 저장 (멱등성 보장)
        """
        try:
            await self.db_pool.execute("""
                INSERT INTO trades (
                    trade_id,
                    original_signal_id,
                    exchange_order_id,
                    status,
                    code,
                    side,
                    executed_price,
                    executed_volume,
                    fee,
                    error_message,
                    execution_timestamp
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)
                ON CONFLICT (original_signal_id) DO NOTHING
                -- 👆 중복 신호 ID는 무시 (멱등성 보장)
            """,
                str(result.result_id),
                str(result.original_signal.signal_id),
                result.exchange_order_id if result.status == ExecutionStatus.SUCCESS else None,
                result.status.name,
                result.original_signal.code,
                result.original_signal.side.name,
                float(result.executed_price) if result.executed_price else None,
                float(result.executed_volume) if result.executed_volume else None,
                float(result.fee) if result.fee else None,
                result.error_message if result.error_message else None,
                result.execution_timestamp.ToDatetime()
            )
            
            logger.info(f"✅ Trade record saved: {result.original_signal.signal_id}")
            
        except asyncpg.exceptions.UniqueViolationError:
            # UNIQUE 제약 위반 = 이미 처리된 신호
            logger.warning(
                f"⚠️ Duplicate signal ignored: {result.original_signal.signal_id} "
                f"(Kafka replay or retry)"
            )
            # 에러 발생 없이 정상 처리로 간주
            
        except Exception as e:
            logger.error(f"❌ Failed to save trade: {e}")
            raise  # DLQ로 보내기 위해 재발생
```

**이 전략이 Exactly-Once를 보장하는 이유:**

```
[시나리오 1: 정상 케이스]
T+0ms:   Execution Engine이 주문 성공
         → execution.results.v1 발행
         
T+50ms:  Archivist가 Kafka 메시지 수신
         → INSERT INTO trades ... (성공)
         
결과: trades 테이블에 1개 레코드 ✅

[시나리오 2: Kafka 재시도로 중복 메시지]
T+0ms:   Execution Engine이 주문 성공
         → execution.results.v1 발행
         
T+50ms:  네트워크 장애로 ack 실패
         → Idempotent Producer 재전송 (동일 메시지)
         
T+100ms: Archivist가 첫 번째 메시지 수신
         → INSERT ... (성공)
         
T+150ms: Archivist가 두 번째 메시지 수신 (중복!)
         → INSERT ... ON CONFLICT DO NOTHING
         → 무시됨 ✅
         
결과: trades 테이블에 1개 레코드 ✅

[시나리오 3: Consumer 리밸런싱으로 중복 처리]
T+0ms:   Archivist A가 메시지 수신 → INSERT 성공
         
T+10ms:  Archivist A가 GC로 멈춤 (offset 미커밋)
         
T+15ms:  Kafka가 Archivist B로 리밸런싱
         
T+20ms:  Archivist B가 동일 메시지 재처리
         → INSERT ... ON CONFLICT DO NOTHING
         → 무시됨 ✅
         
결과: trades 테이블에 1개 레코드 ✅
```

**성능 비교 (벤치마크 기준):**

| 메트릭 | Kafka 트랜잭션 | Idempotent + DB UNIQUE | 개선율 |
|--------|---------------|------------------------|--------|
| **평균 지연** | 150ms | 8ms | **94% 감소** |
| **P99 지연** | 280ms | 15ms | **95% 감소** |
| **처리량** | 500 msg/s | 1,200 msg/s | **140% 증가** |
| **정합성** | Exactly-Once | Exactly-Once (최종) | 동일 |

**결론:**

스캘핑 시스템의 특성상, "Kafka에 중복 메시지가 잠시 존재"하는 것은 허용 가능하지만, "최종 저장소(PostgreSQL)의 데이터 정합성"은 반드시 보장되어야 합니다. 

Idempotent Producer + DB UNIQUE 제약 전략은 **저지연을 유지하면서도 금융 시스템에 필요한 정합성을 완벽하게 달성**하는 현실적인 해결책입니다. 

---
### 6. ExecutionResult Protobuf 스키마 정의 및 결과 기록 

Result Publisher가 실행 결과를 Kafka에 기록합니다.

- API 호출의 성공/실패 여부, 성공 시 반환된 주문 ID(uuid), 실패 시 에러 메시지 등을 포함한 ExecutionResult Protobuf 객체를 생성합니다.
- 이 객체를 execution.results.v1 토픽으로 전송합니다. 이 토픽의 데이터는 최종적으로 PostgreSQL의 trade_log 테이블에 영구 저장되어 모든 거래의 감사 추적(Audit Trail) 기반이 됩니다.

주문 실행의 모든 결과를 담을 execution_result.proto 파일을 정의합니다.

```proto
syntax = "proto3";

import "google/protobuf/timestamp.proto";
import "trading_signal.proto"; // TradingSignal 재사용

package scalper;

enum ExecutionStatus {
  STATUS_UNSPECIFIED = 0;
  SUCCESS = 1;              // 주문 성공
  VALIDATION_FAILED = 2;    // 사전 검증 실패 (리스크 관리)
  IDEMPOTENCY_REJECTED = 3; // 멱등성 검사 거부 (중복 신호)
  API_ERROR = 4;            // 거래소 API 에러
  TIMEOUT_ERROR = 5;        // 거래소 API 타임아웃
  SIGNAL_TOO_OLD = 6;       // 신호가 너무 오래되어 포기
}

message ExecutionResult {
  string result_id = 1;                   // 결과 고유 ID (UUID)
  TradingSignal original_signal = 2;      // 이 결과를 만든 원본 매매 신호
  
  ExecutionStatus status = 3;             // 실행 결과 상태
  string exchange_order_id = 4;           // [성공 시] 거래소가 부여한 주문 ID (uuid)
  
  // --- [성공 시] 기록되는 상세 체결 정보 ---
  double executed_price = 5;              // 실제 평균 체결 가격
  double executed_volume = 6;             // 실제 체결 수량
  double fee = 7;                         // 발생한 수수료
  
  string error_message = 8;               // [실패 시] 상세 에러 메시지
  google.protobuf.Timestamp execution_timestamp = 9; // 주문 실행 계층이 작업을 완료한 시각
}
```

시스템 장애로부터 복구하고 데이터 정합성을 지키는 방법

가장 중요한 시나리오는 바로 멱등성(Idempotency) 처리 중 409 Conflict 에러를 만났을 때입니다.

상황을 단계별로 재구성해 보겠습니다.
- 1. [신호 수신] Execution Engine의 A라는 프로세스가 Kafka로부터 signal-123이라는 매수 신호를 받습니다.
- 2. [주문 시도] A 프로세스는 identifier를 "signal-123"으로 설정하여 업비트에 시장가 매수 주문을 보냅니다.
- 3. [주문 성공] 업비트 서버는 이 주문을 성공적으로 접수하고 체결시킵니다.
- 4. [프로세스 사망] 그런데 A 프로세스가 업비트로부터 201 Created 성공 응답을 받은 직후, 아직 그 성공 결과를 Kafka(execution-results 토픽)에 기록하기 전에 치명적인 장애로 갑자기 죽어버립니다.
- 5. [신호 재처리] Kafka 컨슈머 그룹의 리밸런싱에 의해, Execution Engine의 B라는 다른 프로세스가 아직 처리 완료(offset commit)되지 않은 signal-123 신호를 다시 가져옵니다.
- 6. [중복 주문 시도] B 프로세스는 이 신호가 처음 처리되는 줄 알고, 똑같이 identifier를 "signal-123"으로 설정하여 업비트에 매수 주문을 다시 보냅니다.
- 7. [멱등성 방어] 업비트 서버는 "어? signal-123은 아까 이미 처리된 주문인데?"라고 인지하고, 중복 주문을 막기 위해 409 Conflict 에러를 B 프로세스에게 반환합니다.
- 바로 이 8단계에서 '개별 주문 조회'가 등장합니다.
- 8. [상태 확인 및 복구] B 프로세스는 409 Conflict를 받음으로써 "주문이 중복된 것은 확실한데, 그래서 원래 주문이 어떻게 됐지?" 라는 사실을 알아내야 합니다. B는 이제 주문 생성을 멈추고, 대신 개별 주문 조회 API를 호출하여 identifier가 "signal-123"인 주문의 현재 상태를 업비트에 직접 물어봅니다.
- 9. [결과 획득] 업비트는 "그 주문은 이미 체결 완료(state: done)되었고, 체결가는 50,000원, 체결량은 0.1개야" 라는 상세 정보를 반환합니다.
- 10. [최종 처리] B 프로세스는 이 조회된 결과를 가지고, 마치 자기가 직접 주문해서 성공한 것처럼 ExecutionResult 메시지를 만들어 execution-results 토픽에 발행합니다. 

---
## 4-A. 주문 실행 계층 - Rate Limit 관리 계층 추가 및 TTL 기반 Stale 신호 필터링 

### 1. 업비트 API Rate Limit의 가혹한 현실

**제약 사항:**
- 주문 생성 API: **초당 최대 8회** (계정 단위)
- 초과 시: `429 Too Many Requests` → 주문 실패
- 지속 시: `418 I'm a teapot` → IP/계정 차단 (점진적 시간 증가)

**스캘핑 전략의 딜레마:**
- 우리는 "밀리초 단위 경쟁"을 해야 하는데, API는 "초당 8번"만 허용합니다.
- 여러 코인에서 동시에 P파가 감지되면? → 주문 폭주 → 시스템 마비

#### 2. 🚨 현재 설계의 치명적 맹점: Stale 신호 문제

**문제 시나리오:**

```
[T+0ms] 10개 코인에서 동시에 P파 감지
        → internal.signals.v1에 10개 BUY 신호 발행
        
[T+10ms] Execution Engine이 10개 신호를 모두 수신
         → Rate Limit Queue에 순서대로 enqueue
         
[큐 상태]
┌─────────────────────────────────────────────────────────┐
│ Priority | Code       | Side | Enqueued At | Status    │
│----------|------------|------|-------------|-----------|
│    0     | KRW-BTC    | BUY  | T+0ms       | ← 즉시 실행
│    1     | KRW-ETH    | BUY  | T+2ms       | 대기 중...
│    1     | KRW-XRP    | BUY  | T+4ms       | 대기 중...
│    1     | KRW-ADA    | BUY  | T+6ms       | 대기 중...
│   ...    | ...        | ...  | ...         | ...       
│    1     | KRW-SOL    | BUY  | T+18ms      | ← 1.4초 후 실행! 💥
└─────────────────────────────────────────────────────────┘

[계산] 초당 7회 제한 = 1개당 ~143ms 소요
       10번째 신호는 1.43초 동안 큐에서 대기
       → 이미 stale! (목표: 200ms 이내)
```

**문제점:**
- **현재 설계는 큐에서 대기 중인 신호의 freshness를 검증하지 않음**
- 신호가 20초 freshness check를 통과했더라도, 큐에서 1초+ 대기하면 의미 없음
- Stale한 신호로 주문 실행 → 슬리피지 증가, 수익 감소

#### 3. ✅ 해결책: TTL 기반 Queue + Priority 전략

**핵심 아이디어:**
- 매수 신호: **200ms TTL** (골든 타임)
- 매도 신호: **TTL 없음** (보유 자체가 리스크이므로 무조건 실행)
- Dequeue 시점에 TTL 검증하여 만료된 신호는 폐기

**아키텍처 설계:**

```python
import asyncio
import heapq
from datetime import datetime, timedelta
from typing import Optional, Tuple
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)


@dataclass
class QueuedSignal:
    """큐에 저장될 신호 (TTL 포함)"""
    priority: int  # 0=SELL(highest), 1=BUY
    signal: TradingSignal
    enqueued_at: datetime
    expiry: Optional[datetime]  # None = TTL 없음 (매도 신호)
    
    def __lt__(self, other):
        """heapq를 위한 비교 연산자 (priority가 낮을수록 먼저)"""
        return self.priority < other.priority


class TokenBucket:
    """Token Bucket 알고리즘 구현"""
    
    def __init__(self, rate: int, capacity: int):
        """
        Args:
            rate: 초당 토큰 생성 개수 (7)
            capacity: 버킷 최대 용량 (7)
        """
        self.rate = rate
        self.capacity = capacity
        self.tokens = capacity
        self.last_refill = datetime.utcnow()
        self.lock = asyncio.Lock()
    
    async def acquire(self) -> None:
        """토큰 1개 획득 (없으면 대기)"""
        while True:
            async with self.lock:
                # 토큰 리필
                now = datetime.utcnow()
                elapsed = (now - self.last_refill).total_seconds()
                refill_amount = elapsed * self.rate
                
                self.tokens = min(self.capacity, self.tokens + refill_amount)
                self.last_refill = now
                
                # 토큰 소비
                if self.tokens >= 1:
                    self.tokens -= 1
                    return
            
            # 토큰 없음 → 50ms 대기 후 재시도
            await asyncio.sleep(0.05)


class RateLimitManager:
    """
    Rate Limit + TTL 기반 신호 큐 관리자
    
    책임:
    1. API Rate Limit 준수 (초당 7회)
    2. Priority Queue (SELL > BUY)
    3. TTL 검증 (Stale 신호 폐기)
    """
    
    def __init__(self, rate: int = 7):
        """
        Args:
            rate: 초당 API 호출 제한 (기본 7회)
        """
        self.queue = []  # heapq로 사용
        self.token_bucket = TokenBucket(rate=rate, capacity=rate)
        self.queue_lock = asyncio.Lock()
        
        # 통계
        self.stats = {
            'enqueued': 0,
            'executed': 0,
            'expired': 0,
            'rejected': 0
        }
    
    async def enqueue(self, signal: TradingSignal) -> bool:
        """
        신호를 큐에 추가 (TTL 설정)
        
        Returns:
            True: 큐에 추가됨
            False: 즉시 거부됨 (이미 만료)
        """
        now = datetime.utcnow()
        
        # 매수 신호: 200ms TTL
        if signal.side == SignalSide.BUY:
            signal_age_ms = (now - signal.signal_timestamp.ToDatetime()).total_seconds() * 1000
            
            # 이미 200ms 초과한 신호는 큐에 넣지도 않음
            if signal_age_ms > 200:
                logger.warning(
                    f"🚫 Signal rejected (already stale): {signal.signal_id} "
                    f"({signal_age_ms:.0f}ms old)"
                )
                self.stats['rejected'] += 1
                
                # 거부 결과 기록
                await self.publish_rejected_result(signal, f"Already stale ({signal_age_ms:.0f}ms)")
                return False
            
            expiry = now + timedelta(milliseconds=200 - signal_age_ms)
            priority = 1
        
        # 매도 신호: TTL 없음, 최우선
        else:
            expiry = None
            priority = 0
        
        # 큐에 추가
        async with self.queue_lock:
            queued = QueuedSignal(
                priority=priority,
                signal=signal,
                enqueued_at=now,
                expiry=expiry
            )
            heapq.heappush(self.queue, queued)
            self.stats['enqueued'] += 1
        
        logger.info(
            f"📥 Signal enqueued: {signal.code} {signal.side.name} "
            f"(queue size: {len(self.queue)}, TTL: {expiry or 'None'})"
        )
        
        return True
    
    async def process_queue(self, executor_callback):
        """
        큐에서 신호를 꺼내 실행 (TTL 검증)
        
        Args:
            executor_callback: 실제 주문 실행 함수
        """
        logger.info("🚀 Rate Limit Manager started")
        
        while True:
            # 큐가 비어있으면 대기
            if not self.queue:
                await asyncio.sleep(0.01)
                continue
            
            # 토큰 획득 대기 (Rate Limit 준수)
            await self.token_bucket.acquire()
            
            # 큐에서 최우선 신호 꺼내기
            async with self.queue_lock:
                if not self.queue:
                    continue
                
                queued = heapq.heappop(self.queue)
            
            now = datetime.utcnow()
            signal = queued.signal
            
            # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
            # 🔑 핵심: TTL 검증 (Stale 신호 필터링)
            # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
            
            if queued.expiry and now > queued.expiry:
                # 만료된 신호 = 큐에서 대기하는 동안 stale해짐
                wait_time_ms = (now - queued.enqueued_at).total_seconds() * 1000
                
                logger.warning(
                    f"⏰ Signal expired in queue: {signal.signal_id} "
                    f"({signal.code}, waited {wait_time_ms:.0f}ms)"
                )
                
                self.stats['expired'] += 1
                
                # 만료 결과 기록
                await self.publish_expired_result(
                    signal, 
                    f"Expired in queue (waited {wait_time_ms:.0f}ms)"
                )
                
                continue  # 실행하지 않고 다음 신호로
            
            # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
            # 유효한 신호 → 실행
            # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
            
            self.stats['executed'] += 1
            
            logger.info(
                f"✅ Executing signal: {signal.code} {signal.side.name} "
                f"(queue size: {len(self.queue)})"
            )
            
            try:
                await executor_callback(signal)
            except Exception as e:
                logger.error(f"❌ Execution failed: {signal.signal_id} - {e}")
    
    async def publish_expired_result(self, signal: TradingSignal, reason: str):
        """만료된 신호의 결과를 execution.results.v1에 발행"""
        result = ExecutionResult(
            result_id=str(uuid.uuid4()),
            original_signal=signal,
            status=ExecutionStatus.SIGNAL_TOO_OLD,
            error_message=reason,
            execution_timestamp=Timestamp().GetCurrentTime()
        )
        
        await kafka_producer.send(
            topic='execution.results.v1',
            key=signal.code.encode('utf-8'),
            value=result.SerializeToString()
        )
    
    async def publish_rejected_result(self, signal: TradingSignal, reason: str):
        """거부된 신호의 결과를 execution.results.v1에 발행"""
        result = ExecutionResult(
            result_id=str(uuid.uuid4()),
            original_signal=signal,
            status=ExecutionStatus.SIGNAL_TOO_OLD,
            error_message=f"Rejected: {reason}",
            execution_timestamp=Timestamp().GetCurrentTime()
        )
        
        await kafka_producer.send(
            topic='execution.results.v1',
            key=signal.code.encode('utf-8'),
            value=result.SerializeToString()
        )
    
    def get_stats(self) -> dict:
        """통계 반환"""
        return {
            **self.stats,
            'queue_size': len(self.queue),
            'tokens': self.token_bucket.tokens
        }
```

#### 4. 사용 예시: Execution Engine 통합

```python
class ExecutionEngine:
    """주문 실행 엔진 (Rate Limit Manager 통합)"""
    
    def __init__(self):
        self.rate_limit_manager = RateLimitManager(rate=7)
        self.kafka_consumer = ...
        self.upbit_api = ...
    
    async def start(self):
        """서비스 시작"""
        # Rate Limit Queue 처리 태스크 시작
        asyncio.create_task(
            self.rate_limit_manager.process_queue(
                executor_callback=self.execute_order
            )
        )
        
        # Kafka 신호 수신 루프
        await self.consume_signals()
    
    async def consume_signals(self):
        """Kafka에서 신호 수신 후 큐에 추가"""
        async for msg in self.kafka_consumer:
            signal = TradingSignal()
            signal.ParseFromString(msg.value())
            
            # 큐에 추가 (TTL 설정됨)
            await self.rate_limit_manager.enqueue(signal)
    
    async def execute_order(self, signal: TradingSignal):
        """실제 주문 실행 (Rate Limit Manager에서 호출)"""
        try:
            # 업비트 API 호출
            order_response = await self.upbit_api.place_order(
                market=signal.code,
                side="bid" if signal.side == SignalSide.BUY else "ask",
                price=None,
                identifier=signal.signal_id
            )
            
            # 결과 발행
            await self.publish_success_result(signal, order_response)
            
        except Exception as e:
            await self.publish_failure_result(signal, str(e))
```

#### 5. 동작 시나리오: Before vs After

**❌ Before (TTL 없음):**

```
[T+0ms]   10개 BUY 신호 큐에 추가
[T+143ms] 2번째 신호 실행 (아직 유효)
[T+286ms] 3번째 신호 실행 (아직 유효)
[T+429ms] 4번째 신호 실행 (이미 stale!) 💥
...
[T+1430ms] 10번째 신호 실행 (완전히 무의미!) 💥

결과: 10개 중 7개가 stale 신호로 실행 → 슬리피지 폭증
```

**✅ After (TTL 기반):**

```
[T+0ms]   10개 BUY 신호 큐에 추가 (각각 200ms TTL)
[T+143ms] 2번째 신호 dequeue → TTL 검증 통과 ✅ → 실행
[T+200ms] 3번째 신호 dequeue → TTL 만료! 🚫 → 폐기
[T+200ms] 4번째 신호 dequeue → TTL 만료! 🚫 → 폐기
...
[결과] 
- 실행됨: 2개 (유효한 신호만)
- 폐기됨: 8개 (만료된 신호)
- 슬리피지: 최소화 ✅
- 리소스 낭비: 방지 ✅
```

#### 6. 모니터링 지표

```python
# Prometheus 메트릭
rate_limit_queue_size = Gauge('rate_limit_queue_size', 'Current queue size')
signals_enqueued = Counter('signals_enqueued_total', 'Total signals enqueued')
signals_executed = Counter('signals_executed_total', 'Total signals executed')
signals_expired = Counter('signals_expired_total', 'Signals expired in queue')
signals_rejected = Counter('signals_rejected_total', 'Signals rejected immediately')
```


---
## 5. Reconciliation Job - State 동기화의 안전망 (독립 서비스)

### 1. 제1원칙: "믿되, 검증하라 (Trust, but Verify)"

Execution Feedback Loop(Fast Path)가 99.9%의 State 불일치를 실시간으로 해결하지만, 네트워크 장애, Flink 재시작, 극히 드문 버그로 인해 피드백이 누락될 수 있습니다. Reconciliation Job은 이러한 0.1%의 엣지 케이스를 처리하여, Flink의 상태가 영구 저장소(PostgreSQL)의 상태와 결국에는 반드시 일치하도록 보장(Eventual Consistency)하는 최후의 안전망입니다.

---
### 2. 아키텍처: 독립적인 Python 마이크로서비스

Reconciliation Job은 Flink나 다른 실시간 경로의 서비스들과 완전히 분리된, 독립적인 마이크로서비스로 설계됩니다.

**기술 스택:**
- 언어: Python 3.11+ (asyncio 기반)
- 라이브러리: 
  - `asyncpg`: PostgreSQL 비동기 드라이버
  - `confluent-kafka`: Kafka Producer
  - `APScheduler`: 주기적 작업 스케줄링

**배포:**
- Docker 컨테이너로 패키징
- Flink/Kafka 클러스터와 완전히 독립
- 단일 인스턴스 실행 (분산 잠금 불필요)

---
### 3. 핵심 로직: 10초 주기 검증 루프

이 서비스의 핵심은 10초마다 주기적으로 실행되는 상태 검증 및 복원 로직입니다. 코드가 아닌 논리적 흐름은 다음과 같습니다.

#### 3.1 \[1단계] PostgreSQL에서 '사실의 원천' 조회:

주기적으로 trade_cycles 테이블을 쿼리하여, 현재 status가 OPEN인 모든 포지션의 목록을 가져옵니다. 이 목록은 시스템의 장기적인 관점에서 '반드시 존재해야 하는 포지션'의 기준점, 즉 '사실의 원천(Source of Truth)'이 됩니다

#### 3.2 [\2단계] 오탐(False Positive) 방지를 위한 필터링:

DB에서 조회된 모든 OPEN 포지션이 즉시 복원 대상이 되는 것은 아닙니다. 방금 막 청산되었으나 아직 DB에 반영되지 않은 정상적인 상황을 '오류'로 오인하는 것을 방지하기 위해, 다음과 같은 안전 필터를 적용합니다.

최근 청산 신호 확인: 만약 특정 포지션에 대해 최근 10초 이내에 SELL 신호가 발행된 기록이 signals 테이블에 있다면, 이는 현재 정상적으로 청산 절차가 진행 중인 것으로 간주하고 이번 검증 주기에서는 제외합니다.

신규 포지션 유예 기간: 포지션이 생성된 지 1분 미만이라면, 아직 Flink의 실시간 피드백 루프가 처리 중일 가능성이 높으므로, 상태가 완전히 안정화될 때까지 기다리기 위해 이번 검증에서는 제외합니다.

#### 3.3 \[3단계] 상태 불일치 확정 및 복원 명령 생성:

위 필터링을 거치고도 여전히 남아있는 OPEN 포지션이 있다면, 이는 "Flink의 실시간 상태(active_positions)에서 누락된 '유령 포지션'"으로 최종 확정됩니다. 이 유령 포지션 각각에 대해, Flink가 상태를 재구성하는 데 필요한 모든 정보(PositionInfo)를 담은 StateRestoreCommand 메시지를 생성합니다

#### 3.4 \[4단계] Kafka를 통한 복원 명령 발행:

생성된 StateRestoreCommand 메시지를 system.state.restore.v1 Kafka 토픽으로 발행합니다. 이때 메시지 키를 해당 마켓 코드(code)로 지정하여, Flink 클러스터 내에서 정확히 해당 마켓의 상태를 책임지는 올바른 작업자(Task Manager)에게 명령이 전달되도록 보장합니다.

이러한 단계를 통해 Reconciliation Job은 시스템의 상태 불일치를 주기적으로 감지하고, Flink에게 안전하게 자가 치유(Self-healing) 명령을 내리는 역할을 수행합니다.

---
### 4. 동작 시나리오

#### 시나리오 1: 정상 운영 (메시지 발행 없음)

```
T+0s:   Reconciliation 실행
        → PostgreSQL: 5개 OPEN 포지션
        → 모두 최근 10초 내 활동 확인됨
        → 판단: "정상"
        → 결과: 아무것도 안 함 ✅

T+10s:  Reconciliation 실행
        → PostgreSQL: 4개 OPEN (1개 닫힘)
        → 모두 정상
        → 결과: 아무것도 안 함 ✅

발행된 메시지: 0건
```

#### 시나리오 2: Flink 재시작 후 State 유실

```
T+0s:   Flink 정상 운영
        → active_positions: {"KRW-BTC": ...} ✅

T+10s:  💥 Flink 죽음 (Checkpoint 실패)

T+15s:  Flink 재시작
        → active_positions: {} ❌ (State 유실)

T+20s:  Reconciliation 실행
        → PostgreSQL: KRW-BTC OPEN 발견
        → Entry timestamp: T-60s (1분 전)
        → 최근 EXIT 신호: 없음
        → 판단: "Flink가 모르는 포지션!"
        → system.state.restore.v1 발행 📨

T+20.1s: Flink 수신
         → active_positions.put("KRW-BTC", ...) ✅
         → 매도 로직 재활성화

결과: State 복원 성공 ✅
```

#### 시나리오 3: False Positive 방지 (매도 직후)

```
T+0s:   Flink 매도 신호 생성
        → active_positions.remove("KRW-BTC") ✅

T+0.1s: 주문 성공
        → execution.results.v1 발행

T+0.5s: Reconciliation 실행 (불운한 타이밍)
        → PostgreSQL: KRW-BTC OPEN (아직 업데이트 안 됨)
        → 최근 EXIT 신호: T+0s ✅ (10초 이내!)
        → 판단: "곧 닫힐 예정. 무시"
        → 결과: 아무것도 안 함 ✅

T+2s:   Archivist가 DB 업데이트
        → trade_cycles: KRW-BTC CLOSED ✅

결과: False Positive 회피 ✅
```

### 5. 모니터링 및 알림

Reconciliation Job의 동작 상태를 파악하기 위해 다음과 같은 핵심 지표들을 Prometheus와 같은 모니터링 시스템에 노출시켜야 합니다.
- reconciliation_runs_total: 검증 루프가 실행된 총 횟수. (Job의 활성 상태 확인)
- open_positions_in_db_gauge: 검증 시점마다 DB에서 발견된 OPEN 상태의 포지션 수.
- restore_commands_sent_total: Flink로 실제 발행된 복원 명령의 총 횟수. 이 지표의 갑작스러운 증가는 Flink 또는 피드백 시스템의 잠재적인 문제를 의미하는 강력한 경고 신호입니다.
- reconciliation_duration_seconds: 한 번의 검증 주기를 완료하는 데 걸리는 시간. DB 조회 성능 저하 등을 감지하는 데 사용됩니다.

### 6. Edge Case 처리

| 상황 | 처리 방법 |
|------|----------|
| **Reconciliation 자체가 죽으면?** | Health check 실패 → Kubernetes 와 같은 플랫폼이 자동 재시작 |
| **Kafka 장애로 발행 실패?** | 로그 기록 + 다음 주기(10초 후)에 재시도 |
| **PostgreSQL 지연으로 조회 느림?** | Timeout 설정 (5초) + Skip this cycle |
| **Reconciliation을 여러 개 띄우면?** | MVP: 단일 인스턴스만 실행 (replicas=1) <br> 프로덕션: PostgreSQL Advisory Lock 사용 |

### 7. 프로덕션 고려사항

고가용성을 위해 Reconciliation Job을 여러 인스턴스로 배포할 경우, 여러 Job이 동시에 DB를 조회하고 중복된 복원 명령을 보내는 것을 방지해야 합니다. 이를 위해 PostgreSQL의 Advisory Lock과 같은 분산 잠금 메커니즘을 사용해야 합니다.

서비스가 시작될 때, 모든 인스턴스는 공유된 잠금(Lock)을 획득하려고 시도합니다. 오직 잠금 획득에 성공한 단 하나의 인스턴스만이 주기적인 검증 루프를 실행하고, 나머지 인스턴스들은 대기 상태를 유지합니다. 이를 통해 서비스의 안정성을 보장하면서도 중복 실행 문제를 원천적으로 방지할 수 있습니다.

---
## 6. 데이터베이스 및 관리 계층 (Persistence & Management Layer) in detail 

이 계층은 단순히 데이터를 저장하는 창고가 아닙니다. 시스템의 모든 활동을 기록하는 '불변의 역사서'이자, 과거의 데이터로부터 전략을 개선하는 '학습의 기반'이며, 전체 시스템의 행동을 통제하는 '중앙 관제소'입니다. 이 계층의 설계는 시스템의 신뢰성, 감사 가능성, 그리고 장기적인 진화 가능성을 결정합니다.

---
### 1. 제1원칙: "모든 것을 기억하고, 모든 것으로부터 배우라"
우리는 이 계층을 다음 네 가지 핵심 원칙 하에 설계합니다.

- 감사 가능성 (Auditability): 시스템이 내린 모든 결정(매매 신호)과 행동(주문 실행)은 왜, 언제, 어떤 데이터를 기반으로 이루어졌는지 완벽하게 역추적할 수 있어야 합니다. 이는 장애 분석과 신뢰성 확보의 근간입니다.
- 분석 가능성 (Analyzability): 단순한 거래 기록을 넘어, 전략의 성과를 다각도로 측정하고, 성공과 실패의 패턴을 발견하며, 하이퍼파라미터를 최적화할 수 있는 정제된 데이터를 제공해야 합니다. 이 계층은 '데이터'를 '통찰력'으로 바꾸는 용광로입니다.
- 통제 가능성 (Controllability): 시스템의 두뇌(Flink)와 손발(Execution Engine)이 사용할 전략, 리스크 한도 등의 핵심 파라미터를 중앙에서 관리하고, 필요시 시스템 중단 없이 실시간으로 변경할 수 있는 유연성을 제공해야 합니다.
- 불변성 (Immutability): 발생한 모든 이벤트(신호, 주문, 체결)는 사실 그대로 기록되며, 절대 수정되거나 삭제되지 않는 것을 원칙으로 합니다.

---
### 2. 데이터베이스 스키마 설계: 시스템의 기억 구조

PostgreSQL의 강력한 기능(JSONB, Transaction, Index 등)을 적극 활용하여 다음과 같이 스키마를 설계합니다.

#### strategy_configs - 전략 하이퍼파라미터 관리

전략의 모든 두뇌를 이곳에서 관리합니다. 버전 관리를 통해 A/B 테스트와 점진적인 성능 개선을 지원합니다.

Column	Type	Description
id	BIGSERIAL	PK
strategy_id	VARCHAR	전략의 고유 식별자 (e.g., 'P_WAVE_V1')
config_version	INT	동일 전략 내 하이퍼파라미터 버전 (e.g., 1, 2, 3...)
hyperparameters	JSONB	전략에 사용되는 모든 하이퍼파라미터 (e.g., {"pwave": {"density_threshold_pct": 30}, "risk": ...})
is_active	BOOLEAN	현재 Flink 및 주문 실행기가 참조해야 할 활성 버전인지 여부
description	TEXT	해당 버전의 특징이나 변경 사항에 대한 설명
created_at	TIMESTAMPTZ	레코드 생성 시각

- Unique Constraint: (strategy_id, config_version)

---
#### signals - 모든 생성 신호 기록

실행 여부와 관계없이 Flink가 생성한 모든 매매 신호를 기록하여 전략의 오탐/미탐 여부를 분석하는 데 사용합니다.

Column	Type	Description
id	BIGSERIAL	PK
signal_id	UUID	신호 고유 ID (Protobuf의 signal_id, UNIQUE)
code	VARCHAR	마켓 코드 (e.g., "KRW-BTC")
side	VARCHAR	"BUY" or "SELL"
reason	VARCHAR	신호 생성 이유 (e.g., "P_WAVE_EARTHQUAKE_DETECTED")
price_at_signal	NUMERIC	신호 발생 시점의 기준 가격
signal_timestamp	TIMESTAMPTZ	Flink가 신호를 생성한 시각 (Event Time)
created_at	TIMESTAMPTZ	DB에 기록된 시각

- Indexes: signal_id, (code, signal_timestamp)

---
#### trades - 모든 주문 실행 결과 기록

주문 실행 계층의 모든 활동을 기록하는 감사 추적의 핵심 테이블입니다.

Column	Type	Description
id	BIGSERIAL	PK
trade_id	UUID	거래 결과 고유 ID (ExecutionResult의 result_id, UNIQUE)
original_signal_id	UUID	이 주문을 유발한 원본 신호 ID (FK to signals.signal_id)
exchange_order_id	VARCHAR	거래소가 부여한 주문 ID
status	VARCHAR	SUCCESS, VALIDATION_FAILED, API_ERROR 등 실행 결과
code	VARCHAR	마켓 코드
side	VARCHAR	"BUY" or "SELL"
executed_price	NUMERIC	실제 평균 체결 가격 (체결 성공 시)
executed_volume	NUMERIC	실제 체결 수량 (체결 성공 시)
fee	NUMERIC	발생한 수수료 (체결 성공 시)
error_message	TEXT	실행 실패 시 상세 에러 메시지
execution_timestamp	TIMESTAMPTZ	주문 실행 계층이 작업을 완료한 시각

- Indexes: trade_id, original_signal_id, exchange_order_id, (code, execution_timestamp)

--- 
#### trade_cycles - 진입/청산 사이클 및 손익(P&L) 관리

개별 거래의 성과를 측정하기 위한 최종 분석 테이블입니다.

Column	Type	Description
id	BIGSERIAL	PK
code	VARCHAR	마켓 코드
entry_trade_id	BIGINT	진입 거래 ID (FK to trades.id)
entry_signal_id	UUID	진입 신호 ID (FK to signals.signal_id, 복원용)
exit_trade_id	BIGINT	청산 거래 ID (FK to trades.id, NULLABLE)
status	VARCHAR	"OPEN" or "CLOSED"
pnl	NUMERIC	손익 (수수료 포함)
pnl_percentage	NUMERIC	수익률 (%)
holding_duration_ms	BIGINT	포지션 보유 시간 (밀리초)
entry_timestamp	TIMESTAMPTZ	진입 시각
exit_timestamp	TIMESTAMPTZ	청산 시각 (NULLABLE)

- Indexes: (status, code), entry_trade_id, entry_signal_id, exit_trade_id

---
#### system_events 테이블 

프로젝트의 궁극적인 성공을 위해, 시스템의 운영 상태를 기록하는 새로운 테이블을 추가해야 합니다.

시스템 컴포넌트 간의 '상태 전이(State Transition)' 기록
- 현재 스키마는 "Flink가 BUY 신호를 만들었다"(signals) 와 "주문 실행기가 체결에 성공했다"(trades)는 결과는 기록하지만, 그 두 사건 사이의 과정에서 발생하는 시스템 내부의 이벤트를 기록하지 않습니다.
- 질문 1: Flink가 신호를 Kafka에 발행한 시각과 주문 실행기가 그 메시지를 소비한 시각의 차이(Latency)는 얼마인가?
- 질문 2: 주문 실행기가 API 요청을 보냈지만 타임아웃이 발생하여 재시도했다는 사실을 어떻게 알 수 있는가?
- 질문 3: Archivist 서비스가 장애로 인해 몇 시간 동안 Kafka 데이터를 DB에 쓰지 못했다는 사실을 어떻게 기록하고 추적할 것인가?
- 이러한 '운영 데이터'의 부재는 장애 발생 시 원인 분석을 매우 어렵게 만들고, 시스템의 잠재적인 병목 구간을 파악하지 못하게 하는 문제를 해결할 수 있음. 

언제 이를 발행하는가? system.events.v1 Kafka 토픽에서 이를 수신해서 DB 에 기입하면 됨. 

스키마 구조: 
Column	Type	Description
id	BIGSERIAL	PK
event_id	UUID	이벤트 고유 ID
correlation_id	UUID	연관된 signal_id 또는 trade_id
service_name	VARCHAR	이벤트를 발생시킨 서비스 이름 (e.g., 'Flink', 'ExecutionEngine', 'Archivist')
event_type	VARCHAR	이벤트 타입 (e.g., 'SIGNAL_PRODUCED', 'SIGNAL_CONSUMED', 'API_RETRY')
event_status	VARCHAR	'SUCCESS', 'FAILURE'
event_message	TEXT	상세 메시지 또는 에러 로그
event_timestamp	TIMESTAMPTZ	이벤트 발생 시각

---
#### raw_trades` 테이블: 실시간 체결 원본 데이터

모든 거래 체결 데이터를 시간 순서대로 기록합니다.

```sql
-- 실시간 체결 원본 데이터 (백테스팅용)
CREATE TABLE raw_trades (
    trade_timestamp TIMESTAMPTZ NOT NULL, -- 체결 시각 (Hypertable 시간 축)
    received_timestamp TIMESTAMPTZ NOT NULL, -- 수집 서버 수신 시각
    sequential_id BIGINT NOT NULL, -- 업비트 체결 고유 ID
    code VARCHAR(20) NOT NULL, -- 마켓 코드 (e.g., "KRW-BTC")
    trade_price NUMERIC NOT NULL, -- 체결 가격
    trade_volume NUMERIC NOT NULL, -- 체결량
    ask_bid VARCHAR(4) NOT NULL, -- 'ASK' or 'BID'
    prev_closing_price NUMERIC NOT NULL, -- 전일 종가
    change VARCHAR(10) NOT NULL, -- 'RISE', 'EVEN', 'FALL'
    change_price NUMERIC NOT NULL, -- 전일 대비 변동액
    stream_type VARCHAR(10) NOT NULL -- 'SNAPSHOT' or 'REALTIME'
);

-- sequential_id와 trade_timestamp를 복합 기본 키로 설정
ALTER TABLE raw_trades ADD PRIMARY KEY (sequential_id, trade_timestamp);

-- Hypertable로 전환
SELECT create_hypertable('raw_trades', 'trade_timestamp');

-- 쿼리 성능을 위한 인덱스 생성
CREATE INDEX idx_raw_trades_code_timestamp ON raw_trades (code, trade_timestamp DESC);
```

---
#### `raw_orderbooks` 테이블: 실시간 호가창 원본 데이터

모든 호가창 변경 내역을 기록합니다.

```sql
-- 실시간 호가창 원본 데이터 (백테스팅용)
CREATE TABLE raw_orderbooks (
    event_timestamp TIMESTAMPTZ NOT NULL, -- 호가창 변경 이벤트 시각 (Hypertable 시간 축)
    received_timestamp TIMESTAMPTZ NOT NULL, -- 수집 서버 수신 시각
    code VARCHAR(20) NOT NULL, -- 마켓 코드
    total_ask_size NUMERIC NOT NULL, -- 총 매도량
    total_bid_size NUMERIC NOT NULL, -- 총 매수량
    orderbook_units JSONB NOT NULL, -- 호가 단위 목록 (원본 구조 그대로 저장)
    stream_type VARCHAR(10) NOT NULL -- 'SNAPSHOT' or 'REALTIME'
);

-- code와 event_timestamp를 복합 기본 키로 설정
ALTER TABLE raw_orderbooks ADD PRIMARY KEY (code, event_timestamp);

-- Hypertable로 전환
SELECT create_hypertable('raw_orderbooks', 'event_timestamp');

-- 참고: 기본 키 생성 시 (code, event_timestamp)에 대한 인덱스가 자동으로 생성됩니다.
```

---
### 3. 데이터 흐름 아키텍처: '기록원(Archivist)' 서비스들 

Kafka 토픽의 데이터를 PostgreSQL에 안정적으로 저장하기 위한 마이크로서비스입니다. Archivist는 역할에 따라 두 개의 독립적인 서비스로 분리하여 책임과 확장성을 명확히 합니다.

컴포넌트: Archivist Service (Python, asyncio, confluent-kafka, asyncpg 기반)

#### Archivist (Raw Data Logger)

*   **역할:** 백테스팅을 위한 원본 데이터를 축적하는 데 모든 책임을 집니다.
*   **구독 토픽:** `upbit.trades.v1`, `upbit.orderbooks.v1`
*   **저장 테이블:** `raw_trades`, `raw_orderbooks` (in TimescaleDB)
*   **핵심 로직:** Kafka에서 받은 Protobuf 메시지를 각 테이블 컬럼에 맞게 변환하여 TimescaleDB에 배치(batch) 형태로 최대한 빠르게 INSERT합니다. 데이터 변환 로직은 최소화하여 원본에 가깝게 저장하는 것을 원칙으로 합니다.

#### Archivist (Trade Cycle Manager)

*   **역할:** 실제 매매와 관련된 데이터를 기록하고, 진입/청산 사이클을 완성하여 성과를 계산합니다.
*   **구독 토픽:** `internal.signals.v1`, `execution.results.v1`
*   **저장 테이블:** `signals`, `trades`, `trade_cycles`
*   **핵심 로직 (Trade Cycle 매칭):**
    *   `trades` 테이블에 SUCCESS 상태의 SELL 거래가 기록될 때, 해당 `code`에 대해 `status`가 `OPEN`인 `trade_cycles` 레코드를 찾습니다. 매칭되는 레코드가 있으면, 해당 레코드를 `CLOSED`로 업데이트하고 `exit_trade_id`, `pnl`, `holding_duration_ms` 등 최종 성과 지표를 계산하여 채워 넣습니다.
    *   SUCCESS 상태의 BUY 거래가 기록되면, 새로운 `trade_cycles` 레코드를 `OPEN` 상태로 생성합니다.
*   **데이터 정합성:**
    *   Kafka의 At-Least-Once Delivery 특성으로 인해 동일 메시지가 중복 처리될 수 있습니다. `signals.signal_id`와 `trades.trade_id`에 설정된 UNIQUE 제약 조건을 활용하여 데이터베이스 레벨에서 멱등성을 보장합니다. 서비스 로직은 `INSERT ... ON CONFLICT DO NOTHING` 구문을 사용하여 중복 삽입 에러를 방지합니다.

---
### 4. PostExecutionAnalyzer 사후 체결 분석: 

주문 실행 계층의 핵심 원칙 중 하나는 '실행 경로(Fast-Path)'와 '분석 경로(Slow-Path)'를 분리하는 것입니다. 주문 실행은 1ms라도 빠르게 처리되어야 하므로, 복잡한 분석 로직이 실행을 방해해서는 안 됩니다.

PostExecutionAnalyzer는 바로 이 '분석 경로'를 책임지는 컴포넌트로, 모든 주문이 체결된 이후에 비동기적으로 동작합니다. 이는 시스템이 스스로의 행동을 복기하고, 그로부터 학습하여 장기적으로 더 나은 결정을 내리게 하는 '자가 진단 및 학습 루프'의 핵심입니다.

#### 5.1. 분석의 목적: "우리의 실행은 얼마나 효율적이었는가?"
이 컴포넌트는 모든 거래에 대해 다음과 같은 핵심 품질 지표(KPI)를 측정하여, 눈에 보이지 않는 비용과 비효율을 정량화합니다.
- 슬리피지 (Slippage): Flink가 신호를 보낸 시점의 가격과 실제 체결된 평균 가격의 차이를 계산합니다. 이 값이 크다는 것은, 우리의 주문이 시장에 충격을 주었거나 불리한 타이밍에 체결되었음을 의미하는 가장 중요한 비용 지표입니다.
- 엔드-투-엔드 지연 시간 (End-to-End Latency): Flink가 신호를 생성한 시점부터 주문 실행 계층이 체결 완료를 인지한 시점까지의 총 소요 시간(ms)을 측정합니다. 이를 통해 시스템 전체의 성능 병목 구간을 식별할 수 있습니다.
- 체결 품질 점수 (Execution Quality Score): 위 두 지표(슬리피지, 지연 시간)를 가중 평균하여, 각 거래의 실행 품질을 0점에서 1점 사이의 표준화된 점수로 계산합니다. 이는 여러 코인과 시간대에 걸친 실행 성과를 객관적으로 비교할 수 있게 해줍니다.

#### 5.2. 동작 워크플로우

(1) 트리거: 주문이 성공적으로 체결되고 ExecutionResult 메시지가 발행되면, 이 컴포넌트가 비동기적으로 트리거됩니다.

(2) 데이터 수집: 원본 TradingSignal과 최종 ExecutionResult 두 메시지를 입력받습니다.

(3) 품질 지표 계산: 위에서 설명한 슬리피지, 지연 시간, 품질 점수를 계산합니다.

(4) 결과 저장: 계산된 모든 품질 지표를 execution_quality와 같은 별도의 분석용 테이블에 영구적으로 기록하여 장기적인 추세 분석의 기반을 마련합니다.
실시간 이상 감지 및 경고: 만약 슬리피지가 사전에 정의된 임계치(e.g., 100bps = 1%)를 초과하는 등 비정상적인 결과가 감지되면, 즉시 경고 로그를 남기고 모니터링 시스템(e.g., Sentry, Slack)으로 알림을 보냅니다.

#### 5.3. 장기적인 가치: 자동화된 리스크 관리 및 전략 개선

PostExecutionAnalyzer는 단순한 로깅 도구가 아닙니다. 축적된 데이터를 바탕으로 다음과 같은 능동적인 시스템 개선을 가능하게 합니다.
- 슬리피지 패턴 분석: 특정 코인이나 특정 시간대에서 지속적으로 높은 슬리피지가 발생한다면, 이를 '거래 비우호적 구간'으로 자동 식별할 수 있습니다.
- 동적 리스크 관리: 분석 결과를 바탕으로, 특정 마켓의 변동성이 너무 커져 거래 품질이 저하된다고 판단되면, 해당 마켓에 대한 거래 빈도를 자동으로 줄이거나 최소 주문 금액을 조절하는 등의 자가 적응형 리스크 관리 로직을 구현할 수 있습니다.

이처럼 사후 분석 메커니즘은, 스캘핑 시스템이 변화무쌍한 시장 환경 속에서 단기적인 수익뿐만 아니라 장기적인 안정성과 지속 가능성을 확보하기 위한 필수적인 '면역 체계' 역할을 수행합니다.


---
## 6. Scalper Admin & Dashboard 서비스 in detail 

### 1. 핵심 책임:
- 하이퍼파라미터 관리: strategy_configs 테이블에 대한 CRUD 인터페이스를 제공합니다. 관리자는 웹 UI를 통해 각 전략의 파라미터를 직관적으로 수정하고, 버전을 관리하며, 활성 버전을 지정할 수 있습니다.
- 전략 업데이트 트리거: 관리자가 UI에서 '활성화' 버튼을 누르면, 이 서비스가 책임지고 system.config.updates.v1 Kafka 토픽으로 변경 알림 메시지를 발행(Publish)합니다.
- 성과 분석 대시보드: PostgreSQL의 v_trade_performance 뷰와 같은 분석용 뷰를 조회하여, KPI 지표들을 시각화된 차트와 테이블로 제공합니다.


### 2. 기술 스택 예시 (Python 기반):
- 백엔드 (API 서버): FastAPI
    - 이유: asyncio 기반으로 동작하여 비동기 DB 드라이버(asyncpg)와 잘 맞고, 자동 API 문서 생성 기능이 뛰어나 개발이 빠릅니다.
- 프론트엔드 (UI):
    - Jinja2 + htmx: 더 간단한 관리 페이지를 원한다면, FastAPI에 내장된 템플릿 엔진을 사용하여 서버 사이드 렌더링 방식으로 빠르게 구현할 수도 있습니다.
- 데이터베이스 접속: SQLAlchemy 2.0 (비동기 지원) 또는 asyncpg 직접 사용

### 3. 사용자 시나리오 예시:

- (1) 관리자가 웹 브라우저로 http://admin.my-scalper.com에 접속합니다.
- (2) 로그인 후, 대시보드에서 현재 누적 P&L과 승률을 확인합니다.
- (3) '전략 관리' 탭으로 이동하여 P_WAVE_V1 전략의 상세 페이지로 들어갑니다.
- (4) pwave.density.threshold_pct 값을 30%에서 35%로 수정한 뒤 '저장 및 활성화' 버튼을 클릭합니다.
- (5) Scalper Admin 백엔드는 다음 두 가지 작업을 수행합니다.
    - PostgreSQL의 strategy_configs 테이블에 해당 레코드를 업데이트하고 is_active 플래그를 조정합니다.
    - Kafka Producer를 통해 system.config.updates.v1 토픽으로 { "strategy_id": "P_WAVE_V1" } 메시지를 전송합니다.
- (6) 실시간으로 동작 중이던 Flink Job과 주문 실행 계층은 이 Kafka 메시지를 수신하고 즉시 메모리에 로드된 설정을 새로운 35% 값으로 교체합니다. 시스템은 단 1초의 중단도 없이 새로운 전략으로 업데이트됩니다.

### 4. 실시간 하이퍼파라미터 관리: '무중단 전략 업데이트'

전체 시스템을 재시작하지 않고 실시간으로 전략 파라미터를 변경하는 것은 운영 효율성에 매우 중요합니다.

업데이트 프로세스:
- DB 변경: 관리자가 strategy_configs 테이블에 새로운 버전의 설정을 추가하거나 기존 설정을 수정한 뒤, is_active 플래그를 조정합니다.
- 변경 전파 (Publish): 관리 툴이나 스크립트를 통해 system.config.updates.v1 Kafka 토픽으로 변경 사실을 알리는 메시지를 전송합니다. (e.g., { "event": "CONFIG_UPDATED", "strategy_id": "P_WAVE_V1" })
- 실시간 수신 (Subscribe): Flink Job과 주문 실행 계층은 이 system.config.updates.v1 토픽을 구독하는 별도의 경량 스레드/태스크를 가집니다.
- 메모리 반영 (Reload): 업데이트 메시지를 수신하면, 각 컴포넌트는 즉시 DB의 strategy_configs 테이블을 다시 쿼리하여 최신 활성 설정을 메모리로 불러와 기존 설정을 대체합니다.
- Flink 구현: 이 메커니즘은 Flink의 Broadcast State 패턴을 사용하여 완벽하게 구현할 수 있습니다. 설정 변경 스트림을 모든 SignalGenerator 인스턴스에 브로드캐스트하여 모든 작업자가 동시에 최신 하이퍼파라미터를 적용하도록 보장합니다.

### 5. 성과 분석 및 대시보드: '전략 계기판' 설계

수집된 데이터를 활용하여 전략의 성과를 직관적으로 파악할 수 있는 계기판을 설계합니다.

핵심성과지표 (KPIs):
- 수익성: 누적 손익(Cumulative P&L), 일/주/월별 손익, 평균 손익, 손익비(Profit Factor)
- 승률: 전체 승률, 코인별 승률, 진입/청산 이유별 승률
- 리스크: 최대 낙폭(Max Drawdown), 샤프 지수(Sharpe Ratio)
- 효율성: 평균 포지션 보유 시간, 일일 평균 거래 횟수
- 거래 품질: 평균 슬리피지(신호 가격 대비 체결 가격의 차이)

구현:
- PostgreSQL의 Views 또는 Materialized Views를 생성하여 위 KPI들을 미리 계산해 둡니다.
- 예시 View (v_trade_performance)

```sql
        CREATE VIEW v_trade_performance AS
        SELECT
            c.id,
            c.code,
            c.status,
            c.pnl,
            c.pnl_percentage,
            c.holding_duration_ms,
            entry_s.reason as entry_reason,
            exit_s.reason as exit_reason,
            c.entry_timestamp,
            c.exit_timestamp
        FROM trade_cycles c
        JOIN trades entry_t ON c.entry_trade_id = entry_t.id
        LEFT JOIN trades exit_t ON c.exit_trade_id = exit_t.id
        JOIN signals entry_s ON entry_t.original_signal_id = entry_s.signal_id
        LEFT JOIN signals exit_s ON exit_t.original_signal_id = exit_s.signal_id;
```

- Metabase, Grafana 같은 BI 툴을 이 View에 연결하여 대시보드를 시각화합니다.

