## 1. 데이터 수집 계층 실제 구현 설계 및 체크리스트

### 1.1 프로젝트 구조 

src 
├── data_ingestion/                           # 1. 데이터 수집 계층
│   ├── domain/
│   │   ├── models/
│   │   │   ├── connection_state.py           # ConnectionState Enum
│   │   │   ├── market_data.py                # MarketDataMessage
│   │   │   └── exchange_config.py            # ExchangeConfig
│   │   ├── ports/
│   │   │   ├── exchange_connector.py         # ExchangeConnector 인터페이스
│   │   │   └── message_publisher.py          # MessagePublisher 인터페이스
│   │   └── exceptions.py
│   ├── infrastructure/
│   │   ├── connectors/
│   │   │   ├── upbit_connector.py            # UpbitWebSocketConnector 구현
│   │   │   ├── bithumb_connector.py          # BithumbWebSocketConnector 구현
│   │   │   └── base_websocket.py             # WebSocket 공통 로직
│   │   ├── kafka/
│   │   │   └── kafka_producer.py             # Kafka Producer 구현
│   │   │   └── message_buffer.py             # Kafka Producer 백프래셔 구현
│   ├── application/
│   │   ├── services/
│   │   │   └── ingestion_service.py          # 데이터 수집 오케스트레이션
│   │   └── use_cases/
│   │       ├── stream_market_data.py         # 실시간 데이터 스트리밍 유즈케이스
│   └── interface/
│       ├── cli/
│       │   └── main.py                       # CLI 진입점
│       ├── monitoring/
│       │   ├── metrics.py                    # Prometheus 메트릭
│       │   └── health_check.py               # Health Check 엔드포인트
│       └── config/
│           └── settings.py 

--- 

### 1.1 domain/models/connection_state.py - ConnectionState Enum

```python
class ConnectionState(Enum):
    DISCONNECTED = "disconnected"
    CONNECTING = "connecting"
    CONNECTED = "connected"
    RECONNECTING = "reconnecting"
    FAILED = "failed"
```

- [ ] 불변성 보장: Enum이 frozen=True 설정되어 있거나 값 변경 불가능한가?
- [ ] 상태 전환 매트릭스: 허용 가능한 상태 전환 경로가 주석으로 명시되어 있고, 허용된 상태에서만 전환이 되는가? (테스트 케이스 필요) / RECONNECTING -> CONNECTED 무한 루프 방지 / is_valid_transition() 메서드로 상태 머신 구현

---
### 1.2 domain/models/market_data.py - MarketDataMessage

```python
from dataclasses import dataclass
from datetime import datetime
from typing import Literal

@dataclass(frozen=True)
class MarketDataMessage:
    """원시 시장 데이터를 담는 불변 객체"""
    
    exchange: str  # "upbit", "bithumb"
    data_type: Literal["trade", "orderbook"]
    code: str  # "KRW-BTC"
    raw_data: dict  # 거래소 원본 JSON
    received_timestamp: datetime
    
    def validate(self) -> None:
        """비즈니스 규칙 검증"""
        if not self.code.startswith("KRW-"):
            raise ValueError(f"Invalid market code: {self.code}")
        # ...
```

- 유효하지 않은 code 형식 입력 시 validate() 예외 발생 
- raw_data가 빈 딕셔너리일 때 예외 발생 
- [ ] 코드 정규화: code를 대문자로 정규화하는가? ("krw-btc" → "KRW-BTC")
- 가격 양수 제약 / Decimal 정밀도로 가격 유지 / 매도 호가는 오름차순 정렬, 매수 호가는 가격 내림차순 정렬 

---

### 1.3 domain/models/exchange_config.py - ExchangeConfig

```python
from dataclasses import dataclass
from typing import Set

@dataclass(frozen=True)
class ExchangeConfig:
    """거래소별 설정"""
    
    exchange_name: str
    websocket_url: str
    rest_api_url: str
    subscribed_markets: Set[str]  # ["KRW-BTC", "KRW-ETH"]
    ping_interval_seconds: int = 60
    max_reconnect_attempts: int = 10
    
    def validate(self) -> None:
        if self.ping_interval_seconds < 30:
            raise ValueError("ping_interval must be >= 30 seconds")
        # ...
```

- ping_interval_seconds < 60초 시 검증 실패	/ 업비트 Idle Timeout(120초) 대응	
- 중복된 마켓 코드가 있을 때 자동 제거	/ 데이터 중복 방지	
- max_reconnect_attempts = 0일 때 무한 재시도로 해석 / 장애 복구 전략	
- 보안: API 키가 이 객체에 포함되어 있지 않은가? (환경 변수로 분리)
- [ ] URL 검증: websocket_url과 rest_api_url이 유효한 URL 형식인가?
- 재시도 전략: Exponential Backoff 설정이 포함되어 있는가?
- subscribed_markets가 빈 Set 일 때 거부 / 논리적 오류 방지 

---

### 1.4 domain/ports/exchange_connector.py - ExchangeConnector 인터페이스

```python
from abc import ABC, abstractmethod
from typing import AsyncIterator
from domain.models import MarketDataMessage, ConnectionState

class ExchangeConnector(ABC):
    """거래소 연결 추상 인터페이스 (Port)"""
    
    @abstractmethod
    async def connect(self) -> None:
        """WebSocket 연결 수립"""
        pass
    
    @abstractmethod
    async def disconnect(self) -> None:
        """연결 종료 및 리소스 정리"""
        pass
    
    @abstractmethod
    async def stream_market_data(self) -> AsyncIterator[MarketDataMessage]:
        """실시간 데이터 스트림 생성"""
        pass
    
    @abstractmethod
    async def get_connection_state(self) -> ConnectionState:
        """현재 연결 상태 반환"""
        pass
```

- 모든 메서드가 async로 정의되어 있는가	
- 예외 계층: Domain 예외(DomainException)를 정의하고 사용하는가? / DataIngestionException 이 데이터 수집 계층에서 가장 최상위 예외로 설정 / ConnectionFailedException 은 DataIngestionException 의 하위 클래스 
- stream_market_data 가 AsyncIterator 를 명시하는지 
- [ ] 멱등성: connect()를 여러 번 호출해도 안전한가?

---
### 1.5 domain/ports/message_publisher.py - MessagePublisher 인터페이스

--- 
### 1.6 domain/exceptions.py - 예외 계층 구조

```python
class DataIngestionException(Exception):
    """데이터 수집 계층 기본 예외"""
    pass

class ConnectionException(DataIngestionException):
    """연결 관련 예외"""
    pass

class ValidationException(DataIngestionException):
    """데이터 검증 실패"""
    pass

class PublishException(DataIngestionException):
    """메시지 발행 실패"""
    pass
```

- 모든 예외가 공통 기반 예외를 상속하는가	
- 예외 메시지가 충분한 컨텍스트를 포함하는가 
- 예외가 JSON 직렬화 가능한가
- [ ] 컨텍스트 보존: 예외가 원본 에러를 __cause__로 체이닝하는가?

---

## 2부: Infrastructure Layer - Connectors & HTTP Client 검증 & Kafka Producer & Protobuf 직렬화

(Kafka 설정에 대해서 누락되어 있음.)

### 2.1 infrastructure/connectors/base_websocket.py - WebSocket 공통 로직

- 연결 성공 시 _state가 CONNECTED로 전환되는가 / 연결 종료 시 DISCONNECTED 로 전환되는가 / 
- [ ] 상태 전환 원자성: _state 변경이 예외 발생 전에 일어나는가?
- [ ] 리소스 정리: disconnect()가 모든 예외 상황에서도 호출되는가?
- 연결 실패 시 Exponential Backoff가 정확히 동작하는가 (1s → 2s → 4s → 8s → ...)	
- [ ] 재연결 루프 무한 대기 방지: max_attempts 제한이 있는가?
- max_attempts 도달 시 FAILED 상태로 전환 및 예외 발생	
- ping_interval=60, ping_timeout=30 설정이 실제 적용되는가	
- 연결 중(CONNECTING) 상태에서 disconnect() 호출 시 안전하게 종료되는가	
- _backoff_seconds가 60초를 초과하지 않는가	
- WebSocket 핑/퐁 프레임이 60초마다 자동 전송되는가	
- connect에서 Race Condition 으로 동시 연결 가능성 있음 
- UpbitWebSocket 및 UpbitExchangConfig 만들어서 연결 테스트 해봐야함. 

--- 

### 2.2 infrastructure/connectors/upbit_connector.py - UpbitWebSocketConnector

- 구독 메시지가 업비트 스펙과 정확히 일치하는가 (ticket, type, codes)	
- ticket 필드가 매번 고유한 UUID를 생성하는가	
- ⭐️바이너리 메시지를 UTF-8로 정확히 디코딩하는가
- 연결 전 stream_market_data() 호출 시 RuntimeError 발생하는가 
- ⭐️WebSocket 연결 끊김 시 자동 재연결이 트리거되는가	
- 잘못된 JSON 수신 시 예외를 발생시키지만 연결은 유지되는가	
- received_timestamp가 UTC 시간대인가
- [ ] 재연결 루프 무한 반복 방지: _handle_disconnection()이 무한 재귀를 일으키지 않는가?
- [ ] 데이터 타입 검증: data.get("type")이 "trade" 또는 "orderbook"인지 확인하는가?
- ⭐️[ ] JSON 파싱 최적화: orjson 같은 고성능 라이브러리 사용을 고려했는가?
- [ ] 메모리 누수 방지: stream_market_data() 무한 루프에서 메모리 누적이 없는가? / ~~가져온 데이터를 asyncio.Queue 를 이용해서 넣고 있는가?~~ yield 가 더 적합  

- 구독 요청을 보낼 때 ticket 번호를 메모리에 유지하고, 구독 연결의 상태를 조회할 수 있도록. 상태와 매핑되서 관리. 

---

### 2.3 통합 시나리오 테스트 (Infrastructure Layer 전체)

- WebSocket 연결 끊김 → 재연결 → 정상 스트리밍 재개	
- 100개 마켓 구독 → 10초간 데이터 수신 → 데이터 유실/중복 없음 확인	
- 메모리 프로파일링: 실행 시 메모리가 안정적으로 유지되는지

---
### 2.4 infrastructure/kafka/kafka_producer.py - Kafka Producer 구현

⭐️(기본 config 파일 포함)- Producer 설정이 아키텍처 문서와 일치하는가 (linger.ms=5, acks=all, batch.size': 16384, compression.type': 'lz4', max.in.flight.requests.per.connection': 5, 'retries': 0, request.timeout.ms: 500, client.id: data-ingestion-connector)	
⭐️- [ ] 파티션 키 전략: message.code를 키로 사용하여 Flink의 keyBy() 요구사항을 충족하는가?
- 실패 시 로깅하고 있는가(관측성 측면)
- 백프래셔 관리를 하고 있는가 : 1. 오래된 데이터는 적극적으로 폐기 (TTL), 2. 큐 크기는 물리적 한계로 제한 (Bounded), 3. 투명한 손실 추적
- 호가창 데이터와 체결창 데이터가 별도의 프로듀서를 사용하고 있는지(데이터는 이벤트 시간별로 정렬되고 있으므로)

--- 
### 2.5 Protobuf 직렬화 로직 - _serialize_to_protobuf()

- 업비트 JSON 필드가 Protobuf 필드로 정확히 매핑되는가	
- 밀리초 타임스탬프가 Timestamp 객체로 올바르게 변환되는가	
- received_timestamp가 timezone-aware(UTC)인가	
- Enum 변환 시 잘못된 값은 UNSPECIFIED(0)으로 처리되는가	
- 호가창 15단계(asks/bids 각 15개)가 모두 직렬화되는가	
- 직렬화 후 역직렬화 시 데이터 손실이 없는가 (Roundtrip 테스트)	
- 필수 필드 누락 시 예외 발생하는가 (e.g., code 누락)	
- 직렬화 성능: 1,000개 메시지 < 100ms	
- [ ] 타임스탬프 정밀도: 밀리초 단위가 손실 없이 변환되는가?
- [ ] 성능 최적화: 반복적인 객체 생성을 피하는가? / 

--- 
### 2.6 MessageBuffer - Kafka Producer의 백프레셔 관리 (메모리 기반 메시지 큐잉 및 백프레셔 관리)

- TTL 검증 및 만료 메시지 자동 폐기를 하는가(1초 이상 데이터 폐기, 신선도 보장)
- 우선순위 메시지 전송 보장(호가창 데이터 > 거래 체결 데이터) 
- Bounded capacity 유지라는가 / 용량 초과 폐기 
- 카프카 프로듀서 배치 설정과 일관되게 배치가 처리되고 있는가? 저지연성을 보장하고 있는가
- dequeue_batch(100) 호출 시 최대 100개 반환	
- 비동기로 처리되고 있는가(비동기 큐(asyncio.Queue) 사용 등)
- [ ] TTL 타임존 일관성: 모든 타임스탬프가 UTC로 통일되어 있는가?


---
## 3부: Application Layer - 서비스 오케스트레이션 & 에러 복구

### 3.1 application/services/ingestion_service.py - 데이터 수집 오케스트레이션

- start() 호출 시 connector → publisher 순서로 초기화되는가	/ start 재호출시 RuntimeError 발생 
- SIGTERM 수신 시 10초 내 graceful shutdown 완료되는가 / _shutdown_event 설정 후 현재 메시지 처리 완료 후 종료되는가
- stop() 호출 시 모든 대기 메시지가 flush되는가	
- 여러 번 stop() 호출 시 멱등성이 보장되는가 / _running 플래그의 race condition 방지 (asyncio.Lock 고려)	
- 연속 10회 발행 실패 시 서비스가 중단되는가
- WebSocket 연결 끊김 시 자동 재연결 후 스트리밍 재개되는가	
- 1,000개 메시지마다 로그가 정확히 출력되는가	
- Kafka 일시 장애 시 발행 실패하지만 연결은 유지되는가	
- [ ] 리소스 누수 방지: finally 블록에서 모든 리소스를 정리하는가?
- get_status() 상태 조회 함수 있고 정확한가? 

---
### 3.2 application/use_cases/stream_market_data.py - 실시간 스트리밍 유즈케이스

- 빈 subscribed_markets 전달 시 ValidationException 발생	
- 잘못된 마켓 코드(BTC-KRW) 전달 시 예외 발생	
- 구독하지 않은 마켓 데이터가 필터링되는가	

--- 

### 3.3 모니터링 및 Health Check

- 정상 동작 시 status=HEALTHY, HTTP 200 반환	
- WebSocket 끊김 시 status=UNHEALTHY, HTTP 503 반환	
- Kafka 장애 시 status=DEGRADED, HTTP 503 반환	
- 1분 이상 메시지 없음 시 status=DEGRADED	
- Health Check 호출이 실제 서비스를 방해하지 않음	

---
## 4부(최종): Interface Layer & 시스템 통합 검증

### 4.1 interface/cli/main.py - CLI 진입점

- yaml 로 설정을 입력할 수 있는가? 
- 설정이 충분한가 (구독할 마켓 코드, Kafka 브로커 주소, --log-level)
- [ ] 에러 메시지 품질: 사용자가 문제를 즉시 이해하고 해결할 수 있는가?
- [ ] 로그 파일 관리: 로그 파일 로테이션이 설정되어 있는가?
- 민감 정보(API 키)가 로그에 노출되지 않음	

---
### 4.2 interface/config/settings.py - 설정 관리

- yaml 설정값이 settings 로 정확히 들어가는가
- 민감한 값은 .env 파일 또는 환경변수로 로딩이 되는가
- 민감 정보(API 키)가 로그에 노출되지 않음	
- 모든 중요 설정에 Validator가 있는가?

---
### 4.3 interface/monitoring/metrics.py - Prometheus 메트릭

- 감시해야할 메트릭들이 모두 정의되어 있는가(ingestion_messages_received_total, ingestion_messages_published_total, ingestion_processing_latency_seconds, ingestion_kafka_publish_latency_seconds, ingestion_connection_state, ingestion_consecutive_errors, ingestion_service_info) 

- Grafana 대시보드 패널이 구성되어 있고 docker 컨테이너에 통합되어 있는가 

- 컨테이너 시작 후 Health Check 통과 (30초 이내) 
- 로그가 stdout으로 올바르게 출력되는가	
